{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;font-size:36px\">IMPORT ET CONVERSION DES DONNEES DE COMPTAGES GESTIONNAIRE</h1>\n",
    "> il y a un exemple de verification si doublons de point dans le 17, 47, 87<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\martin.schoreisz\\git\\otv\\otv\\Transfert_Donnees')\n",
    "sys.path.append(r'C:\\Users\\martin.schoreisz\\git\\Outils\\Outils\\Martin_Perso')\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import csv, re, os, statistics, filecmp, unidecode\n",
    "import datetime as dt\n",
    "from math import sqrt, pi, exp, log, log10\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "import Connexion_Transfert as ct\n",
    "import Import_trafics as it\n",
    "from Donnees_horaires import (comparer2Sens, verifValiditeFichier, concatIndicateurFichierHoraire, SensAssymetriqueError,\n",
    "                              verifNbJoursValidDispo, tmjaDepuisHoraire, periodeDepuisHoraire, attributsHoraire, mensuelDepuisHoraire)\n",
    "from Donnees_sources import MHCorbin, NettoyageTemps, GroupeCompletude, NombreDeJours, FIM\n",
    "from Params.DonneesSourcesParams import MHcorbinMaxLength, MHcorbinMaxSpeed, MHCorbinValue0, MHCorbinFailAdviceCode\n",
    "import Outils as O\n",
    "from Params.Mensuel import dico_mois, renommerMois\n",
    "from Integration_nouveau_comptage import (localiser_comptage_a_inserer, ventilerParSectionHomogene, creer_comptage, structureBddOld2NewForm, creerCorrespComptag,\n",
    "                                          ventilerCompteurRefAssoc, ventilerCompteurIdComptagExistant, ventilerNouveauComptageRef, creerCompteur, corresp_nom_id_comptag,\n",
    "                                          creerComptageAssoc, creerCompteurAssoc, structureBddOld2NewFormAssoc, rassemblerNewCompteur, rassemblerNewComptage,\n",
    "                                          rassemblerIndics, classer_comptage_update_insert, hierarchisationCompteur, ventilerDoublons,\n",
    "                                          modifierVentilation, rangBddComptageAssoc)\n",
    "from Import_export_comptage import (recupererIdUniqComptage, comptag_existant_bdd, insererSchemaComptage, insererSchemaComptageAssoc, insert_bdd,\n",
    "                                    recupererIdUniqComptageAssoc)\n",
    "from Params.Bdd_OTV import (attBddCompteur, nomConnBddOtv, schemaComptage, schemaComptageAssoc, tableComptage, \n",
    "                            tableCompteur, tableIndicAgrege, tableIndicHoraire, tableIndicMensuel, tableCorrespIdComptag,\n",
    "                            tableEnumTypeVeh)\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from shapely.geometry import Point, LineString, MultiLineString\n",
    "from shapely import speedups\n",
    "speedups.disable()\n",
    "from shapely.ops import transform\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "# from Base_BdTopo import Import_outils as io\n",
    "# from Base_BdTopo import Rond_points as rp#from Base_BdTopo import Regroupement_correspondance as rc\n",
    "from sqlalchemy.schema import MetaData\n",
    "from sqlalchemy import inspect\n",
    "from statistics import mean\n",
    "from itertools import combinations\n",
    "from unidecode import unidecode\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import pyproj\n",
    "from shapely.ops import transform\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\" ></a>\n",
    "# ***CD 23***\n",
    "- Année 2019 : \n",
    "> ***attention : pour le point de comptage D941 6+152 à Aubusson, le pR est 32 et non 6. il faut donc corriger à la main le fihcier excel***\n",
    "<br> Pour le moment tous les points sont déjà dans  la base, dc pas de traitement de type insert prévus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiliser les données\n",
    "cd23 = it.Comptage_cd23(r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\CD23\\2019-CD23_trafics.xls',2019)\n",
    "df_propre = cd23.ouvrirMiseEnForme()\n",
    "cd23.classer_comptage_update_insert('gti_otv_pg11', 'na_2010_2019_p')\n",
    "cd23.update_bdd_23('gti_otv_pg11','comptage', 'na_2010_2019_p')\n",
    "cd23.donneesMens()\n",
    "cd23.insert_bdd('gti_otv_pg11','comptage', 'na_2010_2019_mensuel',cd23.df_attr_mensuel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\" ></a>\n",
    "# ***CD 40***\n",
    "> 2019 : envoi des données B152 de route +   \n",
    "2020 : envoi des données B153 de route +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019 : initialiser\n",
    "cd40 = it.Comptage_cd40(r'D:\\temp\\otv\\2019\\Donnees_source\\CD40\\Observatoire des trafics')\n",
    "# mettre enf orme\n",
    "cd40.comptage_forme()\n",
    "cd40.classer_comptage_insert_update('local_otv_station_gti', 'na_2010_2019_p', 'comptage')\n",
    "# transfert donnees_agregees\n",
    "cd40.update_bdd_40('local_otv_station_gti', 'comptage', 'na_2010_2019_p')\n",
    "# donnees_mensuelles\n",
    "# cd40.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_mensuel',cd40.df_attr_mens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020 : preparer\n",
    "cd40 = it.Comptage_cd40(r'C:\\Users\\martin.schoreisz\\Box\\Dossier_Perso\\OTV\\donnees_gestionnaires\\CD40\\en_cours\\donnees', donneesType='B153', annee='2020')\n",
    "cd40.comptage_forme()\n",
    "cd40.classer_comptage_insert_update('local_otv_boulot', 'compteur', 'comptage')\n",
    "# cd40.df_attr_update,cd40.df_attr_insert, cd40.df_attr_mens\n",
    "\n",
    "# mettre a jour \n",
    "# comptages\n",
    "dfComptage = cd40.creer_comptage(cd40.df_attr_update.id_comptag.tolist(), cd40.annee, 'tableur CD40', 'tv/pl', obs='fichier B153 route +')\n",
    "cd40.insert_bdd('local_otv_boulot', 'comptage', 'comptage', dfComptage)\n",
    "# indics_agreges\n",
    "dfIndicAgrege = cd40.structureBddOld2NewForm(cd40.df_attr_update, cd40.annee, ['id_comptag', 'annee', 'fichier'], ['tmja', 'pc_pl', 'tmje', 'tmjhe'], 'agrege')\n",
    "cd40.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege', dfIndicAgrege)\n",
    "# trafic mensuel\n",
    "dfIndicMensuel = cd40.structureBddOld2NewForm(cd40.df_attr_mens, cd40.annee, ['id_comptag', 'annee', 'fichier', 'donnees_type'], ['janv', 'fevr', 'mars', 'avri', 'mai', 'juin', 'juil', 'aout', 'sept',\n",
    "                                                                                                                                'octo', 'nove', 'dece'], 'mensuel')\n",
    "cd40.insert_bdd('local_otv_boulot', 'comptage', 'indic_mensuel', dfIndicMensuel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"3\" ></a>\n",
    "# ***CD17***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Année 2015 : traitée dans le fichier Import_trafics.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### année 2016 données issue des borchures de comptage, uniquemnet pour ponctuels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ouverture du fichier\n",
    "cpt17=it.Comptage_cd17(r'Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_produites\\donnnees_travail\\Comptage\\17\\cpt_pctuel_but_2016.txt',\n",
    "                       'brochure',2016)\n",
    "\n",
    "#mettre à jour les id_comptage deja presents (attention, update Bdd à changé, il faut passer par creer_valeur_txt_update avant et certains paramètres ont changé)\n",
    "cpt17.mises_forme_bdd('gti_otv', 'comptage', 'na_2010_2017_p', '17','ponctuel') #creer les attributs selon les donnees presentes dans la base\n",
    "cpt17.update_bdd('gti_otv', 'comptage', 'na_2010_2017_p')#mise à jour\n",
    "\n",
    "#creer referentiel si besoin\n",
    "with ct.ConnexionBdd('gti_otv') as c:\n",
    "    ct.ogr2ogr_shp2pg(c.connstringOgr, r'Y:\\REF_GEO\\BD_Topo\\D17\\ED16\\SHP\\1_DONNEES_LIVRAISON\\N_TRONCON_ROUTE_BDT_017.SHP',\n",
    "                     schema='referentiel',table='troncon_route_bdt17_ed16_l',geotype='MULTILINESTRING', dims=2, encodageClient='LATIN1' )\n",
    "#creer graph\n",
    "rqt=\"\"\"\n",
    "alter table referentiel.troncon_route_bdt17_ed16_l add column source integer , add column target integer ;\n",
    "select pgr_createTopology ('referentiel.troncon_route_bdt17_ed16_l',1,'geom', 'ogc_fid') ;\n",
    "ALTER TABLE referentiel.troncon_route_bdt17_ed16_l  RENAME COLUMN id TO id_ign;\n",
    "ALTER TABLE referentiel.troncon_route_bdt17_ed16_l  RENAME COLUMN ogc_fid TO id;\n",
    "alter table referentiel.troncon_route_bdt17_ed16_l add column long_km numeric ;\n",
    "update referentiel.troncon_route_bdt17_ed16_l set long_km=(st_length(geom)/1000) ;\n",
    "\"\"\"  # attention, il manque la ligne au dessus pour créer l'analyseGraph qui va renvoyer le nb de count\n",
    "with ct.ConnexionBdd('gti_otv') as c:\n",
    "    c.sqlAlchemyConn.execute(rqt)\n",
    "\n",
    "#inserer les nouveaux comptages\n",
    "with ct.ConnexionBdd('gti_otv') as c:\n",
    "    cpt17.df_attr_insert.to_sql('na_2010_2017_p',c.sqlAlchemyConn,schema='comptage',if_exists='append', index=False )\n",
    "\n",
    "#mettre à jour la geom \n",
    "rqt=\"\"\" update comptage.na_2010_2017_p\n",
    "  set geom=(select geom_out  from comptage.geoloc_pt_comptag(id_comptag))\n",
    "  where dep='17' and geom is null\n",
    "\"\"\"\n",
    "with ct.ConnexionBdd('gti_otv') as c:\n",
    "    c.sqlAlchemyConn.execute(rqt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### fichier compteurs permanents format csv annee 2017, 2018, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_perm=it.Comptage_cd17(r'D:\\Boulot\\AffairesEnCours\\OTV\\17\\csv perso pactol_2019_1.csv',\n",
    "                         'permanent_csv',2019)\n",
    "cpt_perm.mises_forme_bdd_brochure_pdf('local_otv_gti', 'comptage', 'na_2010_2019_p', '17','permanent', 'maison')\n",
    "#miettre à jour les données deja existantes\n",
    "cpt_perm.update_bdd_17('local_otv_gti', 'comptage', 'na_2010_2019_p')#mise à jour\n",
    "#inseérer les données nouvelles\n",
    "cpt_perm.insert_bdd('gti_otv', 'comptage', 'na_2010_2019_p')\n",
    "#mettre à jour la geom \n",
    "cpt_perm.maj_geom('gti_otv', 'comptage', 'na_2010_2019_p', '17')\n",
    "# pour les données mensuelles\n",
    "cpt_perm.insert_bdd_mens('local_otv_gti', 'comptage','na_2010_2019_mensuel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### annee 2018 ; fichier compteurs tournant format excel issu des donnees pour brochure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiliser la classe avec le fichier\n",
    "bdd='gti_otv_pg11'\n",
    "cpt_cd17=it.Comptage_cd17(r'Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD17\\Brochure 2018 CD17 DREAL\\10  5 1 B3 tournants recalculés.xls',\n",
    "                      'tournant_xls_bochure',2018)\n",
    "\n",
    "#mise en forme des données\n",
    "cpt_cd17.comptag_existant_bdd(bdd, 'na_2010_2018_p', dep='17')\n",
    "donnees=cpt_cd17.ouvrir_xls_tournant_brochure()\n",
    "cpt_cd17.conversion_id_comptg_existant_xls_brochure(bdd)\n",
    "cpt_cd17.carac_xls_brochure()\n",
    "\n",
    "#mise à jour des données\n",
    "val_txt=cpt_cd17.creer_valeur_txt_update(cpt_cd17.df_attr_update, ['id_comptag','tmja_2018','tmja_2017'])\n",
    "cpt_cd17.update_bdd(bdd, 'comptage', 'na_2010_2018_p', val_txt,{'tmja_2018':'tmja_2018','tmja_2017':'tmja_2017'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "> ### annee 2017-2018 ; fichier ponctuel excel qui alimente des brochures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ouvrir le fichier et initialisation\n",
    "cpt_pct2018_cd17=it.Comptage_cd17(r'Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD17\\Brochure 2018 CD17 DREAL\\spécifique Brochure V85_2018 .xls',\n",
    "                      'ponctuel_xls_bochure',2018)\n",
    "bdd='gti_otv_pg11'\n",
    "#mise en forme\n",
    "cpt_pct2018_cd17.comptag_existant_bdd(bdd, 'na_2010_2018_p', dep='17')\n",
    "cpt_pct2018_cd17.conversion_id_comptg_existant_xls_brochure(bdd)\n",
    "cpt_pct2018_cd17.filtrer_periode_ponctuels_xls_brochure()\n",
    "cpt_pct2018_cd17.carac_xls_brochure()\n",
    "\n",
    "#mise à jour des données\n",
    "val_txt=cpt_pct2018_cd17.creer_valeur_txt_update(cpt_pct2018_cd17.df_attr_update, ['id_comptag','tmja','pc_pl','obs'])\n",
    "cpt_pct2018_cd17.update_bdd(bdd, 'comptage', 'na_2010_2018_p', val_txt,{'tmja_2018':'tmja','pc_pl_2018':'pc_pl', 'obs_2018':'obs'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trouver les points de comptages a inserer situe sur le même troncon elementaires que d'autres points\n",
    "table_corresp=cpt_pct2018_cd17.correspondance_ancien_nouveau_comptage(bdd,'public','cd17_tournant_insert','lineaire.traf2016_bdt17_ed16_l',\n",
    "                                                    'public', 'traf2016_bdt17_ed16_l','traf2016_bdt17_ed16_l_vertices_pgr')\n",
    "\n",
    "# si le point fait partie de la table_corresp, on insère pas, sinon on insère\n",
    "pt_a_inserer=cpt_pct2018_cd17.df_attr_insert.loc[~cpt_pct2018_cd17.df_attr_insert.id_comptag.isin(table_corresp.id_comptag.tolist())].copy()\n",
    "# mise en form avant insertion\n",
    "pt_a_inserer['dep']='17'\n",
    "pt_a_inserer['route']=pt_a_inserer.id_comptag.apply(lambda x : x.split('-')[1])\n",
    "pt_a_inserer.rename(columns={'absc':'abs','tmja':'tmja_2018','pc_pl':'pc_pl_2018','obs':'obs_2018'},inplace=True)\n",
    "pt_a_inserer['reseau']='RD'\n",
    "pt_a_inserer['gestionnai']='CD17'\n",
    "pt_a_inserer['concession']='N'\n",
    "pt_a_inserer['type_poste']='ponctuel'\n",
    "pt_a_inserer=pt_a_inserer[['id_comptag','dep','route','pr','abs','reseau','gestionnai','concession','type_poste','tmja_2018','pc_pl_2018','obs_2018']].copy()\n",
    "# si plusieurs fois le mm point on garde la valeur max\n",
    "pt_a_inserer=pt_a_inserer.loc[pt_a_inserer.tmja_2018==pt_a_inserer.groupby('id_comptag').tmja_2018.transform(max)].copy()\n",
    "\n",
    "cpt_pct2018_cd17.insert_bdd(bdd, 'comptage', 'na_2010_2018_p', pt_a_inserer)\n",
    "cpt_pct2018_cd17.maj_geom(bdd, 'comptage', 'na_2010_2018_p', dep='17')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "> ### annee 2020 ; fichiers permanents et ponctuels csv\n",
    "en 2020, les identifiants des compteurs permanents ont été transférés dans le champs id_cpt de la table compteur.compteur. De fait, pour mettre à jour ces données ont peut s'appuyer sur une simple jointure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    ">> #### permanents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fichier = r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD17\\CSV Permanents.csv'\n",
    "cpt_perm = it.Comptage_cd17(fichier,'permanent_csv_formatTmjPl', 2020, skiprows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mise en forme et insertion dans la Bdd\n",
    "insererSchemaComptage(creer_comptage(df_attr.id_comptag.unique(), cpt_perm.annee, src, type_veh), 'comptage')\n",
    "insererSchemaComptage(recupererIdUniqComptage(df_attr)[['id_comptag_uniq', 'indicateur', 'valeur', 'fichier']], 'indicAgrege')\n",
    "insererSchemaComptage(structureBddOld2NewForm(df_attr.drop('valeur', axis=1), cpt_perm.annee, ['id_comptag', 'fichier', 'indicateur', 'annee'], dico_mois.keys(),\n",
    "                                              'mensuel'), 'indicMensuel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    ">> #### ponctuels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ouvertur et mise en forme du fichier\n",
    "fichier = r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD17\\CSV specifiques.csv'\n",
    "cpt_ponct = it.Comptage_cd17(fichier,'ponctuel_csv', 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classer selon les compteurs connus ou non (5 comptages updates, 261 comptages insert)\n",
    "df_attr_update, df_attr_insert = classer_comptage_update_insert(cpt_ponct.fichier_src, '17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geolocaliser les compteurs de façon auto\n",
    "points_a_inserer = localiser_comptage_a_inserer(df_attr_insert, 'public', 'cd17_ponctuels_2021', 'lineaire.traf2020_bdt_na_ed20_l', 'ref.pr_ed21_p')\n",
    "# ensuite on geolocalise de façon mano via Qgis quand c'est possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# et au final on ne prend que les points avec une géométrie et l'attribut \"MJA TV S3\" non null et sup 0\n",
    "with ct.ConnexionBdd('local_otv_boulot') as c:\n",
    "    df_attr_insertFinal = gp.read_postgis('select * from  public.cd17_ponctuels_2021', c.sqlAlchemyConn)\n",
    "    # cpt_ponct.fichier_src.to_sql('cd17_ponctuels_2021_2', c.sqlAlchemyConn, 'public')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ici il faut d'abord vérifier que les correspondance d'id_comptag ne cree pas de doublons. si c'est le cas on affecte des valeurs à la main\n",
    "ref, assoc = ventilerDoublons(df_attr_insertFinal)\n",
    "assoc['id_comptag'] = assoc.apply(lambda x: f\"17-{x.route}-{x.pr}+{x['abs']}\", axis=1)\n",
    "assoc['id_comptag_ref'] = '17-D137-43+600'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ct.ConnexionBdd(nomConnBddOtv) as c:\n",
    "    df_attr_insertFinal.loc[(~df_attr_insertFinal.nom.isin(assoc.nom.tolist())) & (~df_attr_insertFinal.geom.isna())].to_postgis(\n",
    "        'cd17_ponctuels_2021_2', c.sqlAlchemyConn, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traitement, sur la base du CD24\n",
    "cptSansGeom, ppvHorsSectHomo, cptSimpleSectHomo, cptMultiSectHomo = ventilerParSectionHomogene('cd17_ponctuels_2021_2', 'linauto.traf2020_bdt_na_ed20_simpli_l', '17', 15)\n",
    "cptRefMultiSectHomo, cptAssocMultiSectHomo = ventilerCompteurRefAssoc(cptMultiSectHomo)\n",
    "cptRefSectHomoNew, cptRefSectHomoOld = ventilerCompteurIdComptagExistant(cptSimpleSectHomo, cptRefMultiSectHomo)\n",
    "dfCorrespIdComptag, dfCreationComptageAssocie, dfModifTypePoste, dfCreationCompteur = ventilerNouveauComptageRef(cptRefSectHomoOld, 'type_poste',\n",
    "                                                                                                                 'type_poste_bdd', 'periode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export pour vérif\n",
    "gp.GeoDataFrame(dfCorrespIdComptag[['id_comptag', 'id_comptag_bdd', 'geom_x', 'type_poste', 'tmja', 'periode']].drop('geom_y', axis=1, errors='ignore'), geometry='geom_x', crs=2154\n",
    "                ).to_file(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD17\\verifCorrespIdComptage.shp')\n",
    "gp.GeoDataFrame(dfCreationComptageAssocie[['id_comptag', 'id_comptag_bdd', 'geom_x', 'type_poste', 'tmja', 'periode']].drop('geom_y', axis=1, errors='ignore'), geometry='geom_x', crs=2154\n",
    "                ).to_file(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD17\\creationComptageAssoc.shp')\n",
    "gp.GeoDataFrame(cptRefSectHomoNew[['id_comptag', 'geom_x', 'type_poste', 'tmja', 'id_comptag_bdd', 'periode']].drop('geom_y', axis=1, errors='ignore'), geometry='geom_x', crs=2154\n",
    "                ).to_file(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD17\\NewCompteur.shp')\n",
    "gp.GeoDataFrame(cptAssocMultiSectHomo[['id_comptag', 'geom_x', 'type_poste', 'tmja', 'id_comptag_bdd', 'periode']].drop('geom_y', axis=1, errors='ignore'), geometry='geom_x', crs=2154\n",
    "                ).to_file(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD17\\comptageAssocInterneNewData.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifs manuelle via Qgis : on cherche la mauvais classification des données dans les différentes variables\n",
    "listCompteurAForcer = ['17-D203E3-2+970']\n",
    "cptAForcer = cptRefSectHomoOld.loc[cptRefSectHomoOld.id_comptag.isin(listCompteurAForcer)]\n",
    "# attention, si des compteurs sont à forcer, il faut aussi penser à revoir l'attachement des comptages associés, qui peuvent devenir associés à eux aussi plutot qu'à ceux\n",
    "# de la bdd\n",
    "dicoAssociationForcee = {'17-D203E3-2+970': ['17-D203E3-2+670']}\n",
    "# forcer les associations\n",
    "cptAssocMultiSectHomo.loc[cptAssocMultiSectHomo.apply(lambda x: x.id_comptag in [e for f in dicoAssociationForcee.values() for e in f], axis=1),\n",
    "                          'id_comptag_bdd'] = cptAssocMultiSectHomo.loc[cptAssocMultiSectHomo.apply(lambda x: x.id_comptag in [\n",
    "    e for f in dicoAssociationForcee.values() for e in f], axis=1)].apply(lambda x: [k for k, v in dicoAssociationForcee.items() if x.id_comptag in v][0], axis=1)\n",
    "\n",
    "# listes de passage entre la correspondance d'id_comptage vers les comptages accosies, ou autres transformations\n",
    "listeDepuisCorrespVersAssocies = ['17-D119-36+340', '17-D119-36+580', '17-D216E1-3+480', '17-D122-33+200', '17-D140-4+350', '17-D244-5+050',\n",
    "                                  '17-D245-3+250', '17-D2-17+710', '17-D233-2+700', '17-D107-65+350']\n",
    "listeDepuisAssociesVersCorresp = ['17-D122-31+550', '17-D117-62+180', '17-D117-62+000', '17-D216-34+870', '17-D248-16+800', '17-D248-17+000', '17-D125-45+140',\n",
    "                                  '17-D119E3-7+810', '17-D24-15+240', '17-D120-21+500', '17-D123-20+020']\n",
    "dicoDepuisNewCompteurVersAssocies = {'17-D25-38+020': '17-D25-37+400', '17-D134-42+260': '17-D134-42+530'}  # clé = comptassocié, value = compteur ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nouvelle répartition suite aux vérifs manuelles\n",
    "(dfCreationComptageAssocie_MaJMano, dfCorrespIdComptag_MajMano,\n",
    " cptAssocMultiSectHomo_MajMano, cptRefSectHomoNew_MajMano) = modifierVentilationComptageAssocies(dfCorrespIdComptag, cptRefSectHomoNew, dfCreationComptageAssocie,\n",
    "                                                                                                 cptAssocMultiSectHomo,\n",
    "                                                                                                 listeDepuisAssociesVersCorresp,\n",
    "                                                                                                 listeDepuisCorrespVersAssocies,\n",
    "                                                                                                 dicoDepuisNewCompteurVersAssocies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si besoin nouvel export pour vérif\n",
    "gp.GeoDataFrame(dfCorrespIdComptag_MajMano[['id_comptag', 'id_comptag_bdd', 'geom_x', 'type_poste', 'tmja', 'periode']].drop('geom_y', axis=1, errors='ignore'), geometry='geom_x', crs=2154\n",
    "                ).to_file(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD17\\verifCorrespIdComptage_MaJ.shp')\n",
    "gp.GeoDataFrame(dfCreationComptageAssocie_MaJMano[['id_comptag', 'id_comptag_bdd', 'geom_x', 'type_poste', 'tmja', 'periode']].drop('geom_y', axis=1, errors='ignore'), geometry='geom_x', crs=2154\n",
    "                ).to_file(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD17\\creationComptageAssoc_MaJ.shp')\n",
    "gp.GeoDataFrame(cptRefSectHomoNew_MajMano[['id_comptag', 'geom_x', 'type_poste', 'tmja', 'id_comptag_bdd', 'periode']].drop('geom_y', axis=1, errors='ignore'), geometry='geom_x', crs=2154\n",
    "                ).to_file(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD17\\NewCompteur_MaJ.shp')\n",
    "gp.GeoDataFrame(cptAssocMultiSectHomo_MajMano[['id_comptag', 'geom_x', 'type_poste', 'tmja', 'id_comptag_bdd', 'periode']].drop('geom_y', axis=1, errors='ignore'), geometry='geom_x', crs=2154\n",
    "                ).to_file(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD17\\comptageAssocInterneNewData_MaJ.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mise en forme des données\n",
    "# correspondance des comptages\n",
    "dfCorrespFinale = creerCorrespComptag(dfCorrespIdComptag_MajMano, 'id_comptag', 'id_comptag_bdd', listCompteurAForcer)\n",
    "dfCorrespIdComptag_MajManoFinale = dfCorrespIdComptag_MajMano.loc[~dfCorrespIdComptag_MajMano.id_comptag.isin(listCompteurAForcer)].assign(id_comptag=dfCorrespIdComptag_MajMano.id_comptag_bdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserer les nouveaux compteurs\n",
    "dfNewCompteurInsert = rassemblerNewCompteur('17', 'RD', 'CD17', False, 'pr+abs_gestionnaire', 'double sens', \n",
    "                                            (cptRefSectHomoNew_MajMano.rename(columns={'nom': 'id_cpt'}), 'geom_x'),\n",
    "                                            (cptAForcer.rename(columns={'nom': 'id_cpt'}), 'geom_x'))\n",
    "insererSchemaComptage(dfNewCompteurInsert, 'compteur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserer les nouveaux comptages\n",
    "dfComptageNewTot = rassemblerNewComptage('2020', 'tv/pl',\n",
    "                                         df_attr_update, \n",
    "                                         cptRefSectHomoNew_MajMano, \n",
    "                                         cptAForcer,\n",
    "                                         dfCorrespIdComptag_MajMano.loc[~dfCorrespIdComptag_MajMano.id_comptag.isin(listCompteurAForcer)\n",
    "                                                                       ].assign(id_comptag=dfCorrespIdComptag_MajMano.id_comptag_bdd))\n",
    "# verif que tous les nouveaux compteurs inseres precedemment on bien un comptage qui suit\n",
    "if not dfNewCompteurInsert.loc[~dfNewCompteurInsert.id_comptag.isin(dfComptageNewTot.id_comptag.tolist())].empty:\n",
    "    raise ValueError(\"Certains compteurs précédemment insérés n'ont pas de comptages associes. Sur de continuer ?\")\n",
    "# attention au doublons suite à la prise en compte des corespondaces entre id_comptag juste au dessus. \n",
    "dfCorrespIdComptag_MajManoFinale.loc[dfCorrespIdComptag_MajManoFinale.duplicated('id_comptag')]\n",
    "dfComptageNewTot.loc[dfComptageNewTot.duplicated('id_comptag', keep=False)]\n",
    "# traiatements manuels : on vire le comptage '17-D129-70+360' de df_attr_update car sur un seul jour, \n",
    "df_attr_update.drop(df_attr_update.loc[df_attr_update.id_comptag == '17-D129-70+360'].index, inplace=True)\n",
    "# puis on limite la df concernée\n",
    "dicoRefAssoc = {'D117 PR 61+840 PO1- MESCHERS/GIRONDE' : ['D117 PR 62+000 PO2- MESCHERS/GIRONDE', 'D117 PR 62+180 PO3- MESCHERS/GIRONDE'], \n",
    "                'D125 PR 44+900- PESSINES': ['D125 PR 45+140', ],\n",
    "                'D248 PR 16+630- ST SIMON DE PELLOUAILLE': ['D248 PR 17+000- ST SIMON DE PELLOUAILLE','D248 PR 16+800- ST SIMON DE PELLOUAILLE' ]}\n",
    "assoc2 = dfCorrespIdComptag_MajMano.loc[dfCorrespIdComptag_MajMano.nom.isin([e for f in dicoRefAssoc.values() for e in f])].copy()\n",
    "assoc2['id_comptag_ref'] = assoc2.id_comptag_bdd\n",
    "dfCorrespIdComptag_MajMano_ssDbl = dfCorrespIdComptag_MajMano.loc[~dfCorrespIdComptag_MajMano.nom.isin([e for f in dicoRefAssoc.values() for e in f])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on reprend pour l'insertion des comptages\n",
    "dfComptageNewTot_final = rassemblerNewComptage('2020', 'tv/pl',\n",
    "                                         df_attr_update, \n",
    "                                         cptRefSectHomoNew_MajMano, \n",
    "                                         cptAForcer,\n",
    "                                         dfCorrespIdComptag_MajMano_ssDbl.loc[~dfCorrespIdComptag_MajMano_ssDbl.id_comptag.isin(listCompteurAForcer)\n",
    "                                                                       ].assign(id_comptag=dfCorrespIdComptag_MajMano_ssDbl.id_comptag_bdd))\n",
    "# verif que tous les nouveaux compteurs inseres precedemment on bien un comptage qui suit\n",
    "if not dfNewCompteurInsert.loc[~dfNewCompteurInsert.id_comptag.isin(dfComptageNewTot_final.id_comptag.tolist())].empty:\n",
    "    raise ValueError(\"Certains compteurs précédemment insérés n'ont pas de comptages associes. Sur de continuer ?\")\n",
    "# insertion \n",
    "insererSchemaComptage(dfComptageNewTot_final, 'comptage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserer les nouveaux indicateurs\n",
    "dfIndicAgregeNew, dfIndicMensNew, dfIndicHoraireNew = rassemblerIndics('2020', dfComptageNewTot_final, pd.concat(\n",
    "    [df_attr_update, cptRefSectHomoNew_MajMano, dfCorrespIdComptag_MajMano_ssDbl.loc[~dfCorrespIdComptag_MajMano_ssDbl.id_comptag.isin(listCompteurAForcer)]\n",
    "     .assign(id_comptag=dfCorrespIdComptag_MajMano_ssDbl.id_comptag_bdd), cptAForcer]))\n",
    "insererSchemaComptage(dfIndicMensNew, 'indicAgrege')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPTAGES ASSOCIES\n",
    "# iil va falloir reprendre les variables assoc et assoc2, creer au fur et a mesures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agregation des donnees de comptages associes\n",
    "dfAssocAgglomeree = pd.concat([assoc.assign(dfSrc='assoc'), assoc2.assign(dfSrc='assoc2'),\n",
    "                               dfCreationComptageAssocie_MaJMano.assign(dfSrc='dfCreationComptageAssocie_MaJMano'),\n",
    "                               cptAssocMultiSectHomo_MajMano.assign(dfSrc='cptAssocMultiSectHomo_MajMano')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajout d'un attributt de referencement final et remplissage\n",
    "# dans le cas ou les deux source de référencement sont non null et non cohérente : dans ce cas comme ici on a que du ponctuel, si le comptage de référence en bdd \n",
    "# n'est pas ponctuel, on garde ce comptage, sinon on prend le comptage de référence interne des données gestionnaire\n",
    "dfAssocAgglomeree.loc[\n",
    "    (dfAssocAgglomeree.id_comptag_bdd != dfAssocAgglomeree.id_comptag_ref) & (~dfAssocAgglomeree.id_comptag_bdd.isna()) & \n",
    "    (~dfAssocAgglomeree.id_comptag_ref.isna()), 'id_comptag_ref_final'] = dfAssocAgglomeree.loc[(dfAssocAgglomeree.id_comptag_bdd != dfAssocAgglomeree.id_comptag_ref) & \n",
    "    (~dfAssocAgglomeree.id_comptag_bdd.isna()) & (~dfAssocAgglomeree.id_comptag_ref.isna()\n",
    "    )].apply(lambda x: x.id_comptag_bdd if x.type_poste_bdd != 'ponctuel' else x.id_comptag_ref, axis=1)\n",
    "# dans le cas ou l'un ou l'autre des données est nulle (on a vérifié avant que les deux ne sont pas nulles ensemble), on garde celle qui ne l'est pas\n",
    "dfAssocAgglomeree.loc[(dfAssocAgglomeree.id_comptag_bdd.isna()) | (dfAssocAgglomeree.id_comptag_ref.isna()), 'id_comptag_ref_final'] = dfAssocAgglomeree.loc[\n",
    "    (dfAssocAgglomeree.id_comptag_bdd.isna()) | (dfAssocAgglomeree.id_comptag_ref.isna())].apply(lambda x: x.id_comptag_bdd if not pd.isnull(x.id_comptag_bdd) \n",
    "                                                                                             else x.id_comptag_ref, axis=1)\n",
    "# dans le cas ou les deux sont égale on prend n'importe laquelle\n",
    "dfAssocAgglomeree.loc[dfAssocAgglomeree.id_comptag_bdd == dfAssocAgglomeree.id_comptag_ref, 'id_comptag_ref_final'\n",
    "                     ] = dfAssocAgglomeree.loc[dfAssocAgglomeree.id_comptag_bdd == dfAssocAgglomeree.id_comptag_ref].id_comptag_bdd\n",
    "# verif\n",
    "if not dfAssocAgglomeree.loc[dfAssocAgglomeree.id_comptag_ref_final.isna()].empty:\n",
    "    raise ValueError(\"il reste des comptages sans compteur de référence\")\n",
    "# et on applique la correspondance d'id_comptag pour les compteurs concernés\n",
    "dfAssocAgglomeree.loc[dfAssocAgglomeree.id_comptag_ref_final.isin(dfCorrespFinale.id_gest.tolist()), 'id_comptag_ref_final'\n",
    "                     ] = dfAssocAgglomeree.loc[dfAssocAgglomeree.id_comptag_ref_final.isin(dfCorrespFinale.id_gest.tolist())\n",
    "                                              ].id_comptag_ref_final.replace({v['id_gest']: v['id_gti'] for v in dfCorrespFinale.to_dict(orient='index').values()})\n",
    "# ensuite on filtre avec les comptages qui eteait identifies comme associes, mais que l'on a creer (car ponctuels Vs ponctuels on prend les nouveaux comme ref)\n",
    "comptagesACreer = ['17-D112-27+430', '17-D127-26+060', '17-D131-20+540', '17-D137-43+600', '17-D137-69+080', '17-D140-4+350', '17-D150-5+670', '17-D244-5+050', '17-D733E2-0+380']\n",
    "dfAssocAgglomeree_final = dfAssocAgglomeree.loc[~dfAssocAgglomeree.id_comptag.isin(comptagesACreer)].reset_index().drop(['level_0', 'index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "# certains comptages ponctuelles doivent etre creer car ils remplacent comptges ponctuels exisants qui vont passer en  associés\n",
    "comptageACreer = dfAssocAgglomeree.loc[~dfAssocAgglomeree.id_comptag_ref_final.isin(corresIdComptagInterne.id_comptag.tolist())][['id_comptag', 'id_comptag_bdd', 'id_comptag_ref', 'type_poste_bdd',\n",
    "                                                                                        'id_comptag_ref_final', 'dfSrc']].id_comptag_ref_final.tolist()\n",
    "comptagAtransfererComptagAssoc = dfAssocAgglomeree.loc[~dfAssocAgglomeree.id_comptag_ref_final.isin(corresIdComptagInterne.id_comptag.tolist())][['id_comptag', 'id_comptag_bdd', 'id_comptag_ref', 'type_poste_bdd',\n",
    "                                                                                        'id_comptag_ref_final', 'dfSrc']].id_comptag_bdd.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on créé les comptages a ajouter\n",
    "insererSchemaComptage(\n",
    "rassemblerNewCompteur('17', 'RD', 'CD17', False, 'pr+abs_gestionnaire', 'double sens', \n",
    "                                            (dfAssocAgglomeree.loc[dfAssocAgglomeree.id_comptag.isin(comptageACreer)].rename(columns={'nom': 'id_cpt'}).drop(108)\n",
    "                                             , 'geom_x')), 'compteur')\n",
    "# dfAssocAgglomeree.loc[dfAssocAgglomeree.id_comptag.isin(comptageACreer)]\n",
    "# [['id_comptag', 'id_comptag_bdd', 'id_comptag_ref', 'id_comptag_ref_final', 'type_poste_bdd','dfSrc']]\n",
    "rassemblerNewComptage('2020', 'tv/pl', df_attr_update,\n",
    "                                         dfAssocAgglomeree.loc[dfAssocAgglomeree.id_comptag.isin(comptageACreer)].drop(108))\n",
    "insererSchemaComptage(structureBddOld2NewForm(dfAssocAgglomeree.loc[dfAssocAgglomeree.id_comptag.isin(comptageACreer)].drop(108)\n",
    "                        , '2020', ['id_comptag', 'fichier', 'annee'],\n",
    "                        ['tmja', 'pc_pl'], 'agrege'), 'indicAgrege')\n",
    "structureBddOld2NewForm(dfAssocAgglomeree.loc[dfAssocAgglomeree.id_comptag.isin(comptageACreer)].drop(108)\n",
    "                        , '2020', ['id_comptag', 'fichier', 'annee'],\n",
    "                        ['tmja', 'pc_pl'], 'agrege')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mettre en forme les comptages associes issue du processus d'identifiaction\n",
    "dfIds, tableComptageAssoc = creerComptageAssoc(dfAssocAgglomeree_final.assign(\n",
    "    type_veh='tv/pl', src_geo='pr+abs_gestionnaire', convention=lambda x: dfAssocAgglomeree_final.type_poste.apply(lambda x: True if x == 'permanent' else False),\n",
    "    sens_cpt='double sens', src_cpt=lambda x: dfAssocAgglomeree_final.type_poste.apply(\n",
    "        lambda x: 'convention gestionnaire'if x == 'permanent' else 'gestionnaire'), \n",
    "    id_comptag = dfAssocAgglomeree_final.apply(lambda x: f\"17-{x.route}-{x.pr}+{x['abs']}\", axis=1)),\n",
    "                   'id_comptag_ref_final', '2020', 'id_comptag', src='donnees_xls_sources', listIdCptExclu=listCompteurAForcer)\n",
    "# Mettre en forme les compteurs associes relatifs aux comptages associes\n",
    "tableCompteurAssoc = creerCompteurAssoc(gp.GeoDataFrame(dfIds.drop('geom', axis=1), geometry='geom_x', crs=2154).rename(\n",
    "    columns={'absc': 'abs'}), 'id_cpteur_asso', 'geom_x', 'id_comptag_ref_final', listCompteurAForcer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pb de doublons\n",
    "comptagAssoc = tableComptageAssoc.drop_duplicates(['id_cpteur_asso','periode','src', 'type_veh', 'id_cptag_ref', 'obs']).sort_values('id_cpteur_asso')\n",
    "compteurAssoc = tableCompteurAssoc.drop_duplicates()\n",
    "# insertion\n",
    "insererSchemaComptageAssoc(compteurAssoc, 'compteur')\n",
    "insererSchemaComptageAssoc(comptagAssoc, 'comptage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mise en forme indicateurs\n",
    "dfAssocIndicAgrege = dfAssocAgglomeree_final.assign(id_comptag=dfAssocAgglomeree_final.apply(lambda x: f\"17-{x.route}-{x.pr}+{x['abs']}\", axis=1)\n",
    "                                                   ).merge(comptagAssoc[['id_cpteur_asso', 'id_cptag_ref']], left_on='id_comptag', right_on='id_cpteur_asso', how='right')\n",
    "dfAssocIndicAgregeidForm = structureBddOld2NewFormAssoc(dfAssocIndicAgrege, '2020', \n",
    "                                                  ['id_cptag_ref', 'annee', 'fichier', 'id_cpteur_asso'], ['tmja', 'pc_pl'], 'agrege')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insertion\n",
    "insererSchemaComptageAssoc(dfAssocIndicAgregeidForm.drop('id_cpteur_asso', axis=1), 'indicAgrege')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAConvertir = dfAssocIndicAgrege\n",
    "listAttrFixe = ['id_cptag_ref', 'annee', 'fichier', 'id_cpteur_asso']\n",
    "listAttrIndics = ['tmja', 'pc_pl']\n",
    "dfIndic = pd.melt(dfAConvertir.assign(annee=dfAConvertir.annee.astype(str)), id_vars=listAttrFixe, value_vars=listAttrIndics, \n",
    "                              var_name='indicateur', value_name='valeur')\n",
    "#columns = [c for c in ['id_cptag_ref', 'indicateur', 'valeur', 'fichier', 'obs', 'annee'] if c in dfIndic.columns]\n",
    "#dfIndic = dfIndic[columns].rename(columns={'id':'id_comptag_uniq'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passage des ancins compteurs ponctuels de réfé&rence en compteurs associes via la fonction comptage.transfert_comptage_assoc() dans postgres\n",
    "set(comptagAtransfererComptagAssoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***CD19***\n",
    "> 2019 : creation de la classe Comptage_cd19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\" ></a>\n",
    "# ***CD64***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init\n",
    "fichier=r'C:\\Users\\martin.schoreisz\\Box\\Dossier_Perso\\OTV\\donnees_gestionnaires\\CD64\\en_cours\\Copie de SIG TV PL %PL TOURNANTS + PERMANENTS 2020.xlsx'\n",
    "cd64=it.Comptage_cd64(fichier, '2020')\n",
    "cd64.miseEnForme()\n",
    "cd64.classer_comptage_insert_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verfier les correspondances\n",
    "#verifieles geometries a insrere\n",
    "#calcul auto des geometries et verif Qgis\n",
    "gdfInsert=cd64.localiser_comptage_a_inserer(cd64.df_attr_insert, 'local_otv_boulot', 'public', 'localiser_pt_cd64', \n",
    "                                            'ref.troncon_route_bdt_na_ed20_l', 'ref.pr_ed18_p')\n",
    "#gdfInsert.to_file(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\verif_pt_cd64.shp')\n",
    "#reprendre le fichier corrige via Qgis\n",
    "gdfInsertCorrigee=gp.read_file(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\verif_pt_cd64.shp')\n",
    "dicoCoresp={'64-D10-3+0':'64-D10-3+400','64-D4-25+0':'64-D4-25+500', '64-D+6-8+130':'64-D55-2+535', '64-D6-2+335':'64-D6-0+250'}\n",
    "cd64.verifComptageInsert(dicoCoresp,gdfInsertCorrigee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#mise à jour des données déjà présentes : \n",
    "#mise a jour de obs_supl\n",
    "cd64.update_bdd('comptage', 'compteur', cd64.creer_valeur_txt_update(cd64.df_attr_update, ['id_comptag', 'obs_supl']), {'obs_supl':'obs_supl'})\n",
    "#insere les nouveaux comptages, mettre à jour les anciens\n",
    "#séparer les comptages deja existants et les nouveaux\n",
    "bdd='local_otv_boulot'\n",
    "with ct.ConnexionBdd(bdd) as c  :\n",
    "    comptagesExistant=pd.read_sql('select ca.* from comptage.comptage ca join comptage.compteur ce on ca.id_comptag=ce.id_comptag where ce.dep=\\'64\\'', c.sqlAlchemyConn)\n",
    "dfJointureBddCd64=cd64.df_attr_update.assign(annee=cd64.df_attr_update.annee.astype(str)).merge(comptagesExistant[['id','id_comptag', 'annee']], how='left', on=['id_comptag', 'annee'])\n",
    "dfComptagesExistants=dfJointureBddCd64.loc[~dfJointureBddCd64.id.isna()]\n",
    "dfComptagesNew=dfJointureBddCd64.loc[dfJointureBddCd64.id.isna()]\n",
    "#mise à jour des existants\n",
    "#comptage\n",
    "cd64.update_bdd('comptage', 'comptage', cd64.creer_valeur_txt_update(dfComptagesExistants[['id']].assign(src='tableur CD64'), ['id', 'src']),\n",
    "                {'src':'src'}, identifiant='id')\n",
    "#tmja\n",
    "cd64.update_bdd('comptage', 'indic_agrege', cd64.creer_valeur_txt_update(dfComptagesExistants.assign(id_comptag_uniq=dfComptagesExistants.id)\n",
    "                                                                         , ['id_comptag_uniq', 'tmja']), {'valeur':'tmja'}, identifiant='id_comptag_uniq',\n",
    "                filtre = \"indicateur='tmja'\")\n",
    "#pc_pl\n",
    "cd64.update_bdd('comptage', 'indic_agrege', cd64.creer_valeur_txt_update(dfComptagesExistants.assign(id_comptag_uniq=dfComptagesExistants.id)\n",
    "                                                                         , ['id_comptag_uniq', 'pc_pl']), {'valeur':'pc_pl'}, identifiant='id_comptag_uniq',\n",
    "                filtre = \"indicateur='pc_pl'\")\n",
    "\n",
    "#insertion des nouveaux\n",
    "for a in dfComptagesNew.annee.unique() : \n",
    "    dfComptage=cd64.creer_comptage(dfComptagesNew.loc[dfComptagesNew.annee==a].id_comptag.tolist(), a, 'tableur CD64','tv/pl')\n",
    "    cd64.insert_bdd('local_otv_boulot', 'comptage', 'comptage', dfComptage)\n",
    "    dfIndicAgrege=cd64.structureBddOld2NewForm(dfComptagesNew.loc[dfComptagesNew.annee==a], a,\n",
    "                                               ['id_comptag', 'annee', 'fichier'],['tmja', 'pc_pl'], 'agrege')\n",
    "    cd64.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege', dfIndicAgrege)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# ***CD47***\n",
    "> Annee des trafics 2018, fichiers : Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD47\\comptages_CD47_2018\\COMPTAGES 2018\n",
    "les fichiers sont decomposes en permanents tournants temporaires, il faut recomposer les donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialiser un objet\n",
    "cpt47=it.Comptage_cd47(r'Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD47\\comptages_CD47_2018\\COMPTAGES 2018','TRAFICS PERMANENTS')\n",
    "# calculer les attributs de comptages : df_attr, df_attr_insert et df_attr_update, en prenant en compte les comptages existants\n",
    "cpt47.classer_comptage_update_insert('gti_otv_pg11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mise à jour des données déjà présentes dansla base\n",
    "val_txt=cpt47.creer_valeur_txt_update(cpt47.df_attr_update, ['id_comptag','tmja','pc_pl'])\n",
    "cpt47.update_bdd(bdd, 'comptage', 'na_2010_2018_p', val_txt,{'tmja_2018':'tmja','pc_pl_2018':'pc_pl'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traitement des données non présentes (df_attr_insert)\n",
    "# recherche de correspondance pour les permanents et tournants\n",
    "dico_corresp=cpt47.corresp_old_new_comptag('gti_otv_pg11', 'public','cpt47_temp','lineaire.traf2017_bdt47_ed17_l',\n",
    "                            'referentiel', 'troncon_route_bdt47_ed17_l','troncon_route_bdt47_ed17_l_vertices_pgr','id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtre des données df_attr_insert selon l'id_comptag present dans le dico_corresp\n",
    "cpt47.df_attr_insert=cpt47.df_attr_insert.loc[~cpt47.df_attr_insert.id_comptag.isin(df_correspondance.id_comptag.to_list())].copy()\n",
    "# POUR INFO, l'id_comptag présent dan sle dico_corresp a été transférer à la main dans l table comptage.corresp_id_comptag\n",
    "# mettre en forme les attributs avant insert\n",
    "cpt47.mise_en_forme_insert('2018')\n",
    "# inserer les donnes dans la table\n",
    "cpt47.insert_bdd('gti_otv_pg11', 'comptage', 'na_2010_2018_p', cpt47.df_attr_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mettre à jour la géométrie\n",
    "cpt47.maj_geom('gti_otv_pg11', 'comptage', 'na_2010_2018_p', '47')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **2019**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt47 = it.Comptage_cd47(r'D:\\temp\\otv\\2019\\Donnees_source\\CD47','TRAFICS PERIODIQUES',2019)\n",
    "# calculer les attributs de comptages : df_attr, df_attr_insert et df_attr_update, en prenant en compte les comptages existants, mais ans recherche des équivalences avec les anciens comptage snon recensées\n",
    "cpt47.classer_comptage_update_insert('local_otv_station_gti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qq points tournants non connus\n",
    "cpt47.df_attr_insert.loc[cpt47.df_attr_insert['type_poste'].isin(['permanent','tournant'])]\n",
    "# filtrer les 2 points bizarres\n",
    "cpt47.df_attr = cpt47.df_attr.loc[cpt47.df_attr.id_comptag.apply(lambda x : x[:4]=='47-D')].copy()\n",
    "cpt47.df_attr_insert = cpt47.df_attr_insert.loc[cpt47.df_attr_insert.id_comptag.apply(lambda x : x[:4]=='47-D')].copy()\n",
    "cpt47.df_attr_update = cpt47.df_attr_update.loc[cpt47.df_attr_update.id_comptag.apply(lambda x : x[:4]=='47-D')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtention dico de correspondance\n",
    "dico_corresp = cpt47.corresp_old_new_comptag('local_otv_station_gti', 'public', 'cpt47_temp', 'referentiel.troncon_route_bdt47_ed17_l',\n",
    "                                             'referentiel', 'troncon_route_bdt47_ed17_l', 'troncon_route_bdt47_ed17_l_vertices_pgr', 'id')\n",
    "# insertion dans bdd\n",
    "cpt47.insert_bdd('local_otv_station_gti', 'comptage', 'corresp_id_comptag', dico_corresp[['id_comptag', 'id_comptag_lin']\n",
    "                                                                                         ].rename(columns={'id_comptag': 'id_gest', 'id_comptag_lin': 'id_gti'}))\n",
    "# calcul nouveau id_comptag\n",
    "cpt47.comptag_existant_bdd('local_otv_station_gti', schema='comptage', table='na_2010_2019_p', dep='47', type_poste=False)\n",
    "cpt47.corresp_nom_id_comptag('local_otv_station_gti', cpt47.df_attr)\n",
    "cpt47.df_attr_update = cpt47.df_attr.loc[cpt47.df_attr.id_comptag.isin(cpt47.existant.id_comptag.tolist())].copy()\n",
    "cpt47.df_attr_insert = cpt47.df_attr.loc[~cpt47.df_attr.id_comptag.isin(cpt47.existant.id_comptag.tolist())].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mise a jour\n",
    "cpt47.update_bdd_47('local_otv_station_gti', 'comptage', 'na_2010_2019_p', cpt47.df_attr_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# donnees a inserer\n",
    "cpt47.mise_en_forme_insert()\n",
    "cpt47.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_p', cpt47.df_attr_insert)\n",
    "cpt47.maj_geom('local_otv_station_gti', 'comptage', 'na_2010_2019_p', '47')\n",
    "cpt47.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_mensuel', cpt47.df_attr_mens)\n",
    "cpt47.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_horaire', cpt47.df_attr_horaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **2020**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt47 = it.Comptage_cd47(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD47\\en_cours', 'TRAFICS PERMANENTS', 2020)\n",
    "dep = '47'\n",
    "reseau = 'RD'\n",
    "gestionnai = 'CD47'\n",
    "concession = 'N'\n",
    "src_geo = 'pr+abs_gestionnaire'\n",
    "type_veh = 'vl/pl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ### calculer les attributs de comptages : df_attr, df_attr_insert et df_attr_update, en prenant en compte les comptages existants, mais sans recherche des équivalences avec les anciens comptage snon recensées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['type_veh', '0_1h', '1_2h', '2_3h', '3_4h', '4_5h', '5_6h', '6_7h',\n",
      "       '7_8h', '8_9h', '9_10h', '10_11h', '11_12h', '12_13h', '13_14h',\n",
      "       '14_15h', '15_16h', '16_17h', '17_18h', '18_19h', '19_20h', '20_21h',\n",
      "       '21_22h', '22_23h', '23_24h', 'fichier', 'id_comptag'],\n",
      "      dtype='object')\n",
      "Index(['type_veh', 'h0_1', 'h1_2', 'h2_3', 'h3_4', 'h4_5', 'h5_6', 'h6_7',\n",
      "       'h7_8', 'h8_9', 'h9_10', 'h10_11', 'h11_12', 'h12_13', 'h13_14',\n",
      "       'h14_15', 'h15_16', 'h16_17', 'h17_18', 'h18_19', 'h19_20', 'h20_21',\n",
      "       'h21_22', 'h22_23', 'h23_24', 'fichier', 'id_comptag'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cpt47.classer_comptage_update_insert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ### géolocaliser les nouveaux comptages que l'on doit ventiler dans les différents cas (creer compteur, creer comptages associes, creer corresp_id_comptag, modif type de poste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = localiser_comptage_a_inserer(cpt47.df_attr_insert.drop(['mensuel'], axis=1), 'public', 'cd47_2020', 'lineaire.traf2020_bdt_na_ed20_l', 'ref.pr_ed18_p' )\n",
    "with ct.ConnexionBdd(nomConnBddOtv) as c:\n",
    "    df.to_sql('cd47_2020', c.sqlAlchemyConn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ### 1ere ventilation entre les grandes familles de nouveaux points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "cptSansGeom, ppvHorsSectHomo, cptSimpleSectHomo, cptMultiSectHomo = ventilerParSectionHomogene('cd47_2020', 'linauto.traf2020_bdt_na_ed20_simpli_l', '47')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ### Choix d'un comptage de référence pour les points a plusieurs sur la même section homogene de trafic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cptRefMultiSectHomo, cptAssocMultiSectHomo = ventilerCompteurRefAssoc(cptMultiSectHomo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    ">> ### 2eme ventilation : separation des compteurs de reference selon la presence ou non d'identifiant de comptage sur la section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cptRefSectHomoNew, cptRefSectHomoOld = ventilerCompteurIdComptagExistant(cptSimpleSectHomo, cptRefMultiSectHomo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    ">> ### 3eme ventilation : separation des compteurs de reference situes sur un section homogene de trafic avec id_comptag vers les 3 classes finales : compteur a creer, comptage associe ou correspondance 'id_comptag'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCorrespIdComptag, dfCreationComptageAssocie, dfModifTypePoste = ventilerNouveauComptageRef(cptRefSectHomoOld, 'type_poste', 'type_poste_bdd', 'periode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    ">> ### vérification manuelle de l'étape précédente, création de compteur à forcer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse de la table de correspiIdComptag\n",
    "# export pour vérif\n",
    "gp.GeoDataFrame(dfCorrespIdComptag.drop('geom_y', axis=1), geometry='geom_x', crs=2154\n",
    "                ).to_file(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD47\\verifCorrespIdComptage2.shp')\n",
    "# analyse de la table de dfCreationComptageAssocie\n",
    "# export pour vérif\n",
    "gp.GeoDataFrame(dfCreationComptageAssocie.drop('geom_y', axis=1), geometry='geom_x', crs=2154\n",
    "                ).to_file(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD47\\verifComptagesAssoc2.shp')\n",
    "# analyse des modifs de type de poste : -> null\n",
    "dfModifTypePoste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# après verif manuelle, les compteurs suivants ne sont ni des correspondance d'id_comtage, ni des comptage associé, ni des modif de type de poste, \n",
    "# mais bien de nouveau compteurs\n",
    "listCompteurAForcer = ['47-D211-8+0', '47-D276-10+905', '47-D124-0+315']\n",
    "cptAForcer = cptRefSectHomoOld.loc[cptRefSectHomoOld.id_comptag.isin(listCompteurAForcer)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    ">> ### création et insertion des nouveaux compteurs\n",
    ">> ils ont issus des compteurs sans geom, des compteurs eloignes du réferentiel, des compteurs situe sur des sections homogènes sans id_comptag existants et des compteur a creer après analyse visuelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# il faut passer les compteurs sans geom de façon différentes, car pb de driver geopandas\n",
    "listCpteurNew = []\n",
    "for c in ((ppvHorsSectHomo.assign(src_geo='pr+abs_gestionnaire'), 'geom'),\n",
    "          (cptAForcer.assign(src_geo='pr+abs_gestionnaire'), 'geom_x'), (cptRefSectHomoNew.assign(src_geo='pr+abs_gestionnaire'), 'geom_x')):\n",
    "        c[0]['src_cpt'] = c[0].type_poste.apply(lambda x: 'convention_gestionnaire' if x == 'permanent' else 'gestionnaire')\n",
    "        c[0]['convention'] = c[0].type_poste.apply(lambda x: True if x == 'permanent' else False)\n",
    "        c[0]['sens_cpt'] = 'double sens'\n",
    "        listCpteurNew.append(creerCompteur(c[0], c[1], dep, reseau, gestionnai, concession))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCompteurNewAvecGeo = pd.concat(listCpteurNew)\n",
    "dfCompteurNewSansGeo = creerCompteur(\n",
    "    cptSansGeom.assign(src_geo=None,\n",
    "                       src_cpt=cptSansGeom.type_poste.apply(lambda x: 'convention_gestionnaire' if x == 'permanent' else 'gestionnaire'),\n",
    "                       convention=cptSansGeom.type_poste.apply(lambda x: True if x == 'permanent' else False),\n",
    "                       sens_cpt='double sens',\n",
    "                       geom=Point()),\n",
    "    'geom', dep, reseau, gestionnai, concession)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# insertion théorique : Pb d'insertion à traiter, notamment pour les compteurs sans geom, d'où la solution en dessous\n",
    "insererSchemaComptage(dfCompteurNewSansGeo, 'compteur')\n",
    "dfCompteurNewSansGeo.drop('geom', axis=1).to_csv(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD47\\Cpteur_geom_vide.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    ">> ### création et insertion des nouveaux comptages\n",
    ">> ils ont issus des mêmes tables que les compteurs, mais ne prennent pas les mêmes colonnes. il faut aussi ajouter tous les comptages issus de compteurs déja dans la base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour la partie des nouveaux compteurs\n",
    "dfComptageNew = pd.concat([cptAForcer, cptRefSectHomoNew, ppvHorsSectHomo, dfCompteurNewSansGeo])[['id_comptag', 'src', 'periode']].assign(annee=cpt47.annee)\n",
    "# association avec la partie des compteurs deja connus\n",
    "dfComptageNewTot = pd.concat([creer_comptage(dfComptageNew.id_comptag.tolist(), cpt47.annee, dfComptageNew.src, type_veh, periode=dfComptageNew.periode),\n",
    "                             creer_comptage(cpt47.df_attr_update.id_comptag.tolist(), cpt47.annee, cpt47.df_attr_update.src.tolist(), \n",
    "                                            type_veh, periode=cpt47.df_attr_update.periode.tolist())])\n",
    "# insertion\n",
    "insererSchemaComptage(creer_comptage(dfComptageNewTot.id_comptag.tolist(), cpt47.annee, dfComptageNewTot.src, type_veh, periode=dfComptageNewTot.periode), 'comptage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    ">> ### création et insertion des nouveaux indicateurs\n",
    ">> les indicateurs agrégés sont issus des mêmes tables que les compteurs, mais ne prennent pas les mêmes colonnes. les indics mensuel et horaires sont a rechercher depuis les donnees sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "listIdComptagIndicNew = dfComptageNew.id_comptag.tolist() + cpt47.df_attr_update.id_comptag.tolist()\n",
    "dfAttrIndicAgregeNew = cpt47.df_attr.loc[cpt47.df_attr.id_comptag.isin(listIdComptagIndicNew)]\n",
    "dfAttrIndicMensNew = cpt47.df_attr_mens.loc[cpt47.df_attr_mens.id_comptag.isin(listIdComptagIndicNew)]\n",
    "dfAttrIndicHoraireNew = cpt47.df_attr_horaire.loc[cpt47.df_attr_horaire.id_comptag.isin(listIdComptagIndicNew)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfIndicAgregeNew = structureBddOld2NewForm(dfAttrIndicAgregeNew.assign(annee=cpt47.annee), cpt47.annee, ['id_comptag', 'annee', 'fichier'], ['tmja', 'pc_pl'], 'agrege')\n",
    "dfIndicMensNew = structureBddOld2NewForm(dfAttrIndicMensNew.assign(annee=cpt47.annee), cpt47.annee, ['id_comptag', 'annee', 'fichier', 'donnees_type'], \n",
    "                                          list(dico_mois.keys()), 'mensuel')\n",
    "dfIndicHoraireNew = structureBddOld2NewForm(dfAttrIndicHoraireNew.assign(annee=str(cpt47.annee)), '2020', ['id_comptag', 'annee'], ['tata'], 'horaire')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "insererSchemaComptage(dfIndicAgregeNew, 'indicAgrege')\n",
    "insererSchemaComptage(dfIndicMensNew, 'indicMensuel')\n",
    "insererSchemaComptage(dfIndicHoraireNew, 'indicHoraire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    ">> ### insertion des comptages issus de nouvelles correspondance d'identifiants de comptage\n",
    ">> ces données sont issus des compteurs de références situé sur une section à id_comptag existant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mis en forme et insertion des correspondance dans la base\n",
    "correspIdComptag = creerCorrespComptag(dfCorrespIdComptag, 'id_comptag', 'id_comptag_bdd', listCompteurAForcer)\n",
    "insert_bdd(schemaComptage, tableCorrespIdComptag, correspIdComptag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection des donnees, mise en form de l'id_comptag et insertion\n",
    "dfComptagCorrsp = cpt47.df_attr.loc[cpt47.df_attr.id_comptag.isin(correspIdComptag.id_gest.tolist())].copy()\n",
    "corresp_nom_id_comptag(dfComptagCorrsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "# il est possible qu'une correspondance d'id_comptag concerne un point qui est également mis à jour dans la même annee. Dans ce cas, on ne met pas a jour le trafic\n",
    "# on enleve le poin des données a chercher\n",
    "cptExistant = recupererIdUniqComptage(dfComptagCorrsp, True)\n",
    "jointure = dfComptagCorrsp.assign(annee=str(cpt47.annee)).merge(cptExistant, how='left', on=['id_comptag', 'annee'])\n",
    "dfComptagCorrspFiltre = dfComptagCorrsp.loc[dfComptagCorrsp.id_comptag.isin(jointure.loc[jointure.id_comptag_uniq.isna()].id_comptag.tolist())].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insertion des comptages\n",
    "insererSchemaComptage(creer_comptage(dfComptagCorrspFiltre.id_comptag.tolist(), cpt47.annee, dfComptagCorrspFiltre.src, type_veh, periode=dfComptagCorrspFiltre.periode), 'comptage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trouver et inserer les indicateurs\n",
    "dfIndicAgregeidGest = cpt47.df_attr.loc[cpt47.df_attr.id_comptag.isin(correspIdComptag.drop(61).id_gest.tolist())].copy()\n",
    "dfIndicMensidGest = cpt47.df_attr_mens.loc[cpt47.df_attr_mens.id_comptag.isin(correspIdComptag.drop(61).id_gest.tolist())].copy()  # tous des ponctuels donc vide\n",
    "dfIndicHoraireidGest = cpt47.df_attr_horaire.loc[cpt47.df_attr_horaire.id_comptag.isin(correspIdComptag.drop(61).id_gest.tolist())].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "corresp_nom_id_comptag(dfIndicAgregeidGest)\n",
    "corresp_nom_id_comptag(dfIndicMensidGest)\n",
    "corresp_nom_id_comptag(dfIndicHoraireidGest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfIndicAgregeidGestForm = structureBddOld2NewForm(dfIndicAgregeidGest.assign(annee=cpt47.annee), cpt47.annee, \n",
    "                                                  ['id_comptag', 'annee', 'fichier'], ['tmja', 'pc_pl'], 'agrege')\n",
    "if not dfIndicMensidGest.empty:\n",
    "    dfIndicMensidGestForm = structureBddOld2NewForm(dfIndicMensidGest.assign(annee=cpt47.annee), cpt47.annee, ['id_comptag', 'annee', 'fichier', 'donnees_type'],\n",
    "                                                    list(dico_mois.keys()), 'mensuel')\n",
    "dfIndicHoraireidGestForm = structureBddOld2NewForm(dfIndicHoraireidGest.assign(annee=str(cpt47.annee)), '2020', ['id_comptag', 'annee'], ['tata'], 'horaire')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "insererSchemaComptage(dfIndicAgregeidGestForm, 'indicAgrege')\n",
    "if not dfIndicMensidGest.empty:\n",
    "    insererSchemaComptage(dfIndicMensidGestForm, 'indicMensuel')\n",
    "insererSchemaComptage(dfIndicHoraireidGestForm, 'indicHoraire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    ">> ### création et insertion des comptages et compteurs associés\n",
    ">> les comptages assocés sont défini dans le traitementsdes points nouveau avec multiple points sur une section, et dans le traitemnets des points nouveaux sur une section existante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'id_cpteur_asso', 'tmja', 'pc_pl', 'type_poste', 'periode',\n",
      "       'pr', 'absc', 'route', 'fichier', 'src', 'geom_x', 'gid',\n",
      "       'id_comptag_bdd', 'type_poste_bdd', 'geom_y', 'st_distance',\n",
      "       'note_hierarchise', 'type_veh', 'src_geo', 'convention', 'sens_cpt',\n",
      "       'src_cpt', 'id_comptag', 'id_cptag_ref', 'annee', 'rang_bdd', 'rang_df',\n",
      "       'rang'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Mettre en forme les comptages associes issue du processus d'identifiaction\n",
    "dfIds, tableComptageAssoc = creerComptageAssoc(dfCreationComptageAssocie.assign(\n",
    "    type_veh='vl/pl', src_geo='pr+abs_gestionnaire', convention=lambda x: dfCreationComptageAssocie.type_poste.apply(lambda x: True if x == 'permanent' else False),\n",
    "    sens_cpt='double sens', src_cpt=lambda x: dfCreationComptageAssocie.type_poste.apply(\n",
    "        lambda x: 'convention gestionnaire'if x == 'permanent' else 'gestionnaire')),\n",
    "                   'id_comptag_bdd', '2020', 'id_comptag', src='donnees_xls_sources', listIdCptExclu=listCompteurAForcer)\n",
    "# Mettre en forme les compteurs associes relatifs aux comptages associes\n",
    "tableCompteurAssoc = creerCompteurAssoc(gp.GeoDataFrame(dfIds, geometry='geom_x', crs=2154).rename(\n",
    "    columns={'absc': 'abs'}), 'id_cpteur_asso', 'geom_x', 'id_comptag_bdd', listCompteurAForcer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "insererSchemaComptageAssoc(tableCompteurAssoc, 'compteur')\n",
    "insererSchemaComptageAssoc(tableComptageAssoc, 'comptage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    ">> ### création et insertion des indicateurs des comptages et compteurs associés\n",
    ">> on va simplement reprendre les donnees depuis le stockage, comme pour les autres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "# il n'y a pas de données mensuelle de comptages Associes\n",
    "dfAssocIndicAgrege = cpt47.df_attr.merge(tableComptageAssoc[['id_cpteur_asso', 'id_cptag_ref']], left_on='id_comptag', right_on='id_cpteur_asso', how='right')\n",
    "dfAssocIndicHoraire = cpt47.df_attr_horaire.merge(tableComptageAssoc[['id_cpteur_asso', 'id_cptag_ref']], left_on='id_comptag', right_on='id_cpteur_asso', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAssocIndicAgregeidForm = structureBddOld2NewFormAssoc(dfAssocIndicAgrege.assign(annee=cpt47.annee), cpt47.annee, \n",
    "                                                  ['id_cptag_ref', 'annee', 'fichier'], ['tmja', 'pc_pl'], 'agrege')\n",
    "dfAssocIndicHoraireidForm = structureBddOld2NewFormAssoc(dfAssocIndicHoraire.assign(annee=str(cpt47.annee)), '2020', ['id_cptag_ref', 'annee'], ['tata'], 'horaire')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "insererSchemaComptageAssoc(dfAssocIndicAgregeidForm, 'indicAgrege')\n",
    "insererSchemaComptageAssoc(dfAssocIndicHoraireidForm, 'indicHoraire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# ***CD87***\n",
    "> Dans ce Departement les donnees sont fournies en fichiers .fim. il vaut recalculer les valeusr de comptages <br> Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD87\\Fichiers FIM 87 -2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***lister les voies, classer les types de commptages, lister les fichiers a regrouper***\n",
    "> le dossier contient un tres grand nombre de fihciers, parfois ils sont a regrouper, parfois la structure de nommage varie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d87 = it.Comptage_cd87(r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\CD87\\CD87- Comptages 2019 Fichiers .fim','2019') \n",
    "d87.dico_pt_cptg() #creer le dico de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d87.dico_voie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Traiter les donnees***\n",
    "> Pour chaque route référencée dans le dico, on va calculer les TMJA %PL, date_debut, date_fin, type_poste de chaque fichiers puis\n",
    "faire les calculs si necessaires (moyenne si plsr fichiers).<br> ensuite on classe puis update et insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mettre à jour le dico et le transformer en dataframe sans les ponctuels pendant les grandes vacances\n",
    "d87.dataframe_dico_glob()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparer les données\n",
    "#attention cela comprend un script d'identification des points pas forcément nécéssaire\n",
    "d87.classer_comptage_update_insert('gti_otv_pg11','na_2010_2019_p','comptage',\n",
    "                                   'public','d87_cpt_temp','lineaire.traf2018_bdt87_ed18_l',\n",
    "                                  'ref', 'troncon_route_bdt87_ed18_l','troncon_route_bdt87_ed18_l_vertices_pgr','id','ref.pr_ed18_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mettre à jour les données\n",
    "d87.update_bdd_d87('gti_otv_pg11','na_2010_2019_p','comptage')\n",
    "#insérer les données et mettre à jour les geom\n",
    "d87.insert_bdd_d87('gti_otv_pg11','na_2010_2019_p','comptage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Outils.CopierFichierDepuisArborescence(r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\CD87\\Permanents 2019\\2019',\n",
    "                                      r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\CD87\\Permanents 2019\\tousFichiersVrac',\n",
    "                                      '.fim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d87=it.Comptage_cd87(r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\CD87\\Permanents 2019\\tousFichiersVrac','2019') \n",
    "d87.dico_pt_cptg() #creer le dico de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d87.df_attr.sort_values('id_comptag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"11\" ></a>\n",
    "# ***CD 16***\n",
    "- Année 2018 : \n",
    "> à partir du fichier D:\\temp\\otv\\Donnees_source\\CD16\\B15_2018.xlsx on traite les permanents.<br> à partir des donnees sur PIGMA on traite les compteurs temporaires <br>***attention : il y a aussi des données de comptages temporaires en FIM qui permettront d'obtenir de la données horaires***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2018\n",
    "cd16=it.Comptage_cd16(r'D:\\temp\\otv\\Donnees_source\\CD16\\B15_2018.xlsx',r'D:\\temp\\otv\\Donnees_source\\CD16\\pigma\\comptages_routiers_2019\\comptages_routiers.shp',\n",
    "                      r'D:\\temp\\otv\\Donnees_source\\CD16\\pigma\\position_compteurs_2019\\position_compteurs.shp',2018)\n",
    "cd16.comptage_forme()\n",
    "cd16.classer_comptage_update_insert('local_otv', 'na_2010_2018_p')\n",
    "\n",
    "cd16.classer_comptage_update_insert('local_otv', 'na_2010_2018_p')\n",
    "\n",
    "cd16.update_bdd_16('local_otv','comptage','na_2010_2018_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019\n",
    "cd16 = it.Comptage_cd16(r'D:\\temp\\otv\\2019\\Donnees_source\\CD16\\B15_2019.xlsx', r'D:\\temp\\otv\\2019\\Donnees_source\\CD16\\SIG_Comptages_CD16\\Comptages_routiers.shp',\n",
    "                        r'D:\\temp\\otv\\2019\\Donnees_source\\CD16\\SIG_Comptages_CD16\\Position_compteurs.shp',2019)\n",
    "cpt_a_ignorer = ('16-D731-27+45','16-D910-23+821', '16-D1000-16+35')\n",
    "cd16.comptage_forme(7,('16-D731-27+45','16-D910-23+821', '16-D1000-16+35'),r'D:\\temp\\otv\\2019\\Donnees_source\\CD16\\Comptages_secondaires_CD16_2019')\n",
    "cd16.classer_comptage_update_insert('local_otv_station_gti', 'na_2010_2019_p')\n",
    "# cd16.update_bdd_16('local_otv_station_gti','comptage', 'na_2010_2019_p')\n",
    "# cd16.insert_bdd('local_otv_station_gti','comptage','na_2010_2019_mensuel',cd16.df_attr_mens)\n",
    "# cd16.insert_bdd('local_otv_station_gti','comptage','na_2010_2019_horaire',cd16.df_attr_horaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Année 2020 : \n",
    "> récupération des données horaires à partir du format IRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd16 = it.Comptage_cd16(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD16\\en_cours\\B15_2020.pdf','toto', 'tata', '2020',\n",
    "                        r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD16\\en_cours\\CD16_IRIS_TV',\n",
    "                        r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD16\\en_cours\\CD16_IRIS_PL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# réation des données Horaires completes\n",
    "dataHoraireCompelete = cd16.creerDTtjoursttIndicIris()\n",
    "\n",
    "# filtre des jours non conforme\n",
    "dfHoraireFichierFiltre, dfJourIdcptARetirer = verifValiditeFichier(dataHoraireCompelete, 24)\n",
    "\n",
    "# verif sur la concordance des 2 sens de circulation\n",
    "comparer2Sens(dfHoraireFichierFiltre, attributSens='sens' )[1]\n",
    "\n",
    "# concatener les deux sens\n",
    "dfHoraireConcat = concatIndicateurFichierHoraire(dfHoraireFichierFiltre,\n",
    "                                                 'indicateur')\n",
    "\n",
    "# calcul des TMJAs\n",
    "indic_agrege = tmjaDepuisHoraire(dfHoraireConcat.assign(annee=cd16.annee))\n",
    "\n",
    "# calcul du mensuel\n",
    "tmjMens = mensuelDepuisHoraire(dfHoraireConcat.assign(annee=cd16.annee))\n",
    "tmjMens = tmjMens.loc[~tmjMens.valeur.isna()].copy()\n",
    "\n",
    "# verif que tous les id_comptag existent deja en bdd\n",
    "dfIdsConnus, dfIdsInconnus = cd16.scinderComptagExistant(indic_agrege,\n",
    "                                                         '2020',\n",
    "                                                         dep='16')\n",
    "dfIdsInconnus.empty\n",
    "\n",
    "# insertion des donnees de comptage\n",
    "cd16.insererComptage(dfIdsConnus.drop_duplicates(['id_comptag', 'annee'])[[\n",
    "    'id_comptag', 'annee']].assign(src='donnees horaire IRIS', type_veh='tv/pl'))\n",
    "\n",
    "# insertion des données agrege\n",
    "cd16.insererAgrege(indic_agrege.merge(\n",
    "    cd16.recupererIdUniqComptage(indic_agrege.id_comptag.tolist(), '2020')\n",
    "    ).assign(obs='calcule depuis donnees horaire IRIS'\n",
    "    ).merge(dfHoraireConcat[['id_comptag', 'fichier']].drop_duplicates(['id_comptag', 'fichier']).sort_values('id_comptag').groupby('id_comptag').agg(\n",
    "     {'fichier' : lambda x : ','.join(x)}), on='id_comptag').drop(['id_comptag', 'annee'], axis=1))\n",
    "\n",
    "# insertion des données mensuelles\n",
    "cd16.insererMensuel(tmjMens.merge(\n",
    "    cd16.recupererIdUniqComptage(indic_agrege.id_comptag.tolist(), '2020')\n",
    "    ).merge(dfHoraireConcat[['id_comptag', 'fichier']].drop_duplicates(['id_comptag', 'fichier']).sort_values('id_comptag').groupby('id_comptag').agg(\n",
    "     {'fichier' : lambda x : ','.join(x)}), on='id_comptag').drop(['id_comptag', 'annee'], axis=1))\n",
    "\n",
    "#insertion des données hoarires\n",
    "cd16.insererHoraire(dfHoraireConcat.merge(\n",
    "    cd16.recupererIdUniqComptage(indic_agrege.id_comptag.tolist(), '2020'), on='id_comptag').drop(['mois', 'annee_x', 'annee_y', 'id_comptag'], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> récupération des données de compmtages temporaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd16 = it.Comptage_cd16(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD16\\en_cours\\B15_2020.pdf',\n",
    "                        r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD16\\historique\\2019\\SIG_Comptages_CD16\\Comptages_routiers.shp',\n",
    "                        r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD16\\historique\\2019\\SIG_Comptages_CD16\\Position_compteurs.shp',\n",
    "                        '2020',\n",
    "                        r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD16\\en_cours\\CD16_IRIS_TV',\n",
    "                        r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD16\\en_cours\\CD16_IRIS_PL',\n",
    "                        r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD16\\en_cours\\CD16_Temporaires')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recupération des données PIGMA et mise en forme des données horaire\n",
    "donnees_tmp_filtrees = cd16.cpt_tmp_pigma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creer et mettre en forme les donnees horaires, et les données de comptage\n",
    "cd16.donnees_horaires(donnees_tmp_filtrees)\n",
    "dfComptag = cd16.df_attr_horaire[['id_comptag', 'qualite', 'periode', 'sens_cpt']].drop_duplicates().assign(annee=cd16.annee)\n",
    "dfComptag = dfComptag.groupby(['id_comptag','sens_cpt', 'annee']).agg({'qualite': min, 'periode': lambda x : ' ; '.join(list(x))}).reset_index()\n",
    "cd16.corresp_nom_id_comptag(dfComptag)\n",
    "cd16.df_attr_horaire = concatIndicateurFichierHoraire(cd16.df_attr_horaire, attributIndicateur='indicateur')\n",
    "dfIndicAgrege = tmjaDepuisHoraire(cd16.df_attr_horaire.assign(annee=cd16.annee))\n",
    "dfIndicAgrege = dfIndicAgrege.merge(cd16.df_attr_horaire[['id_comptag', 'fichier']].drop_duplicates(['id_comptag', 'fichier']), on='id_comptag'\n",
    "                        ).groupby(['id_comptag','indicateur', 'annee', 'valeur']).agg({'fichier': lambda x : ' ; '.join(list(x))}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insertion des données \n",
    "cd16.insererComptage(cd16.creer_comptage(dfComptag.id_comptag.tolist(),'2020', 'gestionnaire', obs='fichiers FIM', periode=dfComptag.periode, type_veh='vl/pl'))\n",
    "cd16.insererAgrege(cd16.recupererIdUniqComptage(dfIndicAgrege).drop(['id_comptag', 'annee'], axis=1))\n",
    "cd16.insererHoraire(cd16.recupererIdUniqComptage(cd16.df_attr_horaire.assign(annee='2020')).drop(['id_comptag', 'annee'], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***CD 86***\n",
    "Attention , dans ce département parfois ce sont les données en PLOD et ASCD qui sont ok, parfois c'est le cumulD <br>\n",
    "Dans ce Dept, les Compmtages dites 'Secondaires' sont équivalent à 'tournants', et 'Tournants' equivalent à 'ponctuel'\n",
    "- Année 2018 : \n",
    "> à partir des fichier D:\\temp\\otv\\Donnees_source\\CD86\\comptages permanents 2018.xlsx et  D:\\temp\\otv\\Donnees_source\\CD86\\Postes secondaires 2018.xls on traite les permanents et secondaires <br> il y a un petit pb sur les compteurs permanents entre la donnees pr+abs chez nous et la leur dans le tableau, donc il faut la premiere fois tout passer dans la table de correspondance.<br> dans ce dept pas de nouveau points\n",
    "- Année 2019 : \n",
    "> un seul fichier avec les comptages sur 2feuilles : permanents et tournants.<br> la feuille permanent contient aussi des données 'Tournant' qui sont masquées, pour lesquelles les reference en abscisse sont tuojours à 0<br> 3 nouveaux points tournants ajoutés à  la main, le reste des ponctuels en auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2018\n",
    "cd86=it.Comptage_cd86(r'D:\\temp\\otv\\Donnees_source\\CD86\\comptages permanents 2018.xlsx',r'D:\\temp\\otv\\Donnees_source\\CD86\\Postes secondaires 2018.xls')\n",
    "\n",
    "#si besoin de dico corresp : \n",
    "corr=cd86.corresp_perm('local_otv', 'na_2010_2018_p')\n",
    "cd86.insert_bdd('local_otv', 'comptage','corresp_id_comptag',corr)\n",
    "\n",
    "#sinon\n",
    "cd86.comptage_forme()\n",
    "cd86.classer_comptage_update_insert('local_otv', 'na_2010_2018_p')\n",
    "cd86.update_bdd_86('local_otv','comptage','na_2010_2018_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2019\n",
    "cd86=it.Comptage_cd86(r'D:\\temp\\otv\\2019\\Donnees_source\\CD86\\Comptages globaux 2019 tournants et permanents.xlsx',r'D:\\temp\\otv\\2019\\Donnees_source\\CD86\\Comptages globaux 2019 tournants et permanents.xlsx',2019,\n",
    "                     'permanents','secondaires')\n",
    "cd86.comptage_forme('local_otv_station_gti', 'na_2010_2019_p')\n",
    "cd86.classer_comptage_update_insert('local_otv_station_gti', 'na_2010_2019_p')\n",
    "cd86.update_bdd_86('local_otv_station_gti','comptage','na_2010_2019_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd86.classer_comptage_update_insert('local_otv_station_gti', 'na_2010_2019_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd86.df_attr_insert['dep']='86'\n",
    "cd86.df_attr_insert['reseau']='RD'\n",
    "cd86.df_attr_insert['gestionnai']='CD86'\n",
    "cd86.df_attr_insert['concession']='N'\n",
    "cd86.df_attr_insert['obs']=\"nouveau_point 2019, denomination CD86='tournant'\"\n",
    "cd86.df_attr_insert.rename(columns={'absc' : 'abs', 'tmja':'tmja_'+str(cd86.annee),'pc_pl':'pc_pl_'+str(cd86.annee),'obs':'obs_'+str(cd86.annee), 'src':'src_'+str(cd86.annee)},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd86.insert_bdd_86('local_otv_station_gti', 'comptage','na_2010_2019_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ct.ConnexionBdd('local_otv_gti', localisation='maison') as c : \n",
    "    ct.ogr2ogr_csv2pg(c.connstringOgr, r'F:\\Boulot\\otv\\corresp_id_comptag.csv',schema='public', table='corr_id',encodageClient='UTF-8', headers='YES')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ***CD 24***\n",
    "- Année 2018 : \n",
    "> à partir des fichier D:\\temp\\otv\\Donnees_source\\CD24\\2018_CD24_trafic.csv <br> il n'y a que les compteurs permanents.<br> **Données Mensuelles dispos**.<br> Pensez que des céhanges ont ue lieu pour récupérer tous les points de comptages (perm, tourn, ponct). <br> ***Gros pb de geooloc des PR ign***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Données: PENSER A RECUPERER LE TMJE ET TMJHE AVEC LES PC_PL_E ET PC_PL_HE associés.</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Année 2019 : \n",
    ">à partir du fichier Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\CD24\n",
    "que les compteurs permanents et tournants.\n",
    "**a voir pour les ponctuels, possibilité aussi de récupérer des données à partirde leur Web SIG : https://dordogne.maps.arcgis.com/apps/MapTools/index.html?appid=34558f68af514a63b6b7426ed77d055f en scrolant et enregistrant les différents fichiers html**. ensuite pandas a une fonction read_html qu el'on applique sur des slices du fichiers html (car la fonction renvoi tout les elements dans des slices diffrentes : ligne du tableau, carte, etc...)<br> IL POURRAIT ETRE INTERESSANT DE METTRE A JOUR LES DONNEES DE GEOM SI BESOIN AVCE LES LONG/LAT issues du fichier source du CD24 quand c'est possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd24 = it.Comptage_cd24(r'D:\\Boulot\\AffairesEnCours\\OTV\\24_donnees_sources\\EXPORT SIG COMPTAGES CD24.csv',2019) \n",
    "cd24.comptage_forme()\n",
    "cd24.classer_comptage_update_insert('local_otv_gti', 'na_2010_2019_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd24.update_bdd_24('local_otv_gti', 'comptage', 'na_2010_2019_p')\n",
    "cd24.insert_bdd('local_otv_gti', 'comptage', 'na_2010_2019_p', cd24.df_attr_insert)\n",
    "cd24.insert_bdd('local_otv_gti', 'comptage', 'na_2010_2019_mensuel', cd24.df_attr_mens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Année 2020 : \n",
    "> on ne traite que les permanents et tournants fournis par le CD  \n",
    "***EN 2021 PEnSEZ a TENTER DE RECUPERER AUSSI LES PONTCUELS, COMME DRECIT AU CHAPITRE 2019***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd24 = it.Comptage_cd24(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD24\\PERMANENT-TOURNANT_2020.csv',2020) \n",
    "cd24.comptage_forme()\n",
    "cd24.classer_comptage_update_insert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ici il faut d'abord vérifier que les correspondance d'id_comptag ne cree pas de doublons.\n",
    "doublonsNatifs = cd24.df_attr_update.loc[cd24.df_attr_update.duplicated('id_comptag', keep=False)]\n",
    "if not doublonsNatifs.empty:  # si c'est le cas, il faut néttoyer la donnees et creer des comptages associés (a reprendre en natif dans les fonctions)\n",
    "    ref, assoc = ventilerCompteurRefAssoc(cd24.df_attr_update.loc[cd24.df_attr_update.duplicated('id_comptag', keep=False)].assign(\n",
    "        id_comptag2=cd24.df_attr_update.loc[cd24.df_attr_update.duplicated('id_comptag', keep=False)].id_comptag).rename(columns={'id_comptag2': 'gid'}))\n",
    "assoc['id_comptag'] = assoc.apply(lambda x: f\"24-{x.route}-{x.pr}+{x['abs']}\", axis=1)\n",
    "assoc['id_comptag_ref'] = assoc.id_comptag_ref.apply(lambda x: x if x != '24-D674-9+220' else '24-D674-11+0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traitemnet des geom a la main (seuelment 4 incoonues das les insert) et insertion des points dans bdd\n",
    "with ct.ConnexionBdd(nomConnBddOtv) as c:\n",
    "    cd24.df_attr_insert.to_postgis('cd24_2020', c.sqlAlchemyConn, if_exists = 'replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traitement, sur la base du CD47\n",
    "cptSansGeom, ppvHorsSectHomo, cptSimpleSectHomo, cptMultiSectHomo = ventilerParSectionHomogene('cd24_2020', 'linauto.traf2020_bdt_na_ed20_simpli_l', '24', 15)\n",
    "cptRefMultiSectHomo, cptAssocMultiSectHomo = ventilerCompteurRefAssoc(cptMultiSectHomo)\n",
    "cptRefSectHomoNew, cptRefSectHomoOld = ventilerCompteurIdComptagExistant(cptSimpleSectHomo, cptRefMultiSectHomo)\n",
    "dfCorrespIdComptag, dfCreationComptageAssocie, dfModifTypePoste, dfCreationCompteur = ventilerNouveauComptageRef(cptRefSectHomoOld, 'type_poste',\n",
    "                                                                                                                 'type_poste_bdd', 'periode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export pour vérif\n",
    "gp.GeoDataFrame(dfCorrespIdComptag.drop('geom_y', axis=1), geometry='geom_x', crs=2154\n",
    "                ).to_file(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD24\\verifCorrespIdComptage.shp')\n",
    "gp.GeoDataFrame(dfModifTypePoste.drop('geom_y', axis=1), geometry='geom_x', crs=2154\n",
    "                ).to_file(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD24\\modfiTypePoste.shp')\n",
    "gp.GeoDataFrame(dfCreationCompteur.drop('geom_y', axis=1), geometry='geom_x', crs=2154\n",
    "                ).to_file(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD24\\creationCompteur.shp')\n",
    "gp.GeoDataFrame(cptRefSectHomoNew.drop('geom_y', axis=1), geometry='geom_x', crs=2154\n",
    "                ).to_file(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD24\\NewCompteur.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# après verif manuelle, les compteurs suivants ne sont ni des correspondance d'id_comtage, ni des comptage associé, ni des modif de type de poste,\n",
    "# mais bien de nouveau compteurs\n",
    "listCompteurAForcer = ['24-D57-0+500', '24-D6089-60+675']\n",
    "cptAForcer = cptRefSectHomoOld.loc[cptRefSectHomoOld.id_comptag.isin(listCompteurAForcer)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\"><b>ATTENTION : LA CORRESPONDANCE d'ID_COMPTAGE n'EST PAS REALISEE. IL FAUDRA LA REALISER AVANT LA PARTIE rassembler comptage puis mettre à jour le df_attr_update pour que les id_comptag collent lors de la mise à jour</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserer les nouveaux compteurs\n",
    "insererSchemaComptage(rassemblerNewCompteur('24', 'RD', 'CD24', False, 'coordonnees_gestionnaire', 'double sens', (cptRefSectHomoNew, 'geom_x'),\n",
    "                      (cptAForcer, 'geom_x'), (dfCreationCompteur, 'geom_x')), 'compteur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserer les nouveaux comptages\n",
    "dfComptageNewTot = rassemblerNewComptage('2020', 'tv/pl', cd24.df_attr_update, cptRefSectHomoNew, cptAForcer, dfCreationCompteur)\n",
    "insererSchemaComptage(dfComptageNewTot, 'comptage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserer les nouveaux indicateurs\n",
    "dfIndicAgregeNew, dfIndicMensNew, dfIndicHoraireNew = rassemblerIndics('2020', dfComptageNewTot, cd24.df_attr.assign(fichier='PERMANENT-TOURNANT_2020.csv'),\n",
    "                                                                       cd24.df_attr_mens.assign(fichier='PERMANENT-TOURNANT_2020.csv'))\n",
    "insererSchemaComptage(dfIndicMensNew, 'indicAgrege')\n",
    "insererSchemaComptage(dfIndicMensNew, 'indicMensuel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***CD 33***\n",
    "***PENSER A RECUPERER L'HISTORIQUE DE ENQUETES DEPUIS LE SITE INTERNET***\n",
    "- Année 2019 : \n",
    "> à partir du fichier de comptage C:\\Users\\martin.schoreisz\\Box\\Dossier_Personnel_de_Martin_SCHOREISZ\\OTV\\33\\CD33\\export  2019 pour DREAL.xlsx (aussi présent sur les anciens serveurs) et du fichier de sectionnement C:\\Users\\martin.schoreisz\\Box\\Dossier_Personnel_de_Martin_SCHOREISZ\\OTV\\33\\CD33\\SECT_2021_CAT en cours.shp <br> On va chercher à recouper les comptages avec les notres en associant l'identifiant de troncon.<br> les troncons du CD ont l'air cohérents, on va qd mm checker les regrouepemnt <br> **Données Mensuelles dispos**<br> environ 70 cpt permanents et 60 tournants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cptPerm33 = it.Comptage_cd33( r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\CD33\\export_2019_pour_DREAL.xlsx',2019,\n",
    "                         r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\CD33\\SECT_2021_CAT en cours.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trouver les connus et inconnus\n",
    "GdfPerm,gdfPermConnus, gdfPermInconnus=cptPerm33.trierPermConnus('local_otv_boulot', 'na_2010_2019_p', 'boulot')\n",
    "# assigner les inconnu manuellement\n",
    "dico_corresp={'0106_03':'33-D106-35+835'}\n",
    "cptPerm33.assignerCptInconnus(dico_corresp,gdfPermInconnus)\n",
    "# fusion\n",
    "gdfPermConnus=pd.concat([gdfPermConnus, gdfPermInconnus.loc[~gdfPermInconnus.id_comptag.isna()]])\n",
    "gdfPermInconnus=gdfPermInconnus.loc[gdfPermInconnus.id_comptag.isna()]\n",
    "GdfPerm=pd.concat([gdfPermConnus,gdfPermInconnus])\n",
    "# mensuel\n",
    "donnees_mens_perm=GdfPerm[['troncon']+[m for m in it.dico_mois.keys()]].assign(donnees_type='tmja')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comptages tournants\n",
    "tournant=cptPerm33.analyseTourn()\n",
    "donneesMensTour=cptPerm33.donneesMensTournant(tournant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chercher les correspondance\n",
    "rqtPpvCptTournant = \"\"\"SELECT DISTINCT ON (c.troncon) t.id_ign, c.troncon\n",
    " FROM test_affectation_cd33_tournant t JOIN tournant_geoloc_l93 c ON st_dwithin(c.geom, t.geom,30)\n",
    " ORDER BY c.troncon, st_distance(t.geom, c.geom)\"\"\"\n",
    "rqtCptExistant = \"select id_ign, id_comptag from lineaire.traf2019_bdt33_ed19_l\"\n",
    "rqtGeomReferentielEpure = 'select id_ign, geom from test_affectation_cd33_tournant'\n",
    "rqtPpvCptBdd = \"\"\"SELECT DISTINCT ON (t.id_ign) t.id_ign, c.id_comptag\n",
    " FROM test_affectation_cd33_tournant t JOIN comptage.na_2010_2019_p c ON st_dwithin(c.geom, t.geom,30)\n",
    " WHERE c.gestionnai='CD33'\n",
    " ORDER BY t.id_ign, st_distance(t.geom, c.geom)\"\"\"\n",
    "correspTournant, inconnuTournant = cptPerm33.correspondanceTournant('gti_otv_pg11', 'boulot', rqtPpvCptTournant, rqtCptExistant, rqtGeomReferentielEpure, rqtPpvCptBdd,\n",
    "                               'public', 'test_affectation_cd33_tournant','test_affectation_cd33_tournant_vertices_pgr', tournant )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apres analyse mano : \n",
    "dicoCorrespTourn={'0005_06':'33-D5-76+0',\n",
    "                  '0012_11':'33-D12-17+200',\n",
    "                  '0115_06' : '33-D115-103+0',\n",
    "                 '0116_01':'33-D116-23+0',\n",
    "                 '0216_02':'33-D216-15+0',\n",
    "                 '0222_02':'33-D222-16+0',\n",
    "                 '0655_01':'33-D655-10+0'}\n",
    "cptTournantAffecte=cptPerm33.correctionCorrespondanceTournant(dicoCorrespTourn,tournant,correspTournant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creer les df_attr sur le mm schema que les habituels\n",
    "cptPerm33.df_attr_update=pd.concat([cptTournantAffecte.loc[cptTournantAffecte.correspondance==True][['id_comptag', 'tmja_2019', 'pc_pl_2019', 'obs_2019', 'src_2019', 'fichier']],\n",
    "gdfPermConnus[['id_comptag', 'tmja_2019', 'pc_pl_2019', 'src_2019', 'fichier']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creer nouveaux points tournants\n",
    "dicoNewCpt={'troncon':['0652_00','0003_17','0005_00','0009_02','0011_05','0012_10','0012_13','0110_01','0214_00','0222_01','0651_02','0932_03'],\n",
    "             'pr':[4,163,61,32,55,11,39,15,3,5,34,0],\n",
    "             'absc':[280,60,600,90,760,0,330,885,980,280,20,812]}\n",
    "cptPerm33.df_attr_insert = cptPerm33.creerNouveauPointTournants(cptTournantAffecte,dicoNewCpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cptPerm33.df_attr_insert\n",
    "cptPerm33.df_attr_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# donnees mensuelles\n",
    "donnees_mens_perm.merge(GdfPerm[['troncon', 'id_comptag']], on='troncon')\n",
    "df_corresp_mens=cptTournantAffecte[['troncon','id_comptag']].merge(cptPerm33.df_attr_insert[['troncon','id_comptag']], on='troncon', how='left')\n",
    "df_corresp_mens['id_comptag']=df_corresp_mens.apply(lambda x : x['id_comptag_x'] if not pd.isnull(x['id_comptag_x']) else x['id_comptag_y'], axis=1)\n",
    "df_attr_mens=pd.concat([donneesMensTour.merge(df_corresp_mens[['troncon', 'id_comptag']], on='troncon'),\n",
    "                        donnees_mens_perm.merge(GdfPerm[['troncon', 'id_comptag']], on='troncon')]).drop('troncon', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cptPerm33.insert_bdd('gti_otv_pg11', 'comptage', 'na_2010_2019_mensuel',df_attr_mens.assign(annee=str(cptPerm33.annee)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# ***SCA***\n",
    "- Année 2018 : \n",
    "> Concerne COFIROUTE, VINCI, ALIENOR, ATLANDES.<br> Des données de correspondances id_comptages sont dans la table source de la base de données otv.<br> **Donnees TMJM dispos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## COFIROUTE \n",
    "> l'id_comptage est ajouté manuellement dans le fichier source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation\n",
    "fichier = r'C:\\Users\\martin.schoreisz\\Box\\Dossier_Perso\\OTV\\donnees_gestionnaires\\COFIROUTE\\en_cours\\Resultats_2020.xlsx'\n",
    "annee = '2020'\n",
    "cofi = it.Comptage_Cofiroute(annee, fichier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation / insertion (penser au parametre inserer des fonctions)\n",
    "dfComptage = cofi.insererDonneesComptageBdd()\n",
    "dfAgrege = cofi.insererDonneesAgregeBdd()\n",
    "dfMensuel = cofi.insererDonneesMensuelleBdd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\" ></a>\n",
    "- ## VINCI \n",
    "> L'idée c'est d'importer le tableur et les données et de faire la jointure pour mise à jour.<br>**ATTENTION : rien de prévu si nouveau points** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018\n",
    "cpt = it.Comptage_vinci(r'D:\\temp\\otv\\Donnees_source\\VINCI\\2018_comptage_vitesse_moyenne_VINCI.xlsx')\n",
    "cpt.update_bdd_Vinci('local_otv_station_gti', 'comptage', 'na_2010_2018_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019\n",
    "cpt = it.Comptage_vinci(r'D:\\temp\\otv\\2019\\Donnees_source\\ASF\\bdd_point_comptage et vitesse moyenne 2019.xlsx', 2019)\n",
    "cpt.update_bdd_Vinci('local_otv_station_gti', 'comptage', 'na_2010_2019_p')\n",
    "# cpt.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_mensuel',cpt.df_attr_mens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020 : pb de jointure entre les donnees et les id_comptag en base, donc je fais simple et je copie d'id comptage manuellement\n",
    "cpt = it.Comptage_vinci(r'C:\\Users\\martin.schoreisz\\Box\\Dossier_Perso\\OTV\\donnees_gestionnaires\\ASF\\en_cours\\bdd_point_comptage et vitesse moyenne 2020.xlsx', 2020)\n",
    "cpt.classer_comptage_update_insert('local_otv_boulot', 'compteur')\n",
    "# cpt.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_mensuel',cpt.df_attr_mens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insertion comptage\n",
    "cpt.insert_bdd('local_otv_boulot', 'comptage', 'comptage',cpt.creer_comptage(cpt.df_attr.id_comptag.tolist(), cpt.annee, 'tableur Vinci', 'tv/pl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insertion agrege\n",
    "cpt.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege',\n",
    "               cpt.structureBddOld2NewForm(cpt.df_attr_update, cpt.annee,['id_comptag', 'annee', 'fichier'],['tmja', 'pc_pl'], 'agrege'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insertion mensuel\n",
    "cpt.insert_bdd('local_otv_boulot', 'comptage', 'indic_mensuel',cpt.structureBddOld2NewForm(cpt.df_attr_mens, \n",
    "               cpt.annee,['id_comptag', 'annee', 'fichier', 'donnees_type'],['janv', 'fevr', 'mars', 'avri', 'mai', 'juin', 'juil', 'aout', 'sept',\n",
    "               'octo', 'nove', 'dece'], 'mensuel'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\" ></a>\n",
    "- ## ALIENOR / ATLANDES\n",
    "> Que 7 points chaucun, j'utilise surtout là pour les donees mensuelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alienor = it.Comptage_alienor(r'D:\\temp\\otv\\2019\\Donnees_source\\ALIENOR\\ALIENOR_trafic_2019.xlsx', 2019)\n",
    "alienor.ouvrir_et_separe_donnees()\n",
    "alienor.update_bdd_Alienor('local_otv_station_gti', 'comptage', 'na_2010_2019_p')\n",
    "alienor.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_mensuel',alienor.df_attr_mens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlandes = it.Comptage_atlandes(r'D:\\temp\\otv\\2019\\Donnees_source\\ATLANDES\\2019_trafic_atlandes_7_boucles.xls', 2019)\n",
    "atlandes.donnees_mens()\n",
    "atlandes.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_mensuel',atlandes.df_attr_mens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020\n",
    "alienor = it.Comptage_alienor(r'C:\\Users\\martin.schoreisz\\Box\\Dossier_Perso\\OTV\\donnees_gestionnaires\\ALIENOR\\en_cours\\ALIENOR_trafic_2020.xlsx', '2020')\n",
    "alienor.ouvrir_et_separe_donnees()\n",
    "alienor.insererComptage(alienor.creer_comptage(alienor.df_attr.id_comptag.tolist(),\n",
    "                        '2020', 'tableau DIT', 'vl/pl', obs='attention, dans le tableau DIT 2020 les id_comptag sont décalés par rapport aux id_comptag ALIENOR 2019'))\n",
    "alienor.insererAgrege(alienor.structureBddOld2NewForm(alienor.df_attr.assign(annee='2020').rename(columns={'tmja_2020': 'tmja', 'pc_pl_2020': 'pc_pl'}),\n",
    "                      '2020', ['id_comptag', 'src', 'annee', 'fichier'], ['tmja', 'pc_pl'], 'agrege'))\n",
    "alienor.insererMensuel(alienor.structureBddOld2NewForm(alienor.df_attr_mens, '2020', ['id_comptag', 'donnees_type', 'annee', 'fichier'], \n",
    "                                list(dico_mois.keys()), 'mensuel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020\n",
    "atlandes = it.Comptage_atlandes(r'C:\\Users\\martin.schoreisz\\Box\\Dossier_Perso\\OTV\\donnees_gestionnaires\\ATLANDES\\en_cours\\Trafic atlandes 2020 - 7 boucles DREAL.xls', '2020')\n",
    "donnees = atlandes.miseEnForme()\n",
    "atlandes.insert_bdd('local_otv_boulot', 'comptage', 'comptage', atlandes.donneesAgregees()[['id_comptag', 'src', 'type_veh', 'annee']] )\n",
    "atlandes.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege',\n",
    "                    atlandes.structureBddOld2NewForm(atlandes.donneesAgregees(), atlandes.annee, ['id_comptag', 'annee', 'fichier'], ['tmja', 'pc_pl'], 'agrege'))\n",
    "atlandes.insert_bdd('local_otv_boulot', 'comptage', 'indic_mensuel',\n",
    "                    atlandes.structureBddOld2NewForm(atlandes.df_attr_mens, atlandes.annee, ['id_comptag', 'donnees_type', 'annee', 'fichier'], \n",
    "                                                     ['janv', 'fevr', 'mars', 'avri', 'mai', 'juin', 'juil', 'aout', 'sept', 'octo', 'nove', 'dece'], 'mensuel' ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Grand Poitiers***\n",
    "> on a deja un fichier dans la base de donnees : on va chercher a greffer les donnees et a cree un nouvel id_comptag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ouvrir un fichier\n",
    "dossie r= r'D:\\temp\\otv\\2019\\Donnees_source\\GP\\Automatiques 2019'\n",
    "cpt = it.Comptage_GrandPoitiers(r'D:\\temp\\otv\\2019\\Donnees_source\\GP\\Automatiques 2019',2019)\n",
    "cpt.comptage_forme('local_otv_station_gti')\n",
    "cpt.update_bdd_grdPoi('local_otv_station_gti', 'comptage', 'na_2010_2019_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_horaire', cpt.df_attr_horaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=10 ></a>\n",
    "# ***Ville Anglet***\n",
    "> Ci-dessous simplement un exemple d'ouverture de fcihier .mdb, de liste des tables et de lecture d'une table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Anglet = it.Comptage_Anglet('2016',r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\Anglet\\COMPTAGES ANGLET\\Comptages 2016',\n",
    "                            r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\Anglet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epxortdu fichier csv seravnt a la geoloc\n",
    "Anglet.exporterCsvAGeocoder()\n",
    "# enuiste on geoloc a la main (via l'appli 'mongoecodeur de l'IGN), dans le repertoir dossierResume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# puis on recupere la geoloc et on creer la df permettantde creer des compteurs\n",
    "Anglet.creerDfGeoloc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation des df hoarires et agrege sans filtre\n",
    "Anglet.indicsTousFichiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPPV = Anglet.plusProcheVoisinBddRegroupe('traf2020_bdt_na_ed20_simpli_l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trouver les doublons situés sur un même troncon homogène de trafic\n",
    "listCptDoublons = Anglet.isolerComptagesDoublons(dfPPV).id_comptag.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rechercher des doublons a passer dans comptage_assoc de façon manuelle\n",
    "dfPPV.loc[dfPPV.id_comptag.isin(listCptDoublons)]\n",
    "# on va garder certains, qui vont peut etre etre associé à des "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apres verif on conserve\n",
    "dicoAssoc = {'Anglet-13_rue_de_Lauzin--1.5287;43.4894':['Anglet-7_ter_rue_de_Lauzin--1.5287;43.4895',], 'Anglet-86_rue_de_Chassin--1.5289;43.4916':['Anglet-100_rue_de_Chassin--1.5286;43.4929']}\n",
    "#filtre \n",
    "dfPPVCptRef, dfPPVCptAssoc = Anglet.cptSsDblEtSsGeom(dfPPV, dicoAssoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserer donnees : ATTENTION : ON NE CONSERVE PAS LES POINTS TROP LOIN (a faire ulterieurement)\n",
    "Anglet.insererDatas(dfPPVCptRef.loc[~dfPPVCptRef.gid.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserer les qualites faibles\n",
    "Anglet.insererQualiteFaible(dfPPVCptRef.loc[~dfPPVCptRef.gid.isna()][['id_comptag_bdd', 'id_comptag', \n",
    "                            'note_manuelle_qualite', 'obs_qualite']].rename(columns={'note_manuelle_qualite':'note_manuelle','obs_qualite':'obs' }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insérer les comptages associés\n",
    "# creer la df et les comptages en bdd au passage\n",
    "dfAssoc = Anglet.creerComptageAssoc(dfPPVCptAssoc)\n",
    "dfIndicAgregeAssoc, dfHoraireasso = Anglet.creerIndicsAssoc(dfAssoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Ville Angouleme***\n",
    "> 2021 : une 40aine de points, format MHCorbin, mais un fihcier par sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ang = it.Comptag_Angouleme('2020', r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\Angouleme\\en_cours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dFDataBrutes, dfHshdr = ang.extraireDonneesBrutes()\n",
    "ang.assignerDossierRefEtAdresse(dFDataBrutes, dfHshdr)\n",
    "dfAdresse = ang.adresseUniques(dfHshdr)\n",
    "dfAdresse.adresse.replace('72 St Roch', '70 St Roch', inplace=True)#correction à posteriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visu des adresse sans donnees et creation d'un dico  avec en clé le dossier de reference et ene value une adresse, ou une geoloc en WGS84 si adresse pas dispo\n",
    "dfAdresse.loc[dfAdresse['adresse'].isna()].dir_ref.unique()\n",
    "dicoAdresseMano = {'bd allende section tourgarnier-alsace lorraine': '10 bd salvador allende',\n",
    "                   'bordeaux carrefour st cybard_rue montauzier': '175 rue de bordeaux',\n",
    "                   'bordeaux section montauzier_colone': '161 rue de bordeaux',\n",
    "                   'bd de bury section durosel-gatine': '27 bd de bury',\n",
    "                   'bd de bury section poincaré-durosel': '1 bd de bury',\n",
    "                   'DUROSELLE': '46 r du docteur duroselle', 'JULES FERRY': '3 av jules ferry',\n",
    "                   'bd de liédot section lorraine-olry': '6 bd liedot',\n",
    "                   'limoges section commandant berger_rue paul bert': '206 r de limoges',\n",
    "                   'maréchal juin': '28 av du maréchal juin',\n",
    "                   'montmoreau section bézines_abadie': '90 r de montmoreau',\n",
    "                   'poincarre-citéAdministrative': '10 r raymond poincare',\n",
    "                   'section bellamy-thiers': '45.650174, 0.172777',\n",
    "                   'section léonide lacroix_place mulac': '54 r de saintes',\n",
    "                   'section place mulac_quai du hallage': '36 r de saintes',\n",
    "                   'section quai du hallage_rue de bordeaux': '7 r de saintes',\n",
    "                   'section croix maillot_rue du pont sec': '112 r de saintes',\n",
    "                   'duroselle-montmoreau': '45.643218, 0.160635',\n",
    "                   'rue pierre sémard_rue de la loire': '45.652617, 0.165367',\n",
    "                   'sectiion d1000_bd jean moulin': '45.630431, 0.144746',\n",
    "                   'valette-jean-moulin': ' 45.638887, 0.145055',\n",
    "                   'valette-montmoreau': '45.642477, 0.151709',\n",
    "                   'bretelle entree voie europe-loire': '45.644964, 0.162379'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAdresse2 = ang.assignerAdressesManuelles(dfAdresse, dicoAdresseMano)\n",
    "# ang.exporterCsvAGeocoder(dfAdresse2)\n",
    "ang.creerDfGeoloc(dfAdresse2)\n",
    "ang.creerIndicsTousFichiers(dFDataBrutes)\n",
    "ang.ajouterFichierConcatener()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tester les doublons par section homogene proche\n",
    "dfPPV=ang.plusProcheVoisinBddRegroupe('traf2020_bdt_na_ed20_simpli_l', distance=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trouver les doublons situés sur un même troncon homogène de trafic\n",
    "listCptDoublons = ang.isolerComptagesDoublons(dfPPV).id_comptag.unique()\n",
    "listCptDoublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ang.gdfGeoloc.merge(ang.dfIndicAgrege.loc[ang.dfIndicAgrege.id_comptag.isin(listCptDoublons) & (ang.dfIndicAgrege.indicateur=='tmja')], on='id_comptag').to_file(\n",
    "os.path.join(ang.dossierSource, 'doublons.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apres verif on conserve\n",
    "dicoAssoc = {'Angouleme-27_bd_de_bury-0.165;45.6476':['Angouleme-13_Bury-0.1648;45.6476',], \n",
    "             'Angouleme-6_BD_ALLENDE-0.1671;45.6472':['Angouleme-10_bd_salvador_allende-0.1673;45.6472'],\n",
    "             'Angouleme-8_BD_LIEDOT-0.1701;45.6464':['Angouleme-6_bd_liedot-0.1699;45.6465'],\n",
    "            'Angouleme-195_St_Roch-0.1724;45.6493':['Angouleme-194_St_Roch-0.1725;45.6494'],}\n",
    "# filtre \n",
    "dfPPVCptRef, dfPPVCptAssoc = ang.cptSsDblEtSsGeom(dfPPV, dicoAssoc, True)\n",
    "# liste des comptages à forcer\n",
    "CptAForcer = ('Angouleme-65_besson_bey-0.1578;45.654',\n",
    "                'Angouleme-206_r_de_limoges-0.1779;45.6598',\n",
    "                'Angouleme-28_av_du_maréchal_juin-0.1746;45.6617',\n",
    "                'Angouleme-195_St_Roch-0.1724;45.6493',\n",
    "                'Angouleme-52_BD_LIEDOT-0.173;45.6458',\n",
    "                'Angouleme-3_av_jules_ferry-0.1553;45.6446',\n",
    "                'Angouleme--0.1447;45.6304',\n",
    "                'Angouleme--0.1451;45.6389',\n",
    "                'Angouleme-18_bd_besson_bey-0.1613;45.6601',\n",
    "                'Angouleme-57_BD_CHABASSE-0.1728;45.6468',\n",
    "                'Angouleme-70_St_Roch-0.1641;45.6505')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfert de comptages associés suite à plantage inserion : \n",
    "listCptAssoc=('Angouleme-179_av_Gambetta-0.1613;45.6504',)\n",
    "dfPPVCptRef, dfPPVCptAssoc=ang.transfererAssocSupp(dfPPVCptRef, dfPPVCptAssoc, listCptAssoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insertion des donnees\n",
    "ang.insererDatas(dfPPVCptRef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transférer les comptages associés (ATTENTION, certains CPT -ceux ajoutés à la suite) ne sont pas passé )\n",
    "dfAssoc=ang.creerComptageAssoc(dfPPVCptAssoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# ***Ville Niort***\n",
    "> 2020 : une dizaine de ponts de comptage. l'enjeu est sur al localisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation des donnees a transferer\n",
    "cpt_niort = it.Comptage_Niort(r'D:\\temp\\otv\\2019\\Donnees_source\\Niort\\NIORT_COMPTAGE_ROUTIER_2020\\2020',2020)\n",
    "dico_id_comptag = {\n",
    "                    'Niort-rue_alsace_lorraine--0,4580;46,3287': '01 2020 Alsace Lorraine',\n",
    "                    'Niort-boulevard_cassin--0,4523;46,3223': '01 2020 Rue Terraudiere Bld Cassin_2',\n",
    "                    'Niort-rue_terraudiere--0,4524;46,3228': '01 2020 Rue Terraudiere Bld Cassin_1',\n",
    "                    'Niort-rue_chateau_menu--0,4524;46,3592': '02 2020 Chateau Menu',\n",
    "                    'Niort-rue_de_souche--0,4345;46,3260': '02 2020 rue de Souché',\n",
    "                    'Niort-rue_du_24_fevrier--0,4628;46,3212': '03 2020 24 Février',\n",
    "                    'Niort-avenue_de_paris--0,4458;46,3285': '03 2020 Paris',\n",
    "                    'Niort-avenue_saint_jean_angely--0,4656;46,3203': '03 2020 St Jean',\n",
    "                    'Niort-rue_14_juillet--0,4560;46,3233': '01 2020 Limoges 14 Juillet_2',\n",
    "                    'Niort-rue_marechal_leclerc--0,4400;46,3527': '01 2020 Mal Leclerc',\n",
    "                    'Niort-avenue_de_limoges--0,4565;46,3221': '01 2020 Limoges 14 Juillet_1',\n",
    "                    'Niort-rue_de_la_la_gare--0,4578;46,3203': '01 2020 rue de la gare'}\n",
    "dico_fichiers_final = cpt_niort.creer_dico(dico_id_comptag)\n",
    "cpt_niort.horaire_tout_cpt(dico_fichiers_final)\n",
    "cpt_niort.agrege_tout_cpt(dico_fichiers_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_niort.df_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_txt=cpt_niort.creer_valeur_txt_update(cpt_niort.df_attr, ['id_comptag','tmja','pc_pl', 'src'])\n",
    "cpt_niort.update_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_p', val_txt,{f'tmja_{str(cpt_niort.annee)}':'tmja',f'pc_pl_{str(cpt_niort.annee)}':'pc_pl', f'src_{str(cpt_niort.annee)}':'src'})\n",
    "cpt_niort.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_horaire', cpt_niort.df_attr_horaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 2016 a 2019 : \n",
    "on peut creer le dico_id_comptag a partir des donnees stockes dans la table (geom, id des fchiers, reference du dossier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dossier_src=r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\Niort\\comptages_2016_2019\\CEREMA'\n",
    "annees=['2016','2017','2018','2019']\n",
    "dico_dossier_src={annee:os.path.join(dossier_src, annee) for annee in annees}\n",
    "#obtenir le lien entre les fichiers et de compatg et l'id_comptag, precedemmnet entre dans la bdd via qgis\n",
    "with ct.ConnexionBdd('gti_otv_pg11') as c : \n",
    "    rqt=\"select id_comptag, id_cpt, fichier from comptage.na_2010_2019_p where id_comptag like 'Niort%%' and fichier IS NOT null\"\n",
    "    ids=pd.read_sql(rqt, c.sqlAlchemyConn)\n",
    "#formater pour pouvoir utiliser le code creer pour 2020\n",
    "dico_id_comptag={id_comptag:[os.path.join(d,f) for f in id_cpt.split(';')] for id_comptag,id_cpt,d in \n",
    "                 zip(ids.id_comptag.tolist(),ids.id_cpt.tolist(),ids.fichier.tolist()) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculer les données et les insérer\n",
    "for a,val in dico_dossier_src.items():\n",
    "    dico_limite={k:v for k,v in dico_id_comptag.items() if all([val in e for e in v])}\n",
    "    cpt_niort=it.Comptage_Niort(val,a)\n",
    "    cpt_niort.agrege_tout_cpt(dico_limite)\n",
    "    cpt_niort.horaire_tout_cpt(dico_limite)\n",
    "    cpt_niort.df_attr=cpt_niort.df_attr.loc[~cpt_niort.df_attr.tmja.isna()].copy()\n",
    "    cpt_niort.df_attr_horaire=cpt_niort.df_attr_horaire.loc[cpt_niort.df_attr_horaire.id_comptag.isin(cpt_niort.df_attr.id_comptag.tolist())].copy()\n",
    "    cpt_niort.insert_bdd('gti_otv_pg11', 'comptage', 'na_2010_2019_horaire',cpt_niort.df_attr_horaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Grand Dax***\n",
    "> une 20aine de points de comptage. l'enjeu est sur la localisation : faite à la main pour aller plus vite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cptDax=it.Comptage_GrandDax(r'D:\\temp\\otv\\2019\\donnees_produite\\points_Dax_temp.shp')\n",
    "cptDax.creer_df_agrege()\n",
    "cptDax.df_horaire_final()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cptDax.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_p', cptDax.df_attr)\n",
    "cptDax.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_horaire',cptDax.df_attr_horaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ***Limoges Metropole***\n",
    "> un Webservice est dispo ici : https://siglm.agglo-limoges.fr/servernf/rest/services/_TRANSPORTS/transports_consult/featureServer\n",
    "on peut y acceder via Qgis, ce qui permet de creer un shape : Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\LIMOGES\\Limoge_Web_service.shp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## isoler les points représentatifs du trafic total\n",
    "1. ajouter des attributs d'identification : de la représentativité, de groupement\n",
    "1. Checker la validité des attributs et déterminer sur lesquels s'appuyer\n",
    "1. Regrouper les points avec un identfiant\n",
    "1. Conserver les points avec 'type' == 'Double' ie 'representatif'=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POUR INFO\n",
    "# rechreche incohérence entre direction et type : direction 2 sens et type Simple\n",
    "limMet.loc[(limMet.apply(lambda x: any([a.lower() in x['direction'].lower() \n",
    "            for a in ('2 sens','2  sens', 'deux sens', 'double sens', 'cumul') if x['direction']]), axis=1)) & (limMet['type']=='Simple')].objectid.tolist()\n",
    "\"\"\"objectId in (40390.0, 40844.0, 41639.0, 42174.0, 42175.0, 42176.0, 42177.0, 42432.0, 42599.0, 43066.0, 43720.0, \n",
    "52077.0, 39017.0, 39274.0, 39586.0, 39959.0, 40014.0, 40015.0) prioriser 'type'=='Double', ne pas trop s'appuyer sur le type\"\"\"\n",
    "# rechreche incohérence entre direction et type : direction != 2 sens et type Double : là aussi, ça confirme de s'appuyer sur le type Double\n",
    "limMet.loc[(limMet.apply(lambda x: all([a.lower() not in x['direction'].lower() \n",
    "            for a in ('2 sens','2  sens', 'deux sens', 'double sens', 'cumul') if x['direction']]), axis=1)) & (limMet['type']=='Double')].objectid.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limMet = it.Comptage_Limoges_Metropole(r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\LIMOGES\\Limoge_Web_service.shp',\n",
    "                                       r'D:\\temp\\otv\\2019\\donnees_produite\\test_limoges\\zone_equi_cpt.shp')\n",
    "limMet.groupe_point()\n",
    "limMet.df_regroupee_complete(limMet.df_regroupee())\n",
    "limMet.insert_bdd('gti_otv_pg11', 'comptage', 'na_2010_2019_p', limMet.df_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 2020\n",
    "Il s'agit d'ajouter des données à celle issues de la premiere integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [],
   "source": [
    "fichierSigSource = r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\Limoges_Metropole\\trafics2020.shp'\n",
    "fichierZone = r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\Limoges_Metropole\\zone_equi_cpt.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mettre en forme les données 2020 ; ATTENTION LE CODE DERRIERE EST VIEUX : A VERIFIER\n",
    "limMet = it.Comptage_Limoges_Metropole(fichierSigSource, fichierZone)\n",
    "limMet.groupe_point()\n",
    "limMet.df_regroupee_complete(limMet.df_regroupee())\n",
    "limMet.df_attr.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ###  Ventilation entre les comptages qui correspondent pleinement à des comptages connus et les autres\n",
    "Pour ça on utilise le fichier de zonage créé précédemment et mis à jour : les compteurs qui sont référencé en 2020 dans la même zone que des compteurs existants vont en prendre l'identifiant de comptage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rechercher les correspondances avec de l'existant\n",
    "# il y a correspondance avec de l'existant si l'id_groupe de df_attr est présent dans l'obs_supl de la table compteur\n",
    "# recupérer la table compteur\n",
    "LimMetExistant = comptag_existant_bdd(gest = 'Limoges Metropole')\n",
    "# extraire le numero de groupe et limiter les données\n",
    "LimMetExistant.loc[LimMetExistant.apply(lambda x: True if not pd.isnull(x.obs_supl) and 'numero de zone dans fichier geoloc' in x.obs_supl else False, axis=1)\n",
    "                  , 'id_zone_grp'] = LimMetExistant.loc[\n",
    "    LimMetExistant.apply(lambda x: True if not pd.isnull(x.obs_supl) and 'numero de zone dans fichier geoloc' in x.obs_supl else False, axis=1\n",
    "                        )].obs_supl.apply(lambda x: x.split(' ; ')[0].split(' : ')[1]).astype(int)\n",
    "LimMetExistant = LimMetExistant.loc[~LimMetExistant.id_zone_grp.isna()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jointure non exclusive pour trouver les comptages déjà référencés précédemment\n",
    "verifNouveauComptagVsExistant = limMet.df_attr.merge(LimMetExistant, how='left', left_on='id_groupe', right_on='id_zone_grp', suffixes=('_gest', '_bdd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comptage pouvant etre directement rattachés à des comptages existant, en substituant les id_comptag puisqu'ils ont présents dans la même zone\n",
    "df_attr_update = verifNouveauComptagVsExistant.loc[~verifNouveauComptagVsExistant.id_zone_grp.isna()].copy()\n",
    "# comptages n'étant pas directement rattachés à des comptages existants\n",
    "df_attr_insert = verifNouveauComptagVsExistant.loc[verifNouveauComptagVsExistant.id_zone_grp.isna()].copy().dropna(\n",
    "    how='all', axis=1).rename(columns={c: c[:-5] for c in df_attr_insert.columns if c[-5:]=='_gest'})\n",
    "df_attr_insert.rename(columns={'tmja_2020': 'tmja','pc_pl_2020': 'pc_pl', 'obs_2020': 'periode'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 42)"
      ]
     },
     "execution_count": 1034,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_attr_update), len(df_attr_insert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ###  Pour des comptages qui ne correspondent pas pleinement à des comptages connus, on va appliquer le processus habituel de ventilation  \n",
    "fais en dernier sur le 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verification des doublons :-> pas de doublons\n",
    "ref, assoc = ventilerDoublons(df_attr_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insertion des données en bdd pour étape suivante\n",
    "with ct.ConnexionBdd(nomConnBddOtv) as c:\n",
    "    ref = O.gp_changer_nom_geom(ref, 'geom')\n",
    "    ref.to_postgis('limmet_2020', c.sqlAlchemyConn, 'public', if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traitement, sur la base du CD24\n",
    "cptSansGeom, ppvHorsSectHomo, cptSimpleSectHomo, cptMultiSectHomo = ventilerParSectionHomogene('limmet_2020', 'linauto.traf2020_bdt_na_ed20_simpli_l', '87', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 26, 0, 0)"
      ]
     },
     "execution_count": 938,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verif\n",
    "len(cptMultiSectHomo), len(cptSimpleSectHomo), len(cptSansGeom), len(ppvHorsSectHomo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [],
   "source": [
    "cptRefMultiSectHomo, cptAssocMultiSectHomo = ventilerCompteurRefAssoc(cptMultiSectHomo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 7)"
      ]
     },
     "execution_count": 937,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verif\n",
    "len(cptAssocMultiSectHomo), len(cptRefMultiSectHomo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [],
   "source": [
    "cptRefSectHomoNew, cptRefSectHomoOld = ventilerCompteurIdComptagExistant(cptSimpleSectHomo, cptRefMultiSectHomo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 14)"
      ]
     },
     "execution_count": 940,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verif\n",
    "len(cptRefSectHomoNew), len(cptRefSectHomoOld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCorrespIdComptag, dfCreationComptageAssocie, dfModifTypePoste, dfCreationCompteur = ventilerNouveauComptageRef(cptRefSectHomoOld, 'type_poste',\n",
    "                                                                                                                 'type_poste_bdd', 'periode', '87',\n",
    "                                                                                                                'linauto.traf2020_bdt_na_ed20_cnt2_ini_l',\n",
    "                                                                                                                'lineaire.traf2020_bdt_na_ed20_l' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1033,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 2, 0, 0)"
      ]
     },
     "execution_count": 1033,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verif\n",
    "len(dfCorrespIdComptag), len(dfCreationComptageAssocie), len(dfModifTypePoste), len(dfCreationCompteur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ###  Vérif manuelle via Qgis, modification de la ventilation si besoin  \n",
    "le processus de modif de ventilation est soit manuel soit automatique, selon le type de trafnsfert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verif via Qgis\n",
    "gp.GeoDataFrame(dfCorrespIdComptag[['id_comptag', 'id_comptag_bdd', 'geom_x', 'type_poste', 'tmja', 'periode']].drop('geom_y', axis=1, errors='ignore'), geometry='geom_x', crs=2154\n",
    "                ).to_file(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\Limoges_Metropole\\verifCorrespIdComptage.shp')\n",
    "gp.GeoDataFrame(dfCreationComptageAssocie[['id_comptag', 'id_comptag_bdd', 'geom_x', 'type_poste', 'tmja', 'periode']].drop('geom_y', axis=1, errors='ignore'), geometry='geom_x', crs=2154\n",
    "                ).to_file(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\Limoges_Metropole\\creationComptageAssoc.shp')\n",
    "gp.GeoDataFrame(cptRefSectHomoNew[['id_comptag', 'geom_x', 'type_poste', 'tmja', 'id_comptag_bdd', 'periode']].drop('geom_y', axis=1, errors='ignore'), geometry='geom_x', crs=2154\n",
    "                ).to_file(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\Limoges_Metropole\\NewCompteur.shp')\n",
    "gp.GeoDataFrame(cptAssocMultiSectHomo[['id_comptag', 'geom_x', 'type_poste', 'tmja', 'id_comptag_bdd', 'periode']].drop('geom_y', axis=1, errors='ignore'), geometry='geom_x', crs=2154\n",
    "                ).to_file(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\Limoges_Metropole\\comptageAssocInterneNewData.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modificartion d'affectation de la ventilation\n",
    "listCompteurAForcer = ['LimMet-rue encombe vineuse-1.2548;45.8397', 'LimMet-avenue adrien tarrade-1.257;45.8398', 'LimMet-avenue maryse bastie-1.3281;45.8794']\n",
    "listeDepuisAssociesVersCorresp = ['LimMet-avenue adrien tarrade-1.2545;45.8386']\n",
    "cptAForcer = pd.concat([cptRefSectHomoOld.loc[cptRefSectHomoOld.id_comptag.isin(listCompteurAForcer)], \n",
    "                                            cptAssocMultiSectHomo.loc[cptAssocMultiSectHomo.id_comptag.isin(listCompteurAForcer)]])\n",
    "# verif cpt a forcer \n",
    "if len(listCompteurAForcer) != len(cptAForcer):\n",
    "    raise ValueError(\"tout les comptages de la liste des compteurs à forcer n'ont pas été trouvés, ou certains sont en doublons. Vérfiez les sources et résultats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_groupe</th>\n",
       "      <th>tmja</th>\n",
       "      <th>pc_pl</th>\n",
       "      <th>periode</th>\n",
       "      <th>src_2020</th>\n",
       "      <th>geom_x</th>\n",
       "      <th>src_geo</th>\n",
       "      <th>fichier</th>\n",
       "      <th>obs_supl</th>\n",
       "      <th>id_comptag</th>\n",
       "      <th>fictif</th>\n",
       "      <th>route</th>\n",
       "      <th>type_poste</th>\n",
       "      <th>dep</th>\n",
       "      <th>reseau</th>\n",
       "      <th>gestionnai</th>\n",
       "      <th>concession</th>\n",
       "      <th>x_l93</th>\n",
       "      <th>y_l93</th>\n",
       "      <th>gid</th>\n",
       "      <th>id_comptag_bdd</th>\n",
       "      <th>type_poste_bdd</th>\n",
       "      <th>geom_y</th>\n",
       "      <th>st_distance</th>\n",
       "      <th>note_hierarchise</th>\n",
       "      <th>id_comptag_ref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1044</td>\n",
       "      <td>8338.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2020/01/14-2020/01/16</td>\n",
       "      <td>Webservice Limoges Metropole</td>\n",
       "      <td>POINT (564722.072 6528180.136)</td>\n",
       "      <td>export Webservice, cf atribut fichier</td>\n",
       "      <td>trafics2020.shp</td>\n",
       "      <td>numero de zone dans fichier geoloc : 1044 ; co...</td>\n",
       "      <td>LimMet-avenue adrien tarrade-1.257;45.8398</td>\n",
       "      <td>None</td>\n",
       "      <td>avenue adrien tarrade</td>\n",
       "      <td>ponctuel</td>\n",
       "      <td>87</td>\n",
       "      <td>VC</td>\n",
       "      <td>Limoges Metropole</td>\n",
       "      <td>N</td>\n",
       "      <td>564722.072</td>\n",
       "      <td>6528180.136</td>\n",
       "      <td>9053</td>\n",
       "      <td>LimMet-avenue adrien tarrade-1.2549;45.8387</td>\n",
       "      <td>ponctuel</td>\n",
       "      <td>MULTILINESTRING ((564435.300 6527979.700, 5644...</td>\n",
       "      <td>1.404822</td>\n",
       "      <td>1.002000e+15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1042</td>\n",
       "      <td>652.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2020/01/14-2020/01/16</td>\n",
       "      <td>Webservice Limoges Metropole</td>\n",
       "      <td>POINT (564553.519 6528166.788)</td>\n",
       "      <td>export Webservice, cf atribut fichier</td>\n",
       "      <td>trafics2020.shp</td>\n",
       "      <td>numero de zone dans fichier geoloc : 1042 ; co...</td>\n",
       "      <td>LimMet-rue encombe vineuse-1.2548;45.8397</td>\n",
       "      <td>None</td>\n",
       "      <td>rue encombe vineuse</td>\n",
       "      <td>ponctuel</td>\n",
       "      <td>87</td>\n",
       "      <td>VC</td>\n",
       "      <td>Limoges Metropole</td>\n",
       "      <td>N</td>\n",
       "      <td>564553.519</td>\n",
       "      <td>6528166.788</td>\n",
       "      <td>9145</td>\n",
       "      <td>LimMet-avenue adrien tarrade-1.2555;45.8391</td>\n",
       "      <td>ponctuel</td>\n",
       "      <td>MULTILINESTRING ((564583.300 6528082.200, 5645...</td>\n",
       "      <td>28.998325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1063</td>\n",
       "      <td>967.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2020/02/18-2020/02/20</td>\n",
       "      <td>Webservice Limoges Metropole</td>\n",
       "      <td>POINT (570335.225 6532450.674)</td>\n",
       "      <td>export Webservice, cf atribut fichier</td>\n",
       "      <td>trafics2020.shp</td>\n",
       "      <td>numero de zone dans fichier geoloc : 1063 ; co...</td>\n",
       "      <td>LimMet-avenue maryse bastie-1.3281;45.8794</td>\n",
       "      <td>None</td>\n",
       "      <td>avenue maryse bastie</td>\n",
       "      <td>ponctuel</td>\n",
       "      <td>87</td>\n",
       "      <td>VC</td>\n",
       "      <td>Limoges Metropole</td>\n",
       "      <td>N</td>\n",
       "      <td>570335.225</td>\n",
       "      <td>6532450.674</td>\n",
       "      <td>6644</td>\n",
       "      <td>LimMet-avenue maryse bastie-1.3294;45.8762</td>\n",
       "      <td>ponctuel</td>\n",
       "      <td>MULTILINESTRING ((570306.500 6533010.800, 5703...</td>\n",
       "      <td>2.801865</td>\n",
       "      <td>1.002000e+15</td>\n",
       "      <td>LimMet-avenue maryse bastie-1.3286;45.8776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_groupe    tmja  pc_pl                periode  \\\n",
       "2       1044  8338.0   0.00  2020/01/14-2020/01/16   \n",
       "0       1042   652.0   0.00  2020/01/14-2020/01/16   \n",
       "3       1063   967.0   0.52  2020/02/18-2020/02/20   \n",
       "\n",
       "                       src_2020                          geom_x  \\\n",
       "2  Webservice Limoges Metropole  POINT (564722.072 6528180.136)   \n",
       "0  Webservice Limoges Metropole  POINT (564553.519 6528166.788)   \n",
       "3  Webservice Limoges Metropole  POINT (570335.225 6532450.674)   \n",
       "\n",
       "                                 src_geo          fichier  \\\n",
       "2  export Webservice, cf atribut fichier  trafics2020.shp   \n",
       "0  export Webservice, cf atribut fichier  trafics2020.shp   \n",
       "3  export Webservice, cf atribut fichier  trafics2020.shp   \n",
       "\n",
       "                                            obs_supl  \\\n",
       "2  numero de zone dans fichier geoloc : 1044 ; co...   \n",
       "0  numero de zone dans fichier geoloc : 1042 ; co...   \n",
       "3  numero de zone dans fichier geoloc : 1063 ; co...   \n",
       "\n",
       "                                   id_comptag fictif                  route  \\\n",
       "2  LimMet-avenue adrien tarrade-1.257;45.8398   None  avenue adrien tarrade   \n",
       "0   LimMet-rue encombe vineuse-1.2548;45.8397   None    rue encombe vineuse   \n",
       "3  LimMet-avenue maryse bastie-1.3281;45.8794   None   avenue maryse bastie   \n",
       "\n",
       "  type_poste dep reseau         gestionnai concession       x_l93  \\\n",
       "2   ponctuel  87     VC  Limoges Metropole          N  564722.072   \n",
       "0   ponctuel  87     VC  Limoges Metropole          N  564553.519   \n",
       "3   ponctuel  87     VC  Limoges Metropole          N  570335.225   \n",
       "\n",
       "         y_l93   gid                               id_comptag_bdd  \\\n",
       "2  6528180.136  9053  LimMet-avenue adrien tarrade-1.2549;45.8387   \n",
       "0  6528166.788  9145  LimMet-avenue adrien tarrade-1.2555;45.8391   \n",
       "3  6532450.674  6644   LimMet-avenue maryse bastie-1.3294;45.8762   \n",
       "\n",
       "  type_poste_bdd                                             geom_y  \\\n",
       "2       ponctuel  MULTILINESTRING ((564435.300 6527979.700, 5644...   \n",
       "0       ponctuel  MULTILINESTRING ((564583.300 6528082.200, 5645...   \n",
       "3       ponctuel  MULTILINESTRING ((570306.500 6533010.800, 5703...   \n",
       "\n",
       "   st_distance  note_hierarchise                              id_comptag_ref  \n",
       "2     1.404822      1.002000e+15                                         NaN  \n",
       "0    28.998325               NaN                                         NaN  \n",
       "3     2.801865      1.002000e+15  LimMet-avenue maryse bastie-1.3286;45.8776  "
      ]
     },
     "execution_count": 1046,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cptAForcer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# ***Agglo LaRochelle***\n",
    "> bcp de donnée éparpillées u peu n'importe comment ici : <br> Chaque commune à sa façon de bosser..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Exemple sainte-SOulle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dossier=r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\La_Rochelle\\donnees-la-rochelle\\Données La Rochelle\\7-Communes\\SteSoulle'\n",
    "toto=it.Comptage(os.path.join(dossier,'rue des Fortiness.txt'))\n",
    "SteSoulle=pd.read_csv(os.path.join(dossier,'rue des Fortines.txt'), sep=' ')\n",
    "SteSoulle.rename(columns={'Nombrevéhicules':'nbveh', 'Date':'heure'}, inplace=True)\n",
    "SteSoulle.reset_index(inplace=True)\n",
    "SteSoulle.rename(columns={'Nombrevéhicules':'nbveh', 'Date':'heure', 'index':'jour'}, inplace=True)\n",
    "SteSoulle.set_index(SteSoulle.apply(lambda x : pd.to_datetime(x['jour']+ ' ' + x.heure, dayfirst=True), axis=1), inplace=True)\n",
    "#les données sur le 4,10 et 11 février sont bizarres, on les exclus,du coup pour ne pas fausser le tmja avec trop de WE je ne garde que les jours ouvrés et je fais un tmjo\n",
    "#SteSoulle=SteSoulle.loc[(~SteSoulle.index.dayofyear.isin([pd.to_datetime(x).dayofyear for x in (('2016-03-28','2016-03-23','2016-04-02'))]))\n",
    "                       #& (~SteSoulle.index.dayofweek.isin((5,6)))][['nbveh', 'jour', 'heure']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcul tmja (basé sur calcul_indicateurs_agreges() de la classe FIM)\n",
    "df_jour=SteSoulle[['nbveh']].resample('1D').sum()\n",
    "df_jour=df_jour.loc[df_jour['nbveh']!=0].copy()\n",
    "if len(df_jour)<7 : \n",
    "    raise it.PasAssezMesureError(len(df_jour))\n",
    "elif len(df_jour) in (7,8) : \n",
    "    traf_list=df_jour.nbveh.tolist()\n",
    "    tmjo=int(statistics.mean([traf_list[0]+traf_list[-1]]+traf_list[1:-1]))\n",
    "else : \n",
    "    tmjo=int(df_jour.iloc[1:-1].nbveh.mean())*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_horaire=SteSoulle[['jour', 'heure', 'nbveh']].pivot(index='jour', columns='heure', values='nbveh').fillna(0)*2\n",
    "df_horaire.columns=[f'h{str(int(c.split(\":\")[0]))}_{str(int(c.split(\":\")[0])+1)}' for c in df_horaire.columns]\n",
    "df_horaire=df_horaire.reset_index().assign(type_veh='TV', id_comptag='LaRoche-r des fortines--1.0391;46.188')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toto.insert_bdd('gti_otv_pg11', 'comptage', 'na_2010_2019_horaire', df_horaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## La Rochelle\n",
    "plusieurs dossier contenant desfichiers de comptages, : Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\La_Rochelle\\campagne-comptages-2015\\trafic_aggloLR_SMOB2015 ; Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\La_Rochelle\\comptages_delattre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Larochelle.update_bdd_LaRochelle('gti_otv_pg11', 'comptage', 'na_2010_2019_p')\n",
    "Larochelle.insert_bdd('gti_otv_pg11', 'comptage', 'na_2010_2019_horaire', Larochelle.df_attr_horaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepar donnees\n",
    "Larochelle=it.Comptage_LaRochelle(r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\La_Rochelle\\donnees-la-rochelle\\Données La Rochelle\\7-Communes\\LaRochelle_LaPalice')\n",
    "ids=Larochelle.listCptCreer()\n",
    "Larochelle.creer_dfs(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ct.ConnexionBdd('gti_otv_pg11') as c : \n",
    "            rqt=\"select id_comptag, id_cpt from comptage.na_2010_2019_p where id_comptag in ('LaRoch-r marcel deflandre--1.2128;46.1698','LaRoch-r de bethencourt--1.2028;46.1712','LaRoch-r de bethencourt--1.2014;46.172')\"\n",
    "            ids=pd.read_sql(rqt, c.sqlAlchemyConn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fichier=r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\La_Rochelle\\donnees-la-rochelle\\Données La Rochelle\\7-Communes\\LaRochelle_LaPalice\\SEMAINE 2\\P1-RUE MARCEL DEFLANDRE SENS 2 SEMAINE 2.xls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(fichier)\n",
    "tmja=round(df.loc[38,'Unnamed: 6'])\n",
    "pl=round(df.loc[42,'Unnamed: 6'])\n",
    "periode=df.iloc[1,16]\n",
    "index_date=pd.date_range(start=pd.to_datetime(periode.split(' au ')[0][3:], dayfirst=True), end=pd.to_datetime(periode.split(' au ')[1], dayfirst=True))\n",
    "df_pl=df.iloc[17:24,2:26].copy()\n",
    "df_tv=df.iloc[27:34,2:26].copy()\n",
    "df_pl.columns=[f'h{str(i)}_{str(i+1)}' for i in range(24)]\n",
    "df_tv.columns=[f'h{str(i)}_{str(i+1)}' for i in range(24)]\n",
    "df_pl=df_pl.assign(jour=index_date, type_veh='PL')\n",
    "df_tv=df_tv.assign(jour=index_date, type_veh='TV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "<a id=\"7\" ></a>\n",
    "# ***DIRA***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Année 2019\n",
    "> il existe trois sorte de données, TMJA, TMJM et horaires. les données TMJA DOIVENT etre issu de (ordre de priorité) :<br>\n",
    "1. de la carto DIRA si le point est représenté\n",
    "1. du fichier global (Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\DIRA\\0_tmja_dira_par_section_20200106.ods)\n",
    "1. des fichiers horaires \n",
    "<br> les données horaires ne peuvent etre issue que des fichiers horaires Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\DIRA\\0_Annee_Complete_2019\n",
    "- des graphs dispo dans le notebook Graph_tafics\n",
    "- attention, certaines données de TMJA sont mises à jour apres prises en comptes des données horares,,quand une données horaire est dispo et le TMJA non. fait sous sql  \n",
    "***ATTENTION : EN 2020 IL Y  A EU CONFUSION NETRE LES POINTS rn150 MEDIS ET ST-ROMAIN-DE-BENET / BIEN CHECKER QUE TOUS LES IDENTFIANTS LIES AU BOUCLE ET AUTRES SONT OK***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## *TMJA / TMJM*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation de l'objet\n",
    "dira=it.Comptage_Dira(r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\DIRA\\0_tmja_dira_par_section_20200106.ods',\n",
    "                      r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\DIRA\\0_Annee_Complete_2019',\n",
    "                     '2019','gti_otv_pg11', 'na_2010_2019_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mise en form edes données\n",
    "dfMensGrp=dira.MiseEnFormeMensuelleAnnuelle(dira.verifValiditeMensuelle(dira.jointureExistantFichierTmja('gti_otv_pg11', 'na_2010_2019_p')))\n",
    "dira.MiseEnFormeAnnuelle(dfMensGrp,'16-N10-2+700')\n",
    "dira.MiseEnFormeMensuelle(dfMensGrp,'16-N10-2+700')\n",
    "#mise à jour de la Bdd\n",
    "dira.update_bdd_Dira('gti_otv_pg11', 'comptage', 'na_2010_2019_p', nullOnly=True)\n",
    "dira.insert_bdd('gti_otv_pg11','comptage', 'na_2010_2019_mensuel', dira.df_attr_mens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2020\n",
    "dira=it.Comptage_Dira(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\DIRA\\0_tmja_dira_par_section_20210101.ods',\n",
    "                      r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\DIRA\\GrosFichiers - JP CASSOU\\0_Annee_Complete_2020',\n",
    "                      r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\DIRA\\dira_tmja_2020.ods',\n",
    "                     '2020','local_otv_boulot', 'compteur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mise en forme des données \n",
    "dfMensGrp=dira.MiseEnFormeMensuelleAnnuelle(dira.verifValiditeMensuelle(dira.jointureExistantFichierTmja()))\n",
    "dira.MiseEnFormeAnnuelle(dfMensGrp)\n",
    "dira.MiseEnFormeMensuelle(dfMensGrp)\n",
    "#insertion des comptages\n",
    "dira.insert_bdd('local_otv_boulot', 'comptage', 'comptage', dira.creer_comptage(dira.df_attr.id_comptag.unique(), dira.annee, 'tableau annuel DIRA', 'tv/pl'))\n",
    "#insertion des indicateurs agreges\n",
    "dira.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege',dira.structureBddOld2NewForm(dira.df_attr, dira.annee,['id_comptag', 'annee', 'fichier'],['tmja', 'pc_pl'], 'agrege'))\n",
    "#insertion des indicateurs mensuel\n",
    "dira.insert_bdd('local_otv_boulot', 'comptage', 'indic_mensuel',dira.structureBddOld2NewForm(dira.df_attr_mens.replace(-99, np.nan), \n",
    "            dira.annee,['id_comptag', 'annee', 'fichier', 'donnees_type'],['janv', 'fevr', 'mars', 'avri', 'mai', 'juin', 'juil', 'aout', 'sept',\n",
    "       'octo', 'nove', 'dece'], 'mensuel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gestion des données carto\n",
    "donneesAgregeesUpdate, donneesAgregeesInsert=dira.cptCartoInsertUpdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update comptages\n",
    "dira.update_bdd('comptage', 'comptage', dira.creer_valeur_txt_update(donneesAgregeesUpdate.loc[donneesAgregeesUpdate.obs.isna()], ['id', 'src']),\n",
    "                {'src':'src'}, identifiant='id')\n",
    "dira.update_bdd('comptage', 'comptage', dira.creer_valeur_txt_update(donneesAgregeesUpdate.loc[~donneesAgregeesUpdate.obs.isna()], ['id', 'src', 'obs']),\n",
    "                {'src':'src', 'obs':'obs'}, identifiant='id')\n",
    "#update tmja\n",
    "dira.update_bdd('comptage', 'indic_agrege', dira.creer_valeur_txt_update(donneesAgregeesUpdate.assign(id_comptag_uniq=donneesAgregeesUpdate.id)\n",
    "                                                                         , ['id_comptag_uniq', 'tmja']), {'valeur':'tmja'}, identifiant='id_comptag_uniq',\n",
    "                filtre = \"indicateur='tmja'\")\n",
    "#update pc_pl\n",
    "dira.update_bdd('comptage', 'indic_agrege', dira.creer_valeur_txt_update(donneesAgregeesUpdate.assign(id_comptag_uniq=donneesAgregeesUpdate.id)\n",
    "                                                                         , ['id_comptag_uniq', 'pc_pl']), {'valeur':'pc_pl'}, identifiant='id_comptag_uniq',\n",
    "                filtre = \"indicateur='pc_pl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserer comptages\n",
    "dira.insert_bdd('local_otv_boulot', 'comptage', 'comptage',dira.creer_comptage(donneesAgregeesInsert.id_comptag.unique(), dira.annee, 'carto dira 2020', 'tv/pl', obs=donneesAgregeesInsert.obs.tolist()))\n",
    "dira.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege',dira.structureBddOld2NewForm(donneesAgregeesInsert, dira.annee,['id_comptag', 'annee', 'fichier'],['tmja', 'pc_pl'], 'agrege'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## *Donnees horaires*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time dfTousFichier,idCptNonAffectes,dblATraiter=dira.concatTousFichierHoraire()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vérifier\n",
    "dblATraiter\n",
    "idCptNonAffectes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Séparer les données horaires entres comptages existants et comptages a creer\n",
    "dfHoraireIdConnus, dfHoraireIdsInconnus=dira.scinderComptagExistant(dfTousFichier, dira.annee, table='comptage')\n",
    "dfHoraireIdsInconnus.rename(columns={'type_veh':'indicateur'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comptages a creer\n",
    "#mise en forme des donnees horaire vers du tmja\n",
    "dfTmjaPcpl=tmjaDepuisHoraire(dfHoraireIdsInconnus)\n",
    "dfMeltInconnusPeriode=periodeDepuisHoraire(dfHoraireIdsInconnus)\n",
    "\n",
    "#scinder les tablesvers comptages et indics_agrege\n",
    "#creer les comptages manquants puis recuperer les ids correspondants\n",
    "dfToutTable=dfTmjaPcpl.merge(dfMeltInconnusPeriode[['id_comptag', 'periode']], on=['id_comptag']).assign(\n",
    "    src='tmja reconstitue depuis donnees horaires 2020', type_veh='tv/pl')\n",
    "dfComptages=dfToutTable[['id_comptag','annee', 'periode', 'src', 'type_veh']].drop_duplicates(['id_comptag','annee', 'periode', 'src', 'type_veh'])\n",
    "dira.insert_bdd('local_otv_boulot', 'comptage', 'comptage', dfComptages)\n",
    "dfIdCptUniqsNew=dira.recupererIdUniqComptage(dfComptages.id_comptag.tolist(), '2020', 'local_otv_boulot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserer les indicateurs agreges\n",
    "dfIndicAgreges=dfToutTable[['id_comptag', 'annee', 'indicateur', 'valeur']].merge(dfHoraireIdsInconnus.assign(fichier=dfHoraireIdsInconnus.fichier.apply(\n",
    "    lambda x : ';'.join(set(x.split('.xls'))).strip(';'))).groupby('id_comptag').fichier.agg(lambda x : ';'.join(set(tuple(x)))).reset_index(), on='id_comptag').merge(\n",
    "    dfIdCptUniqsNew, on=['id_comptag','annee']).rename(columns={'id':'id_comptag_uniq'}).drop(['id_comptag', 'annee'], axis=1)\n",
    "dira.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege', dfIndicAgreges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#refaire tourner  l'identification des comptages existant ou non (nromalement tout le monde defvrait etre existant) puis inserer\n",
    "dfHoraireIdConnus, dfHoraireIdsInconnus=dira.scinderComptagExistant(dfTousFichier, dira.annee, table='comptage')\n",
    "dira.insert_bdd('local_otv_boulot', 'comptage', 'indic_horaire',dfHoraireIdConnus.drop(['id_comptag', 'index', 'annee'], axis=1).assign(fichier=dfHoraireIdConnus.fichier.apply(\n",
    "    lambda x : ';'.join(set(x.split('.xls'))).strip(';'))).rename(columns={'type_veh':'indicateur'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Année 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOUVELLE SOURCE DE DONNEES VIA Christophe Damas et DtecTV**\n",
    "on va aussi chercher à obtenir les données DIRA, mais d'abord on puet checker celles contenues dans les fichiersde TV ici : \n",
    "Q:\\DAIT\\TI\\DREAL33\\2021\\OTV\\Doc_travail\\Donnees_sources\\DIRA\\Donnees_Tipi_TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donneesMinutes=pd.read_csv(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\DIRA\\tipi_alienor_raw.v2.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#liste des stations TIPI\n",
    "listIdCompteurTipi=donneesMinutes.PME_ID.unique()\n",
    "#liste des stations OTV\n",
    "with ct.ConnexionBdd('local_otv_boulot') as c : \n",
    "    listObsSupl=pd.read_sql(\"select distinct id_comptag, id_cpt, obs_supl from comptage.compteur where gestionnai='DIRA'\", c.sqlAlchemyConn)\n",
    "listStationOtvBrut=listObsSupl.obs_supl.apply(lambda x : x.split(';')[1].split('station : ')[1] if not pd.isnull(x) and 'EMC' not in x and ';' in x else x).unique()\n",
    "listStationOtvBrut2=[e.split(',') for e in listStationOtvBrut if e and re.search('^M.*\\.._.*$', e)]\n",
    "listStationOtv=[a.strip().replace('_','') for b in listStationOtvBrut2 for a in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#station TIPI non présentes dans OTV : \n",
    "StationTipiHorsOTV=[s for s in listIdCompteurTipi if s not in listStationOtv]\n",
    "StationOtvHorsTipi=[s for s in listStationOtv if s not in listIdCompteurTipi]\n",
    "StationOtvTipi=[s for s in listIdCompteurTipi if s in listStationOtv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "<a id=\"8\" ></a>\n",
    "# ***DIRCO***\n",
    "- Année 2019 : \n",
    "> il existe trois sorte de données, TMJA, TMJM et horaires. les données TMJA et TMJM chaque source de données à sonpropre fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2019\n",
    "fichierMja=r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\DIRCO\\TMJA DIRCO-NA 2019_unfused.csv'\n",
    "fichierMjM=r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\DIRCO\\TMJM DIRCO-NA 2019.ods'\n",
    "dossierHoraire=r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\DIRCO\\données dirco'\n",
    "dirco=it.Comptage_Dirco(fichierMja,fichierMjM,dossierHoraire,'2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2020\n",
    "fichierMja=r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\DIRCO\\TMJA DIRCO 2020 NA.ods'\n",
    "fichierMjM=r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\DIRCO\\TMJM DIRCO 2020 NA.ods'\n",
    "dossierHoraire=r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\DIRCO\\Re_ Observatoire des trafics routiers DREAL NA 2020'\n",
    "dirco=it.Comptage_Dirco(fichierMja,fichierMjM,dossierHoraire,'2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## TMJA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import des données et mise en forme des données\n",
    "dfTrafic=dirco.miseEnFormeMJA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#verifier et creer des compteurs si besoin\n",
    "dfIdsConnus, dfIdsInconnus=dirco.scinderComptagExistant(dfTrafic, '2020', gest='DIRCO')\n",
    "#modfi de la mise en forme\n",
    "dfIdsConnus['obs_supl']=dfIdsConnus.merge(dirco.existant[['obs_supl', 'id_comptag']], on='id_comptag').apply(lambda x : x['obs_supl_y']+';'+x['obs_supl_x'] if x['obs_supl_y'] else x['obs_supl_x'], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#MaJ de l'obs_supl\n",
    "dirco.update_bdd('comptage', 'compteur', dirco.creer_valeur_txt_update(dfIdsConnus.loc[~dfIdsConnus.obs_supl.isna()], ['id_comptag', 'obs_supl']), {'obs_supl':'obs_supl'})\n",
    "#creation des comptages\n",
    "dirco.insert_bdd('local_otv_boulot', 'comptage', 'comptage', dirco.creer_comptage(dfIdsConnus.id_comptag.tolist(), dirco.annee, 'tableau TMJA DIRCO', 'tv/pl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#insertion des données agrégées\n",
    "dirco.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege', \n",
    "                 dirco.structureBddOld2NewForm(dfIdsConnus, '2020', ['id_comptag', 'fichier', 'annee'], ['tmja', 'pc_pl'], 'agrege'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## TMJM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2019\n",
    "dfMensuel=dirco.indicateurGlobalFichierMJM('gti_otv_pg11','3-N145-9+573')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirco.insert_bdd('gti_otv_pg11','comptage', 'na_2010_2019_mensuel', dfMensuel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2020\n",
    "dfMensuel=dirco.indicateurGlobalFichierMJM('local_otv_boulot', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trouver les comptages inconnus en 2020, verifier qu'il ne manque pas de compteur (termine a la main)\n",
    "dfIdsConnus, dfIdsInconnus=dirco.scinderComptagExistant(dfMensuel, '2020', 'comptage', gest='DIRCO')\n",
    "dfIdsInconnus.loc[~dfIdsInconnus.id_comptag.isin(dirco.existant.id_comptag.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creer les commptages inconnus (que si les compteurs existent)\n",
    "dirco.insert_bdd('local_otv_boulot', 'comptage', 'comptage', dirco.creer_comptage(dfIdsInconnus.id_comptag.unique(), dirco.annee, 'tableau TMJM DIRCO', 'tv/pl', obs='1 seul sens disponible'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trouver les comptages ayant des donnees mensuelles mais pas de donnees TMJA\n",
    "dfCptSansTmja=dirco.recupererComptageSansTrafic(dfIdsConnus.id_comptag.tolist(), '2020')\n",
    "dfCptSansTmja2=dfIdsConnus.loc[dfIdsConnus.id_comptag.isin(dfCptSansTmja.id_comptag.tolist())].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculer les indicateurs agreges des comptages sans tmja\n",
    "dfCptSansTmja2['tmja']=dfCptSansTmja2.loc[dfCptSansTmja2.donnees_type=='tmja'].apply(lambda x : int(mean([x[e] for e in dfCptSansTmja2.columns if e not in ('id_comptag', 'donnees_type', 'annee', 'id_comptag_uniq', 'obs')])), axis=1)\n",
    "dfCptSansTmja2['pc_pl']=dfCptSansTmja2.loc[dfCptSansTmja2.donnees_type=='pc_pl'].apply(lambda x : round(mean([x[e] for e in dfCptSansTmja2.columns if e not in ('id_comptag', 'donnees_type', 'annee', 'id_comptag_uniq', 'obs') and not pd.isnull(x[e])]),2), axis=1)\n",
    "#dfCptSansTmja2['valeur']=dfCptSansTmja2.apply(lambda x : x['tmja'] if not pd.isnull(x['tmja']) else x['pc_pl'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserer\n",
    "#agerege\n",
    "dirco.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege', dfCptSansTmja2.rename(columns={'donnees_type':'indicateur'}).assign(fichier=os.path.basename(dirco.fichierTmjm))[['id_comptag_uniq','indicateur','valeur','obs', 'fichier']])\n",
    "#mensuel\n",
    "dirco.insert_bdd('local_otv_boulot', 'comptage', 'indic_mensuel', dirco.structureBddOld2NewForm(dfIdsConnus.assign(fichier=os.path.basename(dirco.fichierTmjm)), \n",
    "                        dirco.annee, ['id_comptag', 'annee','obs', 'fichier', 'donnees_type'], ['janv', 'fevr', 'mars', 'avri', 'mai', 'juin', 'juil', 'aout', 'sept',\n",
    "       'octo', 'nove', 'dece'], 'mensuel' ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Horaire\n",
    "on ne dispose que de donnees TV, et il faut au prealable joindre les id_comptagavec les code_sation des donnes horaire. POur ça on utilise le fichier de tmja comme pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFichierTmja=dirco.miseEnFormeFichierTmjaPourHoraire()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicoCptOkTot,dicoCptErrorTot=dirco.tousFichierHoraires(dfFichierTmja)\n",
    "dicoCptErrorTot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trouver les comptages inconnus en 2020, verifier qu'il ne manque pas de compteur (termine a la main)\n",
    "dirco.corresp_nom_id_comptag(dirco.df_attr_horaire)\n",
    "dfIdsConnus, dfIdsInconnus=dirco.scinderComptagExistant(dirco.df_attr_horaire, '2020', 'comptage', gest='DIRCO')\n",
    "dfIdsInconnus.loc[~dfIdsInconnus.id_comptag.isin(dirco.existant.id_comptag.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfIdsInconnus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creer les commptages inconnus (que si les compteurs existent)\n",
    "dirco.insert_bdd('local_otv_boulot', 'comptage', 'comptage', dirco.creer_comptage(dfIdsInconnus.id_comptag.unique(), dirco.annee, 'donnees horaires DIRCO', 'tv', obs='tmja recalcule a partirdes donnees horaires'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trouver les comptages ayant des donnees horaires mais pas de donnees TMJA\n",
    "dfCptSansTmja=dirco.recupererComptageSansTrafic(dfIdsConnus.id_comptag.tolist(), '2020')\n",
    "dfCptSansTmja2=dfIdsConnus.loc[dfIdsConnus.id_comptag.isin(dfCptSansTmja.id_comptag.tolist())].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mettre en forme les données\n",
    "dfTmja=dfCptSansTmja2[['id_comptag_uniq', 'jour','fichier']+attributsHoraire].assign(tmj=lambda x : sum([x[e] for e in dfCptSansTmja2.columns if e in attributsHoraire])).groupby(['id_comptag_uniq', 'fichier']\n",
    "    ).agg(trafSum=pd.NamedAgg(column='tmj',aggfunc='sum'), \n",
    "        nbJour=pd.NamedAgg(column='jour',aggfunc='count'))\n",
    "dfTmja['valeur']=round(dfTmja['trafSum']/dfTmja['nbJour'])\n",
    "dfTmja['indicateur']='tmja'\n",
    "dfTmja['obs']='tmja recalcule depuis donnees horaires'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserer les donnes agregees non connue\n",
    "dirco.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege',dfTmja.drop(['trafSum', 'nbJour'], axis=1).reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserer les donnes horaires\n",
    "dirco.insert_bdd('local_otv_boulot', 'comptage', 'indic_horaire',dirco.structureBddOld2NewForm(dirco.df_attr_horaire, dirco.annee, ['id_comptag', 'annee'], ['toto'], 'horaire'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"9\" ></a>\n",
    "# ***DIRSO***\n",
    "- Année 2020 : \n",
    "> il n'y a que 2 points, dont les données sont téléchargées directement sur le site de la DIRCO (cf src.txt sur Box)\n",
    "les 2 seuls poijnts qui nous interessent sont MAZERES N524 8+890 et  LAPEYRADE N524 64+800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ficherMensuel=r'C:\\Users\\martin.schoreisz\\Box\\Dossier_Perso\\OTV\\donnees_gestionnaires\\DIRSO\\en_cours\\hors_convention\\tmja_2020_cumule.xls'\n",
    "dirso=it.Comptage(ficherMensuel)\n",
    "dfMens=pd.read_excel(dirso.fichier, skiprows=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMensSo=dfMens.iloc[sorted([a for a in dfMens.loc[dfMens['Intitulé du PM'].isin(('MAZERES', 'LAPEYRADE'))].index]+[a-1 for a in dfMens.loc[dfMens['Intitulé du PM'].isin(\n",
    "    ('MAZERES', 'LAPEYRADE'))].index])].copy()\n",
    "dfMensSo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMensSoTmja=dfMensSo.loc[~dfMensSo.Evts.isna()][[a for b in it.dico_mois.values() for a in b if a in dfMensSo.columns]].assign(\n",
    "    donnees_type='tmja', id_comptag=['33-N524-8+890','40-N524-64+800'],fichier=os.path.basename(ficherMensuel), annee='2020').T.drop_duplicates().T\n",
    "dfMensSoPcpl=dfMensSo.loc[dfMensSo.Evts.isna()][[a for b in it.dico_mois.values() for a in b if a in dfMensSo.columns]].applymap(lambda x : x*100).assign(\n",
    "    donnees_type='pc_pl', id_comptag=['33-N524-8+890','40-N524-64+800'],fichier=os.path.basename(ficherMensuel), annee='2020').T.drop_duplicates().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dirso.insert_bdd('local_otv_boulot', 'comptage', 'indic_mensuel',\n",
    "                 dirso.structureBddOld2NewForm(pd.concat([dirso.renommerMois(dfMensSoPcpl),dirso.renommerMois(dfMensSoTmja)]), '2020', ['id_comptag', 'annee', 'donnees_type'], \n",
    "                                               [k for k in it.dico_mois.keys()], 'mensuel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.read_json(dfMensSo.loc[~dfMensSo.Evts.isna()][[a for b in it.dico_mois.values() for a in b if a in dfMensSo.columns]].T.drop_duplicates().T.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***TESTS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DETAILS OPERATIONS CD87\n",
    "\n",
    "#regrouper les différentes données issues de ficiers et les ajouter au dico\n",
    "for k, v in d87.dico_voie.items() : \n",
    "    for i,e in enumerate(v) : \n",
    "        if len(e['fichiers'])==1 : \n",
    "            print(e['fichiers'][0])\n",
    "            obj_fim=it.FIM(os.path.join(d87.dossier,e['fichiers'][0]))\n",
    "            try : \n",
    "                obj_fim.resume_indicateurs()\n",
    "            except obj_fim.fim_PasAssezMesureError : \n",
    "                continue\n",
    "            except Exception as ex : \n",
    "                print(f\"erreur : {ex} \\n dans fichier : {e['fichiers'][0]}\")\n",
    "            e['tmja'], e['pc_pl'], e['date_debut'], e['date_fin']=obj_fim.tmja, obj_fim.pc_pl, obj_fim.date_debut,obj_fim.date_fin\n",
    "        elif len(e['fichiers'])>1 :\n",
    "            list_tmja=[]\n",
    "            list_pc_pl=[]\n",
    "            for f in e['fichiers'] : \n",
    "                obj_fim=it.FIM(os.path.join(d87.dossier,f))\n",
    "                print(f)\n",
    "                try : \n",
    "                    obj_fim.resume_indicateurs()\n",
    "                except (obj_fim.fim_PasAssezMesureError,obj_fim.fimNbBlocDonneesError)  : \n",
    "                    continue\n",
    "                except Exception as ex : \n",
    "                    print(f\"erreur : {ex} \\n dans fichier : {f}\")\n",
    "                list_tmja.append(obj_fim.tmja)\n",
    "                list_pc_pl.append(obj_fim.pc_pl)\n",
    "            e['tmja'], e['pc_pl'], e['date_debut'], e['date_fin']=int(mean(list_tmja)), round(mean(list_pc_pl),2),np.NaN, np.NaN\n",
    "\n",
    "#renseigner le type de poste\n",
    "for k, v in d87.dico_voie.items() : \n",
    "    for e in v : \n",
    "        if len(e['fichiers']) > 4 :\n",
    "            e['type_poste']='permanent'\n",
    "        elif 1<len(e['fichiers'])<=4 : \n",
    "            e['type_poste']='tournant'\n",
    "        elif len(e['fichiers'])== 1 :\n",
    "            e['type_poste']='ponctuel'\n",
    "        else : \n",
    "            e['type_poste']='NC'\n",
    "\n",
    "#faire une df avec les points de comptage\n",
    "d87.df_attr=pd.DataFrame([[k, e['pr'], e['abs'], e['tmja'], e['pc_pl'], e['type_poste'],\n",
    "                      e['date_debut'],e['date_fin']] for k, v in d87.dico_voie.items() for e in v if 'tmja' in e.keys()], \n",
    "             columns=['route','pr','absc','tmja','pc_pl','type_poste','date_debut','date_fin'])\n",
    "d87.df_attr['id_comptag']=d87.df_attr.apply(lambda x :'87-'+x['route']+'-'+str(x['pr'])+'+'+str(x['absc']), axis=1)\n",
    "\n",
    "#filtre cpt ponctuel\n",
    "d87.df_attr=d87.df_attr.loc[d87.df_attr.apply(lambda x : x['date_debut'].month not in [7,8] and x['date_fin'].month not in [7,8], \n",
    "                                                         axis=1)].copy()\n",
    "\n",
    "#fare le tri avec les comptages existants : \n",
    "#recuperer les compmtages existants\n",
    "d87.comptag_existant_bdd('gti_otv_pg11', 'na_2010_2018_p', schema='comptage',dep='87', type_poste=False)\n",
    "d87.df_attr_update=d87.df_attr.loc[d87.df_attr.id_comptag.isin(d87.existant.id_comptag.tolist())].copy()\n",
    "d87.df_attr_insert=d87.df_attr.loc[~d87.df_attr.id_comptag.isin(d87.existant.id_comptag.tolist())].copy()\n",
    "#obtenir une cle de correspondace pour les comptages tournants et permanents\n",
    "df_correspondance=d87.corresp_old_new_comptag('gti_otv_pg11', 'public','d87_cpt_temp','lineaire.traf2017_bdt87_ed17_l',\n",
    "                                'referentiel', 'troncon_route_bdt87_ed17_l','troncon_route_bdt87_ed17_l_vertices_pgr','id')\n",
    "\n",
    "#verifier si cette clé n'existent pas deja dans la table de correspondance et passer les nouvelles dedans\n",
    "rqt_corresp_comptg='select * from comptage.corresp_id_comptag'\n",
    "with ct.ConnexionBdd('gti_otv_pg11') as c:\n",
    "    corresp_comptg=pd.read_sql(rqt_corresp_comptg, c.sqlAlchemyConn)\n",
    "df_correspondance=df_correspondance.loc[~df_correspondance['id_comptag'].isin(corresp_comptg.id_gest.tolist())]\n",
    "if not df_correspondance.empty():\n",
    "    d87.insert_bdd('gti_otv_pg11', 'comptage', 'corresp_id_comptag', \n",
    "               df_correspondance.rename(columns={'id_comptag_lin':'id_gti','id_comptag':'id_gest'})[['id_gest','id_gti']])\n",
    "\n",
    "#faire la correspondance entre les noms de comptage\n",
    "d87.corresp_nom_id_comptag('gti_otv_pg11',d87.df_attr)\n",
    "\n",
    "#recalculer les insert et update\n",
    "d87.df_attr_update=d87.df_attr.loc[d87.df_attr.id_comptag.isin(d87.existant.id_comptag.tolist())].copy()\n",
    "d87.df_attr_insert=d87.df_attr.loc[~d87.df_attr.id_comptag.isin(d87.existant.id_comptag.tolist())].copy()\n",
    "\n",
    "#mettre en forme pour update\n",
    "d87.df_attr_update['obs']=d87.df_attr_update.apply(lambda x : x['date_debut'].strftime('%d/%m/%Y')+'-'+ x['date_fin'].strftime('%d/%m/%Y') if not pd.isnull(x['date_debut']) else '', axis=1)\n",
    "d87.df_attr_update.loc[d87.df_attr_update.pc_pl.isna(),'obs']='pc_pl inconnu'\n",
    "d87.df_attr_update.loc[d87.df_attr_update.pc_pl.isna(),'pc_pl']=-99\n",
    "\n",
    "#preparer update\n",
    "valeurs_txt=d87.creer_valeur_txt_update(d87.df_attr_update, ['id_comptag','tmja','pc_pl','obs'])\n",
    "dico_attr={'tmja_2018':'tmja','pc_pl_2018':'pc_pl','obs_2018':'obs'}\n",
    "#update\n",
    "d87.update_bdd('gti_otv_pg11', 'comptage', 'na_2010_2018_p', valeurs_txt,dico_attr)\n",
    "\n",
    "#mettre en forme le insert\n",
    "dbl=d87.df_attr_insert.loc[d87.df_attr_insert.duplicated('id_comptag', False)].copy()\n",
    "ss_dbl=d87.df_attr_insert.loc[~d87.df_attr_insert.index.isin(dbl.index.tolist())].copy()\n",
    "dbl=dbl.dropna()\n",
    "dbl_traite=dbl.loc[dbl.tmja==dbl.groupby('id_comptag').tmja.transform(max)].drop_duplicates().copy()\n",
    "d87.df_attr_insert=pd.concat([dbl_traite,ss_dbl], axis=0, sort=False)\n",
    "d87.df_attr_insert.pc_pl.fillna(-99, inplace=True)\n",
    "annee='2018'\n",
    "d87.df_attr_insert['dep']='87'\n",
    "d87.df_attr_insert['reseau']='RD'\n",
    "d87.df_attr_insert['gestionnai']='CD87'\n",
    "d87.df_attr_insert['concession']='N'\n",
    "d87.df_attr_insert['obs']=d87.df_attr_insert.apply(lambda x : f\"\"\"nouveau_point,{x['date_debut'].strftime(\"%d/%m/%Y\")}-{x['date_fin'].strftime(\"%d/%m/%Y\")}\"\"\" if not (pd.isnull(x['date_debut']) and  pd.isnull(x['date_fin'])) else None,axis=1)\n",
    "d87.df_attr_insert.rename(columns={'absc' : 'abs', 'tmja':'tmja_'+annee,'pc_pl':'pc_pl_'+annee,'obs':'obs_'+annee},inplace=True)\n",
    "d87.df_attr_insert.drop(['date_debut','date_fin','route'],axis=1,inplace=True)\n",
    "\n",
    "#mettre à jour la geom\n",
    "d87.maj_geom('gti_otv_pg11', 'comptage', 'na_2010_2018_p', dep='87')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
