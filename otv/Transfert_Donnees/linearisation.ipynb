{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINEARISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys #c'est pas propre mais pour le moment pour importer mes modules perso dans le notebook je ne sais pas faire\n",
    "sys.path.append(r'C:\\Users\\martin.schoreisz\\git\\Outils\\Outils\\Martin_Perso')\n",
    "sys.path.append(r'C:\\Users\\martin.schoreisz\\git\\otv\\otv\\Transfert_Donnees')\n",
    "import agrege_troncon as at\n",
    "import Connexion_Transfert as ct\n",
    "import matplotlib, os, fiona\n",
    "import geopandas as gp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CD17\n",
    "Réutiliser les comptages importés grace au Notebooj Import_trafics (chap cd17) et les données de troncons elemnetaires issues du notebook agrege_troncon pour déterminer les nouveaux id_comptag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import des données de troncon elem (à modifier par imporft depuis Bdd quand le transfert vers Bdd en sortie d'agreg_troncon sera calé)\n",
    "gdf_traf=gp.read_file(r'D:\\temp\\otv\\test_linearisation\\df_lignes_fin_tot.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import des points de comptages depuis la Bdd\n",
    "with ct.ConnexionBdd('gti_otv') as c :\n",
    "    rqt=\"select * from comptage.na_2010_2017_p where dep='17' and geom is not null\"\n",
    "    gdf_pt_cpt = gp.read_postgis(rqt, c.connexionPsy)\n",
    "#mise en forme attributs\n",
    "def convert_tmja(df) : \n",
    "    for annee in [a for a in range(2017, 2009,-1)]+['autre'] :\n",
    "        attr='tmja_'+str(annee)\n",
    "        if ~np.isnan(df[attr]) : \n",
    "            return (df[attr], annee)\n",
    "df_adj=gdf_pt_cpt.apply(lambda x : convert_tmja(x), axis=1,result_type='expand')\n",
    "df_adj.columns=['tmja_recent','annee_tmja_recent']\n",
    "gdf_pt_cpt=gdf_pt_cpt.merge(df_adj, left_index=True, right_index=True)#[['id_comptag','geom','type_poste','tmja_recent','annee_tmja_recent' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtre des points ponctuels en été\n",
    "pt_pctuels_ete=gdf_pt_cpt.loc[gdf_pt_cpt['type_poste']=='ponctuel'].copy()\n",
    "def verif_ete(tmja_2015, obs_2015, tmja_2016, obs_2016) :\n",
    "    if tmja_2016 > 0 :\n",
    "        return any([a in ['July','August']  for a in [pd.to_datetime(obs_2016.split(',')[1].split('-')[i], format='%d/%m/%Y').month_name()for i in [0,1]]])\n",
    "    elif tmja_2015 > 0 :\n",
    "        return any([a in ['July','August']  for a in [pd.to_datetime(obs_2015.split(',')[1].split('-')[i], format='%d/%m/%Y').month_name()for i in [0,1]]])\n",
    "    else : return False\n",
    "pt_pctuels_ete['ete']=pt_pctuels_ete.apply(lambda x : verif_ete(x['tmja_2015'],x['obs_2015'], x['tmja_2016'], x['obs_2016']), axis=1)\n",
    "pt_pctuels_ete=pt_pctuels_ete.loc[~pt_pctuels_ete['ete']].copy()\n",
    "gdf_pt_cpt=gdf_pt_cpt.loc[gdf_pt_cpt.index.isin(pt_pctuels_ete.index.tolist()+gdf_pt_cpt.loc[gdf_pt_cpt['type_poste']!='ponctuel'].index.tolist())].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\martin.schoreisz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\lib\\function_base.py:2167: RuntimeWarning: invalid value encountered in ? (vectorized)\n",
      "  outputs = ufunc(*inputs)\n"
     ]
    }
   ],
   "source": [
    "#croisement point et lignes (sur labase d'un buffer de 0.5m)\n",
    "gdf_pt_cpt.geometry=gdf_pt_cpt.buffer(0.5)\n",
    "gdf_traf_pt=gp.sjoin(gdf_traf,gdf_pt_cpt,how=\"left\", op='intersects' )[['id_ign','tmja', 'importance',\n",
    "            'id_comptag_left', 'id_tronc_e', 'id_comptag_right','type_poste','tmja_recent','annee_tmja_recent','source','target', 'geometry']].rename(\n",
    "columns={'id_comptag_left':'id_cpt_lin','id_comptag_right': 'id_cpt_pt','tmja':'tmja_lin'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recherch des tronc_elem avec plusieurs points\n",
    "gdf_traf_pt_notna=gdf_traf_pt.loc[~gdf_traf_pt['id_cpt_pt'].isna()].copy()\n",
    "tronc_elem_pt_cpt=gdf_traf_pt_notna.sort_index().groupby('id_tronc_e').agg({'id_cpt_pt' : lambda x : tuple(x),\n",
    "                                       'type_poste' : lambda x : tuple(x),\n",
    "                                        'tmja_recent' : lambda x : tuple(x),\n",
    "                                        'annee_tmja_recent' : lambda x : tuple(x)})\n",
    "trc_elem_multipt=tronc_elem_pt_cpt.loc[tronc_elem_pt_cpt.apply(lambda x : len(x['id_cpt_pt'])>1,axis=1)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mise en forme des trocnon supportant plusieurs point : \n",
    "    #gestion des trocnon avec plusieurs points differntes (on garde le ponctuele de trafic max de l'annee la plus recente si que des ponctuels, sinon le tournant ou permanent)\n",
    "    #verif de la validite des points en comprant les valeurs de trafic entre elle: si un des trafics est sup 1000 et que la variation est sup 30 %, on n'affecte pas\n",
    "def cpt_final (type_poste,id_comptag_right,tmja_recent,annee_tmja_recent ): \n",
    "    tmja_recent=np.array(tmja_recent) \n",
    "    id_comptag_right=np.array(id_comptag_right)\n",
    "    mask_tmja = (tmja_recent==max(tmja_recent))\n",
    "    if all(np.unique(type_poste)=='ponctuel') :\n",
    "        mask_annee=np.array(annee_tmja_recent)==max(annee_tmja_recent)\n",
    "        if all(mask_annee):#il n'y a qu'une seule annee\n",
    "            if all(mask_tmja) : \n",
    "                return id_comptag_right[0]\n",
    "            else : \n",
    "                return id_comptag_right[mask_tmja][0]\n",
    "        else : #il y a pluseurs annee dc on ne garde que le max de la bonne annee\n",
    "            return id_comptag_right[mask_tmja]\n",
    "    else :\n",
    "        mask_type_poste=np.isin(np.array(type_poste),['permanent', 'tournant'])#on trouve le(s) poste(s) non ponctuel\n",
    "        return id_comptag_right[mask_type_poste][0]\n",
    "#verif de la validite des points en comprant les valeurs de trafic entre elle: si un des trafics est sup 1000 et que la variation est sup 30 %, on n'affecte pas\n",
    "trc_elem_multipt['id_cpt_final']=trc_elem_multipt.apply(lambda x: cpt_final(\n",
    "    x['type_poste'], x['id_cpt_pt'], x['tmja_recent'], x['annee_tmja_recent']), axis=1)\n",
    "trc_elem_multipt['valide']=trc_elem_multipt.apply(lambda x : (False if abs(100-(min(x['tmja_recent'])/max(x['tmja_recent'])*100))>30 and\n",
    "                                                                    max(x['tmja_recent'])>1000 and all(np.unique(x['type_poste'])=='ponctuel') else True), axis=1)\n",
    "trc_elem_multipt=trc_elem_multipt.loc[trc_elem_multipt['valide']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtention de la df des id_comptage_pt par tronc_elem\n",
    "tronc_elem_pt_cpt.update(trc_elem_multipt.drop('id_cpt_pt',axis=1).rename(columns={'id_cpt_final':'id_cpt_pt'})[['id_cpt_pt']])\n",
    "tronc_elem_pt_cpt['id_cpt_pt']=tronc_elem_pt_cpt.apply(lambda x : x['id_cpt_pt'][0] if isinstance(x['id_cpt_pt'], tuple) else x['id_cpt_pt'],axis=1) #uniformisation du type de données en str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfert de l'id_cpt_pt final dans la df source\n",
    "gdf_traf_pt_final=gdf_traf_pt[['id_ign','importance', 'id_cpt_lin','tmja_lin', 'id_tronc_e','geometry','source','target']].merge(tronc_elem_pt_cpt[['id_cpt_pt']], how='left',left_on='id_tronc_e', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pour info, ligne ign non linéarisée qui le deviennent\n",
    "gdf_creation_idcpt=gdf_traf_pt_final.loc[(gdf_traf_pt_final['id_cpt_lin'].isna()) & (~gdf_traf_pt_final['id_cpt_pt'].isna())]\n",
    "#pour info, ligne ign linéarisée qui le sont toujours, mais peut avec un nouvel id_ign\n",
    "gdf_variation_idcpt=gdf_traf_pt_final.loc[(~gdf_traf_pt_final['id_cpt_lin'].isna()) & (~gdf_traf_pt_final['id_cpt_pt'].isna()) & (gdf_traf_pt_final['id_cpt_pt']!=gdf_traf_pt_final['id_cpt_lin'])].sort_values('id_cpt_lin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mettre à jour les lignes des troncons qui appartiennent à des id_comptag qui supporte un nouvel id_cpt\n",
    "exemple avec l'idcomptag '17-D734-19+620'\n",
    "1. isoler les lignes qui sont relaticves à l'id_cpt_lin et trouver l'importance la plus représentée\n",
    "1. trouver les lignes qui intersectent celles de l'idcompatg etudie dont l'importance est = ou sup\n",
    "1. faire un graph avec les lignes de l'id_cpt_lin et celles qui interectent avec la bonne importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isoler les lignes qui sont relaticves à l'id_cpt_lin et trouver l'importance la plus représentée\n",
    "lgn_idcpt_lin=gdf_traf.loc[gdf_traf['id_comptag']=='17-D734-19+620'].copy()\n",
    "importance=[k for k, v in Counter(lgn_idcpt_lin.importance.tolist()).items() if v==max( Counter(lgn_idcpt_lin.importance.tolist()).values())][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trouver les lignes qui intersectent celles de l'idcompatg etudie dont l'importance est = ou sup\n",
    "    #list des source / target de l'idcomptage\n",
    "list_src_tgt=lgn_idcpt_lin.source.tolist()+lgn_idcpt_lin.target.tolist()\n",
    "df_lgn_interscts=gdf_traf.loc[((gdf_traf['source'].isin(list_src_tgt)) | (gdf_traf['target'].isin(list_src_tgt))) & (gdf_traf['importance'] <=importance) &\n",
    "                             (~gdf_traf['id_ign'].isin(lgn_idcpt_lin.id_ign.tolist()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "#faire un graph avec les lignes de l'id_cpt_lin et celles qui interectent avec la bonne importance\n",
    "    #regrouper l'ensemble des lignes dans une df \n",
    "ligne_pr_graph=gdf_traf.loc[gdf_traf['id_ign'].isin(df_lgn_interscts.id_ign.tolist()+lgn_idcpt_lin.id_ign.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
