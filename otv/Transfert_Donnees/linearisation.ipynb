{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINEARISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys #c'est pas propre mais pour le moment pour importer mes modules perso dans le notebook je ne sais pas faire\n",
    "sys.path.append(r'C:\\Users\\martin.schoreisz\\git\\Outils\\Outils\\Martin_Perso')\n",
    "sys.path.append(r'C:\\Users\\martin.schoreisz\\git\\otv\\otv\\Transfert_Donnees')\n",
    "import agrege_troncon as at\n",
    "import Connexion_Transfert as ct\n",
    "import matplotlib, os, fiona\n",
    "import geopandas as gp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from sqlalchemy import Table, Column, Integer, String, Float,MetaData\n",
    "from geoalchemy2 import Geometry\n",
    "from shapely.wkt import dumps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CD17\n",
    "Réutiliser les comptages importés grace au Notebooj Import_trafics (chap cd17) et les données de troncons elemnetaires issues du notebook agrege_troncon pour déterminer les nouveaux id_comptag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import des données de troncon elem (à modifier par imporft depuis Bdd quand le transfert vers Bdd en sortie d'agreg_troncon sera calé)\n",
    "gdf_traf=gp.read_file(r'D:\\temp\\otv\\test_linearisation\\df_lignes_fin_tot.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import des points de comptages depuis la Bdd\n",
    "with ct.ConnexionBdd('gti_otv') as c :\n",
    "    rqt=\"select * from comptage.na_2010_2017_p where dep='17' and geom is not null\"\n",
    "    gdf_pt_cpt = gp.read_postgis(rqt, c.connexionPsy)\n",
    "#mise en forme attributs\n",
    "def convert_tmja(df) : \n",
    "    for annee in [a for a in range(2017, 2009,-1)]+['autre'] :\n",
    "        attr='tmja_'+str(annee)\n",
    "        if ~np.isnan(df[attr]) : \n",
    "            return (df[attr], annee)\n",
    "df_adj=gdf_pt_cpt.apply(lambda x : convert_tmja(x), axis=1,result_type='expand')\n",
    "df_adj.columns=['tmja_recent','annee_tmja_recent']\n",
    "gdf_pt_cpt=gdf_pt_cpt.merge(df_adj, left_index=True, right_index=True)#[['id_comptag','geom','type_poste','tmja_recent','annee_tmja_recent' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtre des points ponctuels en été\n",
    "pt_pctuels_ete=gdf_pt_cpt.loc[gdf_pt_cpt['type_poste']=='ponctuel'].copy()\n",
    "def verif_ete(tmja_2015, obs_2015, tmja_2016, obs_2016) :\n",
    "    if tmja_2016 > 0 :\n",
    "        return any([a in ['July','August']  for a in [pd.to_datetime(obs_2016.split(',')[1].split('-')[i], format='%d/%m/%Y').month_name()for i in [0,1]]])\n",
    "    elif tmja_2015 > 0 :\n",
    "        return any([a in ['July','August']  for a in [pd.to_datetime(obs_2015.split(',')[1].split('-')[i], format='%d/%m/%Y').month_name()for i in [0,1]]])\n",
    "    else : return False\n",
    "pt_pctuels_ete['ete']=pt_pctuels_ete.apply(lambda x : verif_ete(x['tmja_2015'],x['obs_2015'], x['tmja_2016'], x['obs_2016']), axis=1)\n",
    "pt_pctuels_ete=pt_pctuels_ete.loc[~pt_pctuels_ete['ete']].copy()\n",
    "gdf_pt_cpt=gdf_pt_cpt.loc[gdf_pt_cpt.index.isin(pt_pctuels_ete.index.tolist()+gdf_pt_cpt.loc[gdf_pt_cpt['type_poste']!='ponctuel'].index.tolist())].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\martin.schoreisz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\lib\\function_base.py:2167: RuntimeWarning: invalid value encountered in ? (vectorized)\n",
      "  outputs = ufunc(*inputs)\n"
     ]
    }
   ],
   "source": [
    "#croisement point et lignes (sur labase d'un buffer de 0.5m)\n",
    "gdf_pt_cpt.geometry=gdf_pt_cpt.buffer(0.5)\n",
    "gdf_traf_pt=gp.sjoin(gdf_traf,gdf_pt_cpt,how=\"left\", op='intersects' )[['id_ign','tmja', 'importance',\n",
    "            'id_comptag_left', 'id_tronc_e', 'id_comptag_right','type_poste','tmja_recent','annee_tmja_recent','source','target', 'geometry']].rename(\n",
    "columns={'id_comptag_left':'id_cpt_lin','id_comptag_right': 'id_cpt_pt','tmja':'tmja_lin'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recherch des tronc_elem avec plusieurs points\n",
    "gdf_traf_pt_notna=gdf_traf_pt.loc[~gdf_traf_pt['id_cpt_pt'].isna()].copy()\n",
    "tronc_elem_pt_cpt=gdf_traf_pt_notna.sort_index().groupby('id_tronc_e').agg({'id_cpt_pt' : lambda x : tuple(x),\n",
    "                                       'type_poste' : lambda x : tuple(x),\n",
    "                                        'tmja_recent' : lambda x : tuple(x),\n",
    "                                        'annee_tmja_recent' : lambda x : tuple(x)})\n",
    "trc_elem_multipt=tronc_elem_pt_cpt.loc[tronc_elem_pt_cpt.apply(lambda x : len(x['id_cpt_pt'])>1,axis=1)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mise en forme des trocnon supportant plusieurs point : \n",
    "    #gestion des trocnon avec plusieurs points differntes (on garde le ponctuele de trafic max de l'annee la plus recente si que des ponctuels, sinon le tournant ou permanent)\n",
    "    #verif de la validite des points en comprant les valeurs de trafic entre elle: si un des trafics est sup 1000 et que la variation est sup 30 %, on n'affecte pas\n",
    "def cpt_final (type_poste,id_comptag_right,tmja_recent,annee_tmja_recent ): \n",
    "    tmja_recent=np.array(tmja_recent) \n",
    "    id_comptag_right=np.array(id_comptag_right)\n",
    "    mask_tmja = (tmja_recent==max(tmja_recent))\n",
    "    if all(np.unique(type_poste)=='ponctuel') :\n",
    "        mask_annee=np.array(annee_tmja_recent)==max(annee_tmja_recent)\n",
    "        if all(mask_annee):#il n'y a qu'une seule annee\n",
    "            if all(mask_tmja) : \n",
    "                return id_comptag_right[0]\n",
    "            else : \n",
    "                return id_comptag_right[mask_tmja][0]\n",
    "        else : #il y a pluseurs annee dc on ne garde que le max de la bonne annee\n",
    "            return id_comptag_right[mask_tmja]\n",
    "    else :\n",
    "        mask_type_poste=np.isin(np.array(type_poste),['permanent', 'tournant'])#on trouve le(s) poste(s) non ponctuel\n",
    "        return id_comptag_right[mask_type_poste][0]\n",
    "#verif de la validite des points en comprant les valeurs de trafic entre elle: si un des trafics est sup 1000 et que la variation est sup 30 %, on n'affecte pas\n",
    "trc_elem_multipt['id_cpt_final']=trc_elem_multipt.apply(lambda x: cpt_final(\n",
    "    x['type_poste'], x['id_cpt_pt'], x['tmja_recent'], x['annee_tmja_recent']), axis=1)\n",
    "trc_elem_multipt['valide']=trc_elem_multipt.apply(lambda x : (False if abs(100-(min(x['tmja_recent'])/max(x['tmja_recent'])*100))>30 and\n",
    "                                                                    max(x['tmja_recent'])>1000 and all(np.unique(x['type_poste'])=='ponctuel') else True), axis=1)\n",
    "trc_elem_multipt=trc_elem_multipt.loc[trc_elem_multipt['valide']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtention de la df des id_comptage_pt par tronc_elem\n",
    "tronc_elem_pt_cpt.update(trc_elem_multipt.drop('id_cpt_pt',axis=1).rename(columns={'id_cpt_final':'id_cpt_pt'})[['id_cpt_pt']])\n",
    "tronc_elem_pt_cpt['id_cpt_pt']=tronc_elem_pt_cpt.apply(lambda x : x['id_cpt_pt'][0] if isinstance(x['id_cpt_pt'], tuple) else x['id_cpt_pt'],axis=1) #uniformisation du type de données en str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfert de l'id_cpt_pt final dans la df source\n",
    "gdf_traf_pt_final=gdf_traf_pt[['id_ign','importance', 'id_cpt_lin','tmja_lin', 'id_tronc_e','geometry','source','target']].merge(tronc_elem_pt_cpt[['id_cpt_pt']], how='left',left_on='id_tronc_e', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pour info, ligne ign non linéarisée qui le deviennent\n",
    "gdf_creation_idcpt=gdf_traf_pt_final.loc[(gdf_traf_pt_final['id_cpt_lin'].isna()) & (~gdf_traf_pt_final['id_cpt_pt'].isna())]\n",
    "#pour info, ligne ign linéarisée qui le sont toujours, mais peut avec un nouvel id_ign\n",
    "gdf_variation_idcpt=gdf_traf_pt_final.loc[(~gdf_traf_pt_final['id_cpt_lin'].isna()) & (~gdf_traf_pt_final['id_cpt_pt'].isna()) & (gdf_traf_pt_final['id_cpt_pt']!=gdf_traf_pt_final['id_cpt_lin'])].sort_values('id_cpt_lin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mettre à jour les lignes des troncons qui appartiennent à des id_comptag qui supporte un nouvel id_cpt\n",
    "exemple avec l'idcomptag '17-D734-19+620' pour le point de comptage nouveau '17-D734-28+170'\n",
    "1. isoler les lignes qui sont relaticves à l'id_cpt_lin et trouver l'importance la plus représentée\n",
    "1. trouver les lignes qui intersectent celles de l'idcompatg etudie dont l'importance est = ou sup\n",
    "1. faire un graph avec les lignes de l'id_cpt_lin et celles qui interectent avec la bonne importance\n",
    "1. trouver toute les lignes concernées par l'id_cpt_pt à partir du nouveau graph (plus tard quand on trouvera facilement les troncons elemenraires cela ne sera plus utile) comme ça on ne s'embarasse pas des pb de croisement avec des lignes de moindre importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17-A10-423+0\n"
     ]
    }
   ],
   "source": [
    "#isoler les lignes qui sont relaticves à l'id_cpt_lin et trouver l'importance la plus représentée\n",
    "for id_cpt_a_test in gdf_variation_idcpt.id_cpt_lin.unique() : \n",
    "    print(id_cpt_a_test)\n",
    "    lgn_idcpt_lin=gdf_traf.loc[gdf_traf['id_comptag']==id_cpt_a_test].copy()\n",
    "    importance=[k for k, v in Counter(lgn_idcpt_lin.importance.tolist()).items() if v==max( Counter(lgn_idcpt_lin.importance.tolist()).values())][0]\n",
    "\n",
    "    #trouver les lignes qui intersectent celles de l'idcompatg etudie dont l'importance est = ou sup\n",
    "        #list des source / target de l'idcomptage\n",
    "    list_src_tgt=lgn_idcpt_lin.source.tolist()+lgn_idcpt_lin.target.tolist()\n",
    "    df_lgn_interscts=gdf_traf.loc[((gdf_traf['source'].isin(list_src_tgt)) | (gdf_traf['target'].isin(list_src_tgt))) & (gdf_traf['importance'] <=importance) &\n",
    "                                 (~gdf_traf['id_ign'].isin(lgn_idcpt_lin.id_ign.tolist()))]\n",
    "\n",
    "    #faire un graph avec les lignes de l'id_cpt_lin et celles qui interectent avec la bonne importance\n",
    "        #regrouper l'ensemble des lignes dans une df \n",
    "    ligne_pr_graph=gdf_traf.loc[gdf_traf['id_ign'].isin(df_lgn_interscts.id_ign.tolist()+lgn_idcpt_lin.id_ign.tolist())]\n",
    "    ligne_pr_graph_transfert=ligne_pr_graph.copy()\n",
    "    ligne_pr_graph_transfert['geom']=ligne_pr_graph_transfert.apply(lambda x : dumps(x.geometry), axis=1)\n",
    "        #faire un graph à partir de ces lignes\n",
    "    bdd='gti_otv'\n",
    "    schema='public'\n",
    "    table='graph_temp'\n",
    "    table_vertex='graph_temp_vertices_pgr'\n",
    "    with ct.ConnexionBdd(bdd) as c:\n",
    "        metadata = MetaData(schema=schema)\n",
    "        #supprimer table si elle existe\n",
    "        rqt=f\"drop table if exists {schema}.{table} ; drop table if exists {schema}.{table_vertex} \"\n",
    "        c.sqlAlchemyConn.execute(rqt)\n",
    "\n",
    "        #creer nouvelle table\n",
    "        graph = Table('graph_temp', metadata,\n",
    "            Column('id', Integer, primary_key=True),\n",
    "            Column('id_ign', String),\n",
    "            Column('importance', String),\n",
    "            Column('numero', String),\n",
    "            Column('nature', String),\n",
    "            Column('codevoie_d', String),\n",
    "            Column('sens', String),\n",
    "            Column('tmja', Integer),\n",
    "            Column('source', Integer),\n",
    "            Column('target', Integer),\n",
    "            Column('long_km', Float),\n",
    "            Column('geom',Geometry()))\n",
    "        metadata.create_all(c.engine)\n",
    "        ligne_pr_graph_transfert[['id','id_ign','importance','numero','tmja','source','target','long_km','geom']].to_sql(\n",
    "            table,c.sqlAlchemyConn,schema=schema,if_exists='append', index=False )\n",
    "        #creer le graph\n",
    "        rqt_creation_graph_transfert=f\"\"\"update {schema}.{table} set geom=st_Multi(st_setsrid(geom,2154)), source=null, target=null ; \n",
    "                             select pgr_createTopology('{schema}.{table}', 0.001,'geom')\"\"\"\n",
    "        c.sqlAlchemyConn.execute(rqt_creation_graph)\n",
    "        rqt_anlyse_graph=f\"SELECT pgr_analyzeGraph('{schema}.{table}', 0.001,\\'geom\\')\"\n",
    "        c.curs.execute(rqt_anlyse_graph)#je le fait avec psycopg2 car avec sql acchemy ça ne passe pas\n",
    "        c.connexionPsy.commit()\n",
    "\n",
    "    #trouver une ligne relative à chaque nouveau point\n",
    "    liste_new_pt=gdf_variation_idcpt.loc[gdf_variation_idcpt['id_cpt_lin']==id_cpt_a_test].id_cpt_pt.unique()\n",
    "    if len(liste_new_pt)==1 :\n",
    "        liste_new_pt=liste_new_pt[0]\n",
    "        dico_ligne_pt=gdf_variation_idcpt.loc[gdf_variation_idcpt['id_cpt_pt']==liste_new_pt].groupby('id_cpt_pt').agg({'id_ign': 'max',\n",
    "                                            'id_tronc_e' : 'max'}).to_records()\n",
    "    else : \n",
    "        dico_ligne_pt=gdf_variation_idcpt.loc[gdf_variation_idcpt['id_cpt_pt'].isin(liste_new_pt)].groupby('id_cpt_pt').agg({'id_ign': 'max',\n",
    "                                            'id_tronc_e' : 'max'}).to_records()\n",
    "    dico_ligne_pt={k[0] : {'ligne_base': k[1],'trc_elem':k[2],'lgn_trc_elem' : gdf_traf_pt.loc[gdf_traf_pt['id_tronc_e']==k[2]].id_ign.tolist(), 'priorite':2} for k in dico_ligne_pt}\n",
    "    dico_ligne_pt['17-D734-19+620']={'ligne_base' : gdf_traf_pt.loc[(gdf_traf_pt['type_poste']=='permanent') & \n",
    "                                                                    (gdf_traf_pt['id_cpt_lin']=='17-D734-19+620')].id_ign.values[0],\n",
    "                                     'trc_elem':gdf_traf_pt.loc[(gdf_traf_pt['type_poste']=='permanent') & \n",
    "                                                                    (gdf_traf_pt['id_cpt_lin']=='17-D734-19+620')].id_tronc_e.values[0], \n",
    "                                     'lgn_trc_elem' : gdf_traf_pt.loc[gdf_traf_pt['id_tronc_e']==gdf_traf_pt.loc[(gdf_traf_pt['type_poste']=='permanent') & \n",
    "                                                                    (gdf_traf_pt['id_cpt_lin']=='17-D734-19+620')].id_tronc_e.values[0]].id_ign.tolist(),\n",
    "                                     'priorite':1}\n",
    "    dico_ligne_pt\n",
    "\n",
    "    #pour chaque ligne : on fait tourner la fonction de tronc elem à partir du graph avec les importance sup ou égale, \n",
    "    #d'abord pour le cpt permanent, ensuite pour les autres, avec prise necompte des lignes deja_traitees\n",
    "    #list des id_ign des tronc_elem\n",
    "    liste_id_ign_te=[a  for k, v in dico_ligne_pt.items() for a in v['lgn_trc_elem']]\n",
    "    lignes_traitees=[]\n",
    "    #appel des fonction de carac des lignes \n",
    "    df=at.import_donnes_base('local_otv','public', 'traf2015_bdt17_ed15_l','traf2015_bdt17_ed15_l_vertices_pgr')\n",
    "    df2_chaussees=df.loc[df.nature.isin(['Autoroute', 'Quasi-autoroute', 'Route à 2 chaussées'])]\n",
    "    df_avec_rd_pt,carac_rd_pt,lign_entrant_rdpt=at.identifier_rd_pt(df)\n",
    "    df_lignes=df_avec_rd_pt.set_index('id_ign')#mettre l'id_ign en index\n",
    "    #utilisret les fnctions de carac\n",
    "    for k in sorted(dico_ligne_pt.keys(), key=lambda x: (dico_ligne_pt[x]['priorite'])): \n",
    "        ligne_comp=[x for x in at.lignes_troncon_elem(df_avec_rd_pt,carac_rd_pt, dico_ligne_pt[k]['ligne_base']) if x not in liste_id_ign_te+lignes_traitees]\n",
    "        lignes_traitees+=ligne_comp\n",
    "        dico_ligne_pt[k]['lignes_comp_base']=lgn_idcpt_lin.loc[lgn_idcpt_lin.id_ign.isin(ligne_comp)].id_ign.tolist()\n",
    "\n",
    "    # mettre en forme et creation df de correspondance finale : \n",
    "    df_linearisee=pd.DataFrame(index=dico_ligne_pt.keys(), data=dico_ligne_pt.values())\n",
    "    df_linearisee['lignes_comp_fin']=df_linearisee.apply(lambda x : x['lignes_comp_base'] + x['lgn_trc_elem'], axis=1 )\n",
    "    dico_inverse=df_linearisee[['lignes_comp_fin']].to_dict()\n",
    "    dico_inverse={a:k   for k, val  in dico_inverse['lignes_comp_fin'].items() for a in val}\n",
    "    df_linearisee_fin=pd.DataFrame(index=dico_inverse.keys(), data=dico_inverse.values(), columns=['id_cpt_fin'])\n",
    "\n",
    "    try : \n",
    "        df_linearisee_fin_glob=pd.concat([df_linearisee_fin_glob,df_linearisee_fin], axis=0, sort=False)\n",
    "    except NameError : \n",
    "        df_linearisee_fin_glob=df_linearisee_fin.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mise à jour avec \n",
    "df_linearisee_fin.to_csv(r'D:\\temp\\otv\\test_linearisation\\test_lin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "ligne_pr_graph_transfert=ligne_pr_graph.copy()\n",
    "ligne_pr_graph_transfert['geom']=ligne_pr_graph_transfert.apply(lambda x : dumps(x.geometry), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_ign</th>\n",
       "      <th>id</th>\n",
       "      <th>nature</th>\n",
       "      <th>numero</th>\n",
       "      <th>importance</th>\n",
       "      <th>cl_admin</th>\n",
       "      <th>gestion</th>\n",
       "      <th>mise_serv</th>\n",
       "      <th>fictif</th>\n",
       "      <th>franchisst</th>\n",
       "      <th>...</th>\n",
       "      <th>id_tronc_e</th>\n",
       "      <th>nb_intrsct</th>\n",
       "      <th>src_geom</th>\n",
       "      <th>nb_intrs_1</th>\n",
       "      <th>tgt_geom</th>\n",
       "      <th>id_rdpt</th>\n",
       "      <th>nb_rte_rdp</th>\n",
       "      <th>nb_obj_sig</th>\n",
       "      <th>geometry</th>\n",
       "      <th>geom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>TRONROUT0000000032954110</td>\n",
       "      <td>119438</td>\n",
       "      <td>Autoroute</td>\n",
       "      <td>A10</td>\n",
       "      <td>1</td>\n",
       "      <td>Autoroute</td>\n",
       "      <td>ASF</td>\n",
       "      <td>NR</td>\n",
       "      <td>Non</td>\n",
       "      <td>NC</td>\n",
       "      <td>...</td>\n",
       "      <td>497.0</td>\n",
       "      <td>3</td>\n",
       "      <td>POINT(415106.9 6526825.29999999)</td>\n",
       "      <td>2</td>\n",
       "      <td>POINT(415455.8 6528087.29999999)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (415106.8999999997 6526825.29999999...</td>\n",
       "      <td>LINESTRING (415106.8999999996740371 6526825.29...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id_ign      id     nature numero importance  \\\n",
       "2735  TRONROUT0000000032954110  119438  Autoroute    A10          1   \n",
       "\n",
       "       cl_admin gestion mise_serv fictif franchisst  ...  id_tronc_e  \\\n",
       "2735  Autoroute     ASF        NR    Non         NC  ...       497.0   \n",
       "\n",
       "      nb_intrsct                          src_geom  nb_intrs_1  \\\n",
       "2735           3  POINT(415106.9 6526825.29999999)           2   \n",
       "\n",
       "                              tgt_geom id_rdpt  nb_rte_rdp nb_obj_sig  \\\n",
       "2735  POINT(415455.8 6528087.29999999)     NaN         NaN        NaN   \n",
       "\n",
       "                                               geometry  \\\n",
       "2735  LINESTRING (415106.8999999997 6526825.29999999...   \n",
       "\n",
       "                                                   geom  \n",
       "2735  LINESTRING (415106.8999999996740371 6526825.29...  \n",
       "\n",
       "[1 rows x 68 columns]"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ligne_pr_graph_transfert.loc[ligne_pr_graph_transfert['id_ign']=='TRONROUT0000000032954110']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
