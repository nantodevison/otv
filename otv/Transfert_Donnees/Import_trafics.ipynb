{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;font-size:36px\">IMPORT ET CONVERSION DES DONNEES DE COMPTAGES GESTIONNAIRE</h1>\n",
    "> il y a un exemple de verification si doublons de point dans le 17, 47, 87<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\martin.schoreisz\\git\\otv\\otv\\Transfert_Donnees')\n",
    "sys.path.append(r'C:\\Users\\martin.schoreisz\\git\\Outils\\Outils\\Martin_Perso')\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import csv, re, os, statistics, filecmp, unidecode\n",
    "import datetime as dt\n",
    "from math import sqrt, pi, exp, log, log10\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "import Connexion_Transfert as ct\n",
    "import Import_trafics as it\n",
    "from Donnees_horaires import (comparer2Sens, verifValiditeFichier, concatIndicateurFichierHoraire, SensAssymetriqueError,\n",
    "                              verifNbJoursValidDispo, tmjaDepuisHoraire, periodeDepuisHoraire, attributsHoraire, mensuelDepuisHoraire)\n",
    "from Donnees_sources import MHCorbin, NettoyageTemps, GroupeCompletude, NombreDeJours, FIM\n",
    "from Params.DonneesSourcesParams import MHcorbinMaxLength, MHcorbinMaxSpeed, MHCorbinValue0, MHCorbinFailAdviceCode\n",
    "import Outils as O\n",
    "from Params.Mensuel import dico_mois\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from shapely.geometry import Point, LineString, MultiLineString\n",
    "from shapely import speedups\n",
    "speedups.disable()\n",
    "from shapely.ops import transform\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "# from Base_BdTopo import Import_outils as io\n",
    "# from Base_BdTopo import Rond_points as rp#from Base_BdTopo import Regroupement_correspondance as rc\n",
    "from sqlalchemy.schema import MetaData\n",
    "from sqlalchemy import inspect\n",
    "from statistics import mean\n",
    "from itertools import combinations\n",
    "from unidecode import unidecode\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import pyproj\n",
    "from shapely.ops import transform\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_colwidth', 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\" ></a>\n",
    "# ***CD 23***\n",
    "- Année 2019 : \n",
    "> ***attention : pour le point de comptage D941 6+152 à Aubusson, le pR est 32 et non 6. il faut donc corriger à la main le fihcier excel***\n",
    "<br> Pour le moment tous les points sont déjà dans  la base, dc pas de traitement de type insert prévus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiliser les données\n",
    "cd23 = it.Comptage_cd23(r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\CD23\\2019-CD23_trafics.xls',2019)\n",
    "df_propre = cd23.ouvrirMiseEnForme()\n",
    "cd23.classer_comptage_update_insert('gti_otv_pg11', 'na_2010_2019_p')\n",
    "cd23.update_bdd_23('gti_otv_pg11','comptage', 'na_2010_2019_p')\n",
    "cd23.donneesMens()\n",
    "cd23.insert_bdd('gti_otv_pg11','comptage', 'na_2010_2019_mensuel',cd23.df_attr_mensuel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\" ></a>\n",
    "# ***CD 40***\n",
    "> 2019 : envoi des données B152 de route +   \n",
    "2020 : envoi des données B153 de route +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019 : initialiser\n",
    "cd40 = it.Comptage_cd40(r'D:\\temp\\otv\\2019\\Donnees_source\\CD40\\Observatoire des trafics')\n",
    "# mettre enf orme\n",
    "cd40.comptage_forme()\n",
    "cd40.classer_comptage_insert_update('local_otv_station_gti', 'na_2010_2019_p', 'comptage')\n",
    "# transfert donnees_agregees\n",
    "cd40.update_bdd_40('local_otv_station_gti', 'comptage', 'na_2010_2019_p')\n",
    "# donnees_mensuelles\n",
    "# cd40.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_mensuel',cd40.df_attr_mens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020 : preparer\n",
    "cd40 = it.Comptage_cd40(r'C:\\Users\\martin.schoreisz\\Box\\Dossier_Perso\\OTV\\donnees_gestionnaires\\CD40\\en_cours\\donnees', donneesType='B153', annee='2020')\n",
    "cd40.comptage_forme()\n",
    "cd40.classer_comptage_insert_update('local_otv_boulot', 'compteur', 'comptage')\n",
    "# cd40.df_attr_update,cd40.df_attr_insert, cd40.df_attr_mens\n",
    "\n",
    "# mettre a jour \n",
    "# comptages\n",
    "dfComptage = cd40.creer_comptage(cd40.df_attr_update.id_comptag.tolist(), cd40.annee, 'tableur CD40', 'tv/pl', obs='fichier B153 route +')\n",
    "cd40.insert_bdd('local_otv_boulot', 'comptage', 'comptage', dfComptage)\n",
    "# indics_agreges\n",
    "dfIndicAgrege = cd40.structureBddOld2NewForm(cd40.df_attr_update, cd40.annee, ['id_comptag', 'annee', 'fichier'], ['tmja', 'pc_pl', 'tmje', 'tmjhe'], 'agrege')\n",
    "cd40.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege', dfIndicAgrege)\n",
    "# trafic mensuel\n",
    "dfIndicMensuel = cd40.structureBddOld2NewForm(cd40.df_attr_mens, cd40.annee, ['id_comptag', 'annee', 'fichier', 'donnees_type'], ['janv', 'fevr', 'mars', 'avri', 'mai', 'juin', 'juil', 'aout', 'sept',\n",
    "                                                                                                                                'octo', 'nove', 'dece'], 'mensuel')\n",
    "cd40.insert_bdd('local_otv_boulot', 'comptage', 'indic_mensuel', dfIndicMensuel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\" ></a>\n",
    "# ***CD17***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Année 2015 : traitée dans le fichier Import_trafics.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### année 2016 données issue des borchures de comptage, uniquemnet pour ponctuels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ouverture du fichier\n",
    "cpt17=it.Comptage_cd17(r'Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_produites\\donnnees_travail\\Comptage\\17\\cpt_pctuel_but_2016.txt',\n",
    "                       'brochure',2016)\n",
    "\n",
    "#mettre à jour les id_comptage deja presents (attention, update Bdd à changé, il faut passer par creer_valeur_txt_update avant et certains paramètres ont changé)\n",
    "cpt17.mises_forme_bdd('gti_otv', 'comptage', 'na_2010_2017_p', '17','ponctuel') #creer les attributs selon les donnees presentes dans la base\n",
    "cpt17.update_bdd('gti_otv', 'comptage', 'na_2010_2017_p')#mise à jour\n",
    "\n",
    "#creer referentiel si besoin\n",
    "with ct.ConnexionBdd('gti_otv') as c:\n",
    "    ct.ogr2ogr_shp2pg(c.connstringOgr, r'Y:\\REF_GEO\\BD_Topo\\D17\\ED16\\SHP\\1_DONNEES_LIVRAISON\\N_TRONCON_ROUTE_BDT_017.SHP',\n",
    "                     schema='referentiel',table='troncon_route_bdt17_ed16_l',geotype='MULTILINESTRING', dims=2, encodageClient='LATIN1' )\n",
    "#creer graph\n",
    "rqt=\"\"\"\n",
    "alter table referentiel.troncon_route_bdt17_ed16_l add column source integer , add column target integer ;\n",
    "select pgr_createTopology ('referentiel.troncon_route_bdt17_ed16_l',1,'geom', 'ogc_fid') ;\n",
    "ALTER TABLE referentiel.troncon_route_bdt17_ed16_l  RENAME COLUMN id TO id_ign;\n",
    "ALTER TABLE referentiel.troncon_route_bdt17_ed16_l  RENAME COLUMN ogc_fid TO id;\n",
    "alter table referentiel.troncon_route_bdt17_ed16_l add column long_km numeric ;\n",
    "update referentiel.troncon_route_bdt17_ed16_l set long_km=(st_length(geom)/1000) ;\n",
    "\"\"\"  # attention, il manque la ligne au dessus pour créer l'analyseGraph qui va renvoyer le nb de count\n",
    "with ct.ConnexionBdd('gti_otv') as c:\n",
    "    c.sqlAlchemyConn.execute(rqt)\n",
    "\n",
    "#inserer les nouveaux comptages\n",
    "with ct.ConnexionBdd('gti_otv') as c:\n",
    "    cpt17.df_attr_insert.to_sql('na_2010_2017_p',c.sqlAlchemyConn,schema='comptage',if_exists='append', index=False )\n",
    "\n",
    "#mettre à jour la geom \n",
    "rqt=\"\"\" update comptage.na_2010_2017_p\n",
    "  set geom=(select geom_out  from comptage.geoloc_pt_comptag(id_comptag))\n",
    "  where dep='17' and geom is null\n",
    "\"\"\"\n",
    "with ct.ConnexionBdd('gti_otv') as c:\n",
    "    c.sqlAlchemyConn.execute(rqt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### fichier compteurs permanents format csv annee 2017, 2018, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_perm=it.Comptage_cd17(r'D:\\Boulot\\AffairesEnCours\\OTV\\17\\csv perso pactol_2019_1.csv',\n",
    "                         'permanent_csv',2019)\n",
    "cpt_perm.mises_forme_bdd_brochure_pdf('local_otv_gti', 'comptage', 'na_2010_2019_p', '17','permanent', 'maison')\n",
    "#miettre à jour les données deja existantes\n",
    "cpt_perm.update_bdd_17('local_otv_gti', 'comptage', 'na_2010_2019_p')#mise à jour\n",
    "#inseérer les données nouvelles\n",
    "cpt_perm.insert_bdd('gti_otv', 'comptage', 'na_2010_2019_p')\n",
    "#mettre à jour la geom \n",
    "cpt_perm.maj_geom('gti_otv', 'comptage', 'na_2010_2019_p', '17')\n",
    "# pour les données mensuelles\n",
    "cpt_perm.insert_bdd_mens('local_otv_gti', 'comptage','na_2010_2019_mensuel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### annee 2018 ; fichier compteurs tournant format excel issu des donnees pour brochure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiliser la classe avec le fichier\n",
    "bdd='gti_otv_pg11'\n",
    "cpt_cd17=it.Comptage_cd17(r'Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD17\\Brochure 2018 CD17 DREAL\\10  5 1 B3 tournants recalculés.xls',\n",
    "                      'tournant_xls_bochure',2018)\n",
    "\n",
    "#mise en forme des données\n",
    "cpt_cd17.comptag_existant_bdd(bdd, 'na_2010_2018_p', dep='17')\n",
    "donnees=cpt_cd17.ouvrir_xls_tournant_brochure()\n",
    "cpt_cd17.conversion_id_comptg_existant_xls_brochure(bdd)\n",
    "cpt_cd17.carac_xls_brochure()\n",
    "\n",
    "#mise à jour des données\n",
    "val_txt=cpt_cd17.creer_valeur_txt_update(cpt_cd17.df_attr_update, ['id_comptag','tmja_2018','tmja_2017'])\n",
    "cpt_cd17.update_bdd(bdd, 'comptage', 'na_2010_2018_p', val_txt,{'tmja_2018':'tmja_2018','tmja_2017':'tmja_2017'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### annee 2017-2018 ; fichier ponctuel excel qui alimente des brochures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ouvrir le fichier et initialisation\n",
    "cpt_pct2018_cd17=it.Comptage_cd17(r'Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD17\\Brochure 2018 CD17 DREAL\\spécifique Brochure V85_2018 .xls',\n",
    "                      'ponctuel_xls_bochure',2018)\n",
    "bdd='gti_otv_pg11'\n",
    "#mise en forme\n",
    "cpt_pct2018_cd17.comptag_existant_bdd(bdd, 'na_2010_2018_p', dep='17')\n",
    "cpt_pct2018_cd17.conversion_id_comptg_existant_xls_brochure(bdd)\n",
    "cpt_pct2018_cd17.filtrer_periode_ponctuels_xls_brochure()\n",
    "cpt_pct2018_cd17.carac_xls_brochure()\n",
    "\n",
    "#mise à jour des données\n",
    "val_txt=cpt_pct2018_cd17.creer_valeur_txt_update(cpt_pct2018_cd17.df_attr_update, ['id_comptag','tmja','pc_pl','obs'])\n",
    "cpt_pct2018_cd17.update_bdd(bdd, 'comptage', 'na_2010_2018_p', val_txt,{'tmja_2018':'tmja','pc_pl_2018':'pc_pl', 'obs_2018':'obs'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trouver les points de comptages a inserer situe sur le même troncon elementaires que d'autres points\n",
    "table_corresp=cpt_pct2018_cd17.correspondance_ancien_nouveau_comptage(bdd,'public','cd17_tournant_insert','lineaire.traf2016_bdt17_ed16_l',\n",
    "                                                    'public', 'traf2016_bdt17_ed16_l','traf2016_bdt17_ed16_l_vertices_pgr')\n",
    "\n",
    "#si le point fait partie de la table_corresp, on insère pas, sinon on insère\n",
    "pt_a_inserer=cpt_pct2018_cd17.df_attr_insert.loc[~cpt_pct2018_cd17.df_attr_insert.id_comptag.isin(table_corresp.id_comptag.tolist())].copy()\n",
    "#mise en form avant insertion\n",
    "pt_a_inserer['dep']='17'\n",
    "pt_a_inserer['route']=pt_a_inserer.id_comptag.apply(lambda x : x.split('-')[1])\n",
    "pt_a_inserer.rename(columns={'absc':'abs','tmja':'tmja_2018','pc_pl':'pc_pl_2018','obs':'obs_2018'},inplace=True)\n",
    "pt_a_inserer['reseau']='RD'\n",
    "pt_a_inserer['gestionnai']='CD17'\n",
    "pt_a_inserer['concession']='N'\n",
    "pt_a_inserer['type_poste']='ponctuel'\n",
    "pt_a_inserer=pt_a_inserer[['id_comptag','dep','route','pr','abs','reseau','gestionnai','concession','type_poste','tmja_2018','pc_pl_2018','obs_2018']].copy()\n",
    "#si plusieurs fois le mm point on garde la valeur max\n",
    "pt_a_inserer=pt_a_inserer.loc[pt_a_inserer.tmja_2018==pt_a_inserer.groupby('id_comptag').tmja_2018.transform(max)].copy()\n",
    "\n",
    "cpt_pct2018_cd17.insert_bdd(bdd, 'comptage', 'na_2010_2018_p', pt_a_inserer)\n",
    "cpt_pct2018_cd17.maj_geom(bdd, 'comptage', 'na_2010_2018_p', dep='17')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***CD19***\n",
    "> 2019 : creation de la classe Comptage_cd19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\" ></a>\n",
    "# ***CD64***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init\n",
    "fichier=r'C:\\Users\\martin.schoreisz\\Box\\Dossier_Perso\\OTV\\donnees_gestionnaires\\CD64\\en_cours\\Copie de SIG TV PL %PL TOURNANTS + PERMANENTS 2020.xlsx'\n",
    "cd64=it.Comptage_cd64(fichier, '2020')\n",
    "cd64.miseEnForme()\n",
    "cd64.classer_comptage_insert_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verfier les correspondances\n",
    "#verifieles geometries a insrere\n",
    "#calcul auto des geometries et verif Qgis\n",
    "gdfInsert=cd64.localiser_comptage_a_inserer(cd64.df_attr_insert, 'local_otv_boulot', 'public', 'localiser_pt_cd64', \n",
    "                                            'ref.troncon_route_bdt_na_ed20_l', 'ref.pr_ed18_p')\n",
    "#gdfInsert.to_file(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\verif_pt_cd64.shp')\n",
    "#reprendre le fichier corrige via Qgis\n",
    "gdfInsertCorrigee=gp.read_file(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\verif_pt_cd64.shp')\n",
    "dicoCoresp={'64-D10-3+0':'64-D10-3+400','64-D4-25+0':'64-D4-25+500', '64-D+6-8+130':'64-D55-2+535', '64-D6-2+335':'64-D6-0+250'}\n",
    "cd64.verifComptageInsert(dicoCoresp,gdfInsertCorrigee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#mise à jour des données déjà présentes : \n",
    "#mise a jour de obs_supl\n",
    "cd64.update_bdd('comptage', 'compteur', cd64.creer_valeur_txt_update(cd64.df_attr_update, ['id_comptag', 'obs_supl']), {'obs_supl':'obs_supl'})\n",
    "#insere les nouveaux comptages, mettre à jour les anciens\n",
    "#séparer les comptages deja existants et les nouveaux\n",
    "bdd='local_otv_boulot'\n",
    "with ct.ConnexionBdd(bdd) as c  :\n",
    "    comptagesExistant=pd.read_sql('select ca.* from comptage.comptage ca join comptage.compteur ce on ca.id_comptag=ce.id_comptag where ce.dep=\\'64\\'', c.sqlAlchemyConn)\n",
    "dfJointureBddCd64=cd64.df_attr_update.assign(annee=cd64.df_attr_update.annee.astype(str)).merge(comptagesExistant[['id','id_comptag', 'annee']], how='left', on=['id_comptag', 'annee'])\n",
    "dfComptagesExistants=dfJointureBddCd64.loc[~dfJointureBddCd64.id.isna()]\n",
    "dfComptagesNew=dfJointureBddCd64.loc[dfJointureBddCd64.id.isna()]\n",
    "#mise à jour des existants\n",
    "#comptage\n",
    "cd64.update_bdd('comptage', 'comptage', cd64.creer_valeur_txt_update(dfComptagesExistants[['id']].assign(src='tableur CD64'), ['id', 'src']),\n",
    "                {'src':'src'}, identifiant='id')\n",
    "#tmja\n",
    "cd64.update_bdd('comptage', 'indic_agrege', cd64.creer_valeur_txt_update(dfComptagesExistants.assign(id_comptag_uniq=dfComptagesExistants.id)\n",
    "                                                                         , ['id_comptag_uniq', 'tmja']), {'valeur':'tmja'}, identifiant='id_comptag_uniq',\n",
    "                filtre = \"indicateur='tmja'\")\n",
    "#pc_pl\n",
    "cd64.update_bdd('comptage', 'indic_agrege', cd64.creer_valeur_txt_update(dfComptagesExistants.assign(id_comptag_uniq=dfComptagesExistants.id)\n",
    "                                                                         , ['id_comptag_uniq', 'pc_pl']), {'valeur':'pc_pl'}, identifiant='id_comptag_uniq',\n",
    "                filtre = \"indicateur='pc_pl'\")\n",
    "\n",
    "#insertion des nouveaux\n",
    "for a in dfComptagesNew.annee.unique() : \n",
    "    dfComptage=cd64.creer_comptage(dfComptagesNew.loc[dfComptagesNew.annee==a].id_comptag.tolist(), a, 'tableur CD64','tv/pl')\n",
    "    cd64.insert_bdd('local_otv_boulot', 'comptage', 'comptage', dfComptage)\n",
    "    dfIndicAgrege=cd64.structureBddOld2NewForm(dfComptagesNew.loc[dfComptagesNew.annee==a], a,\n",
    "                                               ['id_comptag', 'annee', 'fichier'],['tmja', 'pc_pl'], 'agrege')\n",
    "    cd64.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege', dfIndicAgrege)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***CD47***\n",
    "> Annee des trafics 2018, fichiers : Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD47\\comptages_CD47_2018\\COMPTAGES 2018\n",
    "les fichiers sont decomposes en permanents tournants temporaires, il faut recomposer les donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialiser un objet\n",
    "cpt47=it.Comptage_cd47(r'Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD47\\comptages_CD47_2018\\COMPTAGES 2018','TRAFICS PERMANENTS')\n",
    "#calculer les attributs de comptages : df_attr, df_attr_insert et df_attr_update, en prenant en compte les comptages existants\n",
    "cpt47.classer_comptage_update_insert('gti_otv_pg11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mise à jour des données déjà présentes dansla base\n",
    "val_txt=cpt47.creer_valeur_txt_update(cpt47.df_attr_update, ['id_comptag','tmja','pc_pl'])\n",
    "cpt47.update_bdd(bdd, 'comptage', 'na_2010_2018_p', val_txt,{'tmja_2018':'tmja','pc_pl_2018':'pc_pl'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traitement des données non présentes (df_attr_insert)\n",
    "#recherche de correspondance pour les permanents et tournants\n",
    "dico_corresp=cpt47.corresp_old_new_comptag('gti_otv_pg11', 'public','cpt47_temp','lineaire.traf2017_bdt47_ed17_l',\n",
    "                            'referentiel', 'troncon_route_bdt47_ed17_l','troncon_route_bdt47_ed17_l_vertices_pgr','id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtre des données df_attr_insert selon l'id_comptag present dans le dico_corresp\n",
    "cpt47.df_attr_insert=cpt47.df_attr_insert.loc[~cpt47.df_attr_insert.id_comptag.isin(df_correspondance.id_comptag.to_list())].copy()\n",
    "# POUR INFO, l'id_comptag présent dan sle dico_corresp a été transférer à la main dans l table comptage.corresp_id_comptag\n",
    "#mettre en forme les attributs avant insert\n",
    "cpt47.mise_en_forme_insert('2018')\n",
    "#inserer les donnes dans la table\n",
    "cpt47.insert_bdd('gti_otv_pg11', 'comptage', 'na_2010_2018_p', cpt47.df_attr_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mettre à jour la géométrie\n",
    "cpt47.maj_geom('gti_otv_pg11', 'comptage', 'na_2010_2018_p', '47')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **2019**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt47 = it.Comptage_cd47(r'D:\\temp\\otv\\2019\\Donnees_source\\CD47','TRAFICS PERIODIQUES',2019)\n",
    "# calculer les attributs de comptages : df_attr, df_attr_insert et df_attr_update, en prenant en compte les comptages existants, mais ans recherche des équivalences avec les anciens comptage snon recensées\n",
    "cpt47.classer_comptage_update_insert('local_otv_station_gti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qq points tournants non connus\n",
    "cpt47.df_attr_insert.loc[cpt47.df_attr_insert['type_poste'].isin(['permanent','tournant'])]\n",
    "# filtrer les 2 points bizarres\n",
    "cpt47.df_attr = cpt47.df_attr.loc[cpt47.df_attr.id_comptag.apply(lambda x : x[:4]=='47-D')].copy()\n",
    "cpt47.df_attr_insert = cpt47.df_attr_insert.loc[cpt47.df_attr_insert.id_comptag.apply(lambda x : x[:4]=='47-D')].copy()\n",
    "cpt47.df_attr_update = cpt47.df_attr_update.loc[cpt47.df_attr_update.id_comptag.apply(lambda x : x[:4]=='47-D')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtention dico de correspondance\n",
    "dico_corresp = cpt47.corresp_old_new_comptag('local_otv_station_gti', 'public', 'cpt47_temp', 'referentiel.troncon_route_bdt47_ed17_l',\n",
    "                                             'referentiel', 'troncon_route_bdt47_ed17_l', 'troncon_route_bdt47_ed17_l_vertices_pgr', 'id')\n",
    "# insertion dans bdd\n",
    "cpt47.insert_bdd('local_otv_station_gti', 'comptage', 'corresp_id_comptag',dico_corresp[['id_comptag', 'id_comptag_lin'\n",
    "                                                                                        ]].rename(columns={'id_comptag': 'id_gest','id_comptag_lin': 'id_gti'}))\n",
    "# calcul nouveau id_comptag\n",
    "cpt47.comptag_existant_bdd('local_otv_station_gti', schema='comptage', table='na_2010_2019_p', dep='47', type_poste=False)\n",
    "cpt47.corresp_nom_id_comptag('local_otv_station_gti', cpt47.df_attr)\n",
    "cpt47.df_attr_update = cpt47.df_attr.loc[cpt47.df_attr.id_comptag.isin(cpt47.existant.id_comptag.tolist())].copy()\n",
    "cpt47.df_attr_insert = cpt47.df_attr.loc[~cpt47.df_attr.id_comptag.isin(cpt47.existant.id_comptag.tolist())].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mise a jour\n",
    "cpt47.update_bdd_47('local_otv_station_gti', 'comptage', 'na_2010_2019_p', cpt47.df_attr_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# donnees a inserer\n",
    "cpt47.mise_en_forme_insert()\n",
    "cpt47.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_p', cpt47.df_attr_insert)\n",
    "cpt47.maj_geom('local_otv_station_gti', 'comptage', 'na_2010_2019_p', '47')\n",
    "cpt47.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_mensuel', cpt47.df_attr_mens)\n",
    "cpt47.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_horaire', cpt47.df_attr_horaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **2020**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt47 = it.Comptage_cd47(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD47\\en_cours', 'TRAFICS PERMANENTS', 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculer les attributs de comptages : df_attr, df_attr_insert et df_attr_update, en prenant en compte les comptages existants, mais ans recherche des équivalences avec les anciens comptage snon recensées\n",
    "cpt47.classer_comptage_update_insert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cpt47.localiser_comptage_a_inserer(cpt47.df_attr_insert.drop(['mensuel'], axis=1), 'local_otv_boulot', 'public', 'cd47_2020', 'lineaire.traf2020_bdt_na_ed20_l', 'ref.pr_ed18_p' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id_comptag</th>\n",
       "      <th>tmja</th>\n",
       "      <th>pc_pl</th>\n",
       "      <th>type_poste</th>\n",
       "      <th>periode</th>\n",
       "      <th>pr</th>\n",
       "      <th>absc</th>\n",
       "      <th>route</th>\n",
       "      <th>fichier</th>\n",
       "      <th>src</th>\n",
       "      <th>geom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103</td>\n",
       "      <td>47-D15-19+505</td>\n",
       "      <td>613</td>\n",
       "      <td>3.7</td>\n",
       "      <td>ponctuel</td>\n",
       "      <td>2020/06/04-2020/06/10</td>\n",
       "      <td>19</td>\n",
       "      <td>505</td>\n",
       "      <td>D15</td>\n",
       "      <td>Astaffort D15 PR 19+505 T.xlsx</td>\n",
       "      <td>donnees_xls_sources</td>\n",
       "      <td>POINT (510475.335 6332818.993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104</td>\n",
       "      <td>47-D292-1+960</td>\n",
       "      <td>1412</td>\n",
       "      <td>3.6</td>\n",
       "      <td>ponctuel</td>\n",
       "      <td>2020/10/27-2020/11/02</td>\n",
       "      <td>1</td>\n",
       "      <td>960</td>\n",
       "      <td>D292</td>\n",
       "      <td>Aubiac D292 PR 1+960 T.xlsx</td>\n",
       "      <td>donnees_xls_sources</td>\n",
       "      <td>POINT (504177.579 6342500.428)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105</td>\n",
       "      <td>47-D656-53+976</td>\n",
       "      <td>2405</td>\n",
       "      <td>8.3</td>\n",
       "      <td>ponctuel</td>\n",
       "      <td>2020/10/27-2020/11/02</td>\n",
       "      <td>53</td>\n",
       "      <td>976</td>\n",
       "      <td>D656</td>\n",
       "      <td>Aubiac D656 PR 53+976 T.xlsx</td>\n",
       "      <td>donnees_xls_sources</td>\n",
       "      <td>POINT (503974.310 6342472.303)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106</td>\n",
       "      <td>47-D136-10+838</td>\n",
       "      <td>1089</td>\n",
       "      <td>6.1</td>\n",
       "      <td>ponctuel</td>\n",
       "      <td>2020/11/18-2020/11/24</td>\n",
       "      <td>10</td>\n",
       "      <td>838</td>\n",
       "      <td>D136</td>\n",
       "      <td>Bruch D136 PR 10+838 T.xlsx</td>\n",
       "      <td>donnees_xls_sources</td>\n",
       "      <td>POINT (492890.539 6348226.237)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107</td>\n",
       "      <td>47-D136-10+930</td>\n",
       "      <td>1111</td>\n",
       "      <td>5.5</td>\n",
       "      <td>ponctuel</td>\n",
       "      <td>2020/11/18-2020/11/24</td>\n",
       "      <td>10</td>\n",
       "      <td>930</td>\n",
       "      <td>D136</td>\n",
       "      <td>Bruch D136 PR 10+930 T.xlsx</td>\n",
       "      <td>donnees_xls_sources</td>\n",
       "      <td>POINT (492962.150 6348283.904)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>179</td>\n",
       "      <td>47-D276-9+0</td>\n",
       "      <td>211</td>\n",
       "      <td>1.1</td>\n",
       "      <td>ponctuel</td>\n",
       "      <td>2020/01/15-2020/01/22</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>D276</td>\n",
       "      <td>D276 PR 9+000 T.xlsx</td>\n",
       "      <td>donnees_xls_sources</td>\n",
       "      <td>POINT (535277.493 6379385.591)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>181</td>\n",
       "      <td>47-D225-5+80</td>\n",
       "      <td>1037</td>\n",
       "      <td>4.4</td>\n",
       "      <td>ponctuel</td>\n",
       "      <td>2020/06/13-2020/06/19</td>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>D225</td>\n",
       "      <td>St Etienne de Fougères D225 PR 5+080 T.xlsx</td>\n",
       "      <td>donnees_xls_sources</td>\n",
       "      <td>POINT (507202.622 6372387.910)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>182</td>\n",
       "      <td>47-D225-5+200</td>\n",
       "      <td>841</td>\n",
       "      <td>3.5</td>\n",
       "      <td>ponctuel</td>\n",
       "      <td>2020/06/13-2020/06/19</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>D225</td>\n",
       "      <td>St Etienne de Fougères D225 PR 5+200 T.xlsx</td>\n",
       "      <td>donnees_xls_sources</td>\n",
       "      <td>POINT (507120.948 6372313.149)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>183</td>\n",
       "      <td>47-D710-2+650</td>\n",
       "      <td>1163</td>\n",
       "      <td>6.8</td>\n",
       "      <td>ponctuel</td>\n",
       "      <td>2020/03/04-2020/03/10</td>\n",
       "      <td>2</td>\n",
       "      <td>650</td>\n",
       "      <td>D710</td>\n",
       "      <td>Sauveterre La Lémance D710 PR 2+650 T.xlsx</td>\n",
       "      <td>donnees_xls_sources</td>\n",
       "      <td>POINT (542452.274 6390158.071)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>184</td>\n",
       "      <td>47-D442-1+850</td>\n",
       "      <td>6476</td>\n",
       "      <td>1.4</td>\n",
       "      <td>ponctuel</td>\n",
       "      <td>2020/10/07-2020/10/13</td>\n",
       "      <td>1</td>\n",
       "      <td>850</td>\n",
       "      <td>D442</td>\n",
       "      <td>Villeneuve sur Lot D442 PR 1+850 T.xlsx</td>\n",
       "      <td>donnees_xls_sources</td>\n",
       "      <td>POINT (518724.375 6371485.064)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index      id_comptag  tmja  pc_pl type_poste                periode  pr  \\\n",
       "0     103   47-D15-19+505   613    3.7   ponctuel  2020/06/04-2020/06/10  19   \n",
       "1     104   47-D292-1+960  1412    3.6   ponctuel  2020/10/27-2020/11/02   1   \n",
       "2     105  47-D656-53+976  2405    8.3   ponctuel  2020/10/27-2020/11/02  53   \n",
       "3     106  47-D136-10+838  1089    6.1   ponctuel  2020/11/18-2020/11/24  10   \n",
       "4     107  47-D136-10+930  1111    5.5   ponctuel  2020/11/18-2020/11/24  10   \n",
       "..    ...             ...   ...    ...        ...                    ...  ..   \n",
       "74    179     47-D276-9+0   211    1.1   ponctuel  2020/01/15-2020/01/22   9   \n",
       "75    181    47-D225-5+80  1037    4.4   ponctuel  2020/06/13-2020/06/19   5   \n",
       "76    182   47-D225-5+200   841    3.5   ponctuel  2020/06/13-2020/06/19   5   \n",
       "77    183   47-D710-2+650  1163    6.8   ponctuel  2020/03/04-2020/03/10   2   \n",
       "78    184   47-D442-1+850  6476    1.4   ponctuel  2020/10/07-2020/10/13   1   \n",
       "\n",
       "    absc route                                      fichier  \\\n",
       "0    505   D15               Astaffort D15 PR 19+505 T.xlsx   \n",
       "1    960  D292                  Aubiac D292 PR 1+960 T.xlsx   \n",
       "2    976  D656                 Aubiac D656 PR 53+976 T.xlsx   \n",
       "3    838  D136                  Bruch D136 PR 10+838 T.xlsx   \n",
       "4    930  D136                  Bruch D136 PR 10+930 T.xlsx   \n",
       "..   ...   ...                                          ...   \n",
       "74     0  D276                         D276 PR 9+000 T.xlsx   \n",
       "75    80  D225  St Etienne de Fougères D225 PR 5+080 T.xlsx   \n",
       "76   200  D225  St Etienne de Fougères D225 PR 5+200 T.xlsx   \n",
       "77   650  D710   Sauveterre La Lémance D710 PR 2+650 T.xlsx   \n",
       "78   850  D442      Villeneuve sur Lot D442 PR 1+850 T.xlsx   \n",
       "\n",
       "                    src                            geom  \n",
       "0   donnees_xls_sources  POINT (510475.335 6332818.993)  \n",
       "1   donnees_xls_sources  POINT (504177.579 6342500.428)  \n",
       "2   donnees_xls_sources  POINT (503974.310 6342472.303)  \n",
       "3   donnees_xls_sources  POINT (492890.539 6348226.237)  \n",
       "4   donnees_xls_sources  POINT (492962.150 6348283.904)  \n",
       "..                  ...                             ...  \n",
       "74  donnees_xls_sources  POINT (535277.493 6379385.591)  \n",
       "75  donnees_xls_sources  POINT (507202.622 6372387.910)  \n",
       "76  donnees_xls_sources  POINT (507120.948 6372313.149)  \n",
       "77  donnees_xls_sources  POINT (542452.274 6390158.071)  \n",
       "78  donnees_xls_sources  POINT (518724.375 6371485.064)  \n",
       "\n",
       "[79 rows x 12 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>donnees_type</th>\n",
       "      <th>janv</th>\n",
       "      <th>fevr</th>\n",
       "      <th>mai</th>\n",
       "      <th>juin</th>\n",
       "      <th>juil</th>\n",
       "      <th>aout</th>\n",
       "      <th>sept</th>\n",
       "      <th>octo</th>\n",
       "      <th>nove</th>\n",
       "      <th>dece</th>\n",
       "      <th>id_comptag</th>\n",
       "      <th>annee</th>\n",
       "      <th>mars</th>\n",
       "      <th>avri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tmja</td>\n",
       "      <td>7415.0</td>\n",
       "      <td>7673.0</td>\n",
       "      <td>6396.0</td>\n",
       "      <td>7378.0</td>\n",
       "      <td>7643.0</td>\n",
       "      <td>7195.0</td>\n",
       "      <td>7971.0</td>\n",
       "      <td>7785.0</td>\n",
       "      <td>5511.0</td>\n",
       "      <td>6336.0</td>\n",
       "      <td>47-D813-42+0</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pc_pl</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>47-D813-42+0</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tmja</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3468.0</td>\n",
       "      <td>2137.0</td>\n",
       "      <td>3546.0</td>\n",
       "      <td>4393.0</td>\n",
       "      <td>4424.0</td>\n",
       "      <td>3730.0</td>\n",
       "      <td>3696.0</td>\n",
       "      <td>2117.0</td>\n",
       "      <td>2674.0</td>\n",
       "      <td>47-D655-30+0</td>\n",
       "      <td>2020</td>\n",
       "      <td>2066.0</td>\n",
       "      <td>1106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pc_pl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.1</td>\n",
       "      <td>13.5</td>\n",
       "      <td>11.4</td>\n",
       "      <td>10.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>10.5</td>\n",
       "      <td>16.8</td>\n",
       "      <td>11.4</td>\n",
       "      <td>47-D655-30+0</td>\n",
       "      <td>2020</td>\n",
       "      <td>14.7</td>\n",
       "      <td>24.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tmja</td>\n",
       "      <td>4995.0</td>\n",
       "      <td>5436.0</td>\n",
       "      <td>3830.0</td>\n",
       "      <td>5808.0</td>\n",
       "      <td>6247.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5677.0</td>\n",
       "      <td>3841.0</td>\n",
       "      <td>4468.0</td>\n",
       "      <td>47-D666-10+500</td>\n",
       "      <td>2020</td>\n",
       "      <td>3490.0</td>\n",
       "      <td>2322.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pc_pl</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>47-D676-29+740</td>\n",
       "      <td>2020</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tmja</td>\n",
       "      <td>3773.0</td>\n",
       "      <td>3901.0</td>\n",
       "      <td>2701.0</td>\n",
       "      <td>3845.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4216.0</td>\n",
       "      <td>4107.0</td>\n",
       "      <td>4050.0</td>\n",
       "      <td>2805.0</td>\n",
       "      <td>3438.0</td>\n",
       "      <td>47-D676-29+740</td>\n",
       "      <td>2020</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1368.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pc_pl</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>47-D676-29+740</td>\n",
       "      <td>2020</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tmja</td>\n",
       "      <td>3773.0</td>\n",
       "      <td>3901.0</td>\n",
       "      <td>2701.0</td>\n",
       "      <td>3845.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4216.0</td>\n",
       "      <td>4107.0</td>\n",
       "      <td>4050.0</td>\n",
       "      <td>2805.0</td>\n",
       "      <td>3438.0</td>\n",
       "      <td>47-D676-29+740</td>\n",
       "      <td>2020</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1368.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pc_pl</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>47-D676-29+740</td>\n",
       "      <td>2020</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   donnees_type    janv    fevr     mai    juin    juil    aout    sept  \\\n",
       "0          tmja  7415.0  7673.0  6396.0  7378.0  7643.0  7195.0  7971.0   \n",
       "1         pc_pl     4.2     4.2     4.6     4.9     5.0     3.9     5.1   \n",
       "0          tmja     NaN  3468.0  2137.0  3546.0  4393.0  4424.0  3730.0   \n",
       "1         pc_pl     NaN    11.1    13.5    11.4    10.3     7.0    10.7   \n",
       "0          tmja  4995.0  5436.0  3830.0  5808.0  6247.0     NaN     NaN   \n",
       "..          ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "1         pc_pl     3.3     3.3     4.1     3.8     NaN     2.8     3.5   \n",
       "0          tmja  3773.0  3901.0  2701.0  3845.0     NaN  4216.0  4107.0   \n",
       "1         pc_pl     3.3     3.3     4.1     3.8     NaN     2.8     3.5   \n",
       "0          tmja  3773.0  3901.0  2701.0  3845.0     NaN  4216.0  4107.0   \n",
       "1         pc_pl     3.3     3.3     4.1     3.8     NaN     2.8     3.5   \n",
       "\n",
       "      octo    nove    dece      id_comptag annee    mars    avri  \n",
       "0   7785.0  5511.0  6336.0    47-D813-42+0  2020     NaN     NaN  \n",
       "1      5.3     6.9     4.8    47-D813-42+0  2020     NaN     NaN  \n",
       "0   3696.0  2117.0  2674.0    47-D655-30+0  2020  2066.0  1106.0  \n",
       "1     10.5    16.8    11.4    47-D655-30+0  2020    14.7    24.6  \n",
       "0   5677.0  3841.0  4468.0  47-D666-10+500  2020  3490.0  2322.0  \n",
       "..     ...     ...     ...             ...   ...     ...     ...  \n",
       "1      3.4     4.6     3.0  47-D676-29+740  2020     3.9     6.8  \n",
       "0   4050.0  2805.0  3438.0  47-D676-29+740  2020  2401.0  1368.0  \n",
       "1      3.4     4.6     3.0  47-D676-29+740  2020     3.9     6.8  \n",
       "0   4050.0  2805.0  3438.0  47-D676-29+740  2020  2401.0  1368.0  \n",
       "1      3.4     4.6     3.0  47-D676-29+740  2020     3.9     6.8  \n",
       "\n",
       "[370 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpt47.df_attr_mens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***CD87***\n",
    "> Dans ce Departement les donnees sont fournies en fichiers .fim. il vaut recalculer les valeusr de comptages <br> Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD87\\Fichiers FIM 87 -2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***lister les voies, classer les types de commptages, lister les fichiers a regrouper***\n",
    "> le dossier contient un tres grand nombre de fihciers, parfois ils sont a regrouper, parfois la structure de nommage varie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d87=it.Comptage_cd87(r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\CD87\\CD87- Comptages 2019 Fichiers .fim','2019') \n",
    "d87.dico_pt_cptg() #creer le dico de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d87.dico_voie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Traiter les donnees***\n",
    "> Pour chaque route référencée dans le dico, on va calculer les TMJA %PL, date_debut, date_fin, type_poste de chaque fichiers puis\n",
    "faire les calculs si necessaires (moyenne si plsr fichiers).<br> ensuite on classe puis update et insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mettre à jour le dico et le transformer en dataframe sans les ponctuels pendant les grandes vacances\n",
    "d87.dataframe_dico_glob()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparer les données\n",
    "#attention cela comprend un script d'identification des points pas forcément nécéssaire\n",
    "d87.classer_comptage_update_insert('gti_otv_pg11','na_2010_2019_p','comptage',\n",
    "                                   'public','d87_cpt_temp','lineaire.traf2018_bdt87_ed18_l',\n",
    "                                  'ref', 'troncon_route_bdt87_ed18_l','troncon_route_bdt87_ed18_l_vertices_pgr','id','ref.pr_ed18_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mettre à jour les données\n",
    "d87.update_bdd_d87('gti_otv_pg11','na_2010_2019_p','comptage')\n",
    "#insérer les données et mettre à jour les geom\n",
    "d87.insert_bdd_d87('gti_otv_pg11','na_2010_2019_p','comptage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Outils.CopierFichierDepuisArborescence(r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\CD87\\Permanents 2019\\2019',\n",
    "                                      r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\CD87\\Permanents 2019\\tousFichiersVrac',\n",
    "                                      '.fim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d87=it.Comptage_cd87(r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\CD87\\Permanents 2019\\tousFichiersVrac','2019') \n",
    "d87.dico_pt_cptg() #creer le dico de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d87.df_attr.sort_values('id_comptag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"11\" ></a>\n",
    "# ***CD 16***\n",
    "- Année 2018 : \n",
    "> à partir du fichier D:\\temp\\otv\\Donnees_source\\CD16\\B15_2018.xlsx on traite les permanents.<br> à partir des donnees sur PIGMA on traite les compteurs temporaires <br>***attention : il y a aussi des données de comptages temporaires en FIM qui permettront d'obtenir de la données horaires***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2018\n",
    "cd16=it.Comptage_cd16(r'D:\\temp\\otv\\Donnees_source\\CD16\\B15_2018.xlsx',r'D:\\temp\\otv\\Donnees_source\\CD16\\pigma\\comptages_routiers_2019\\comptages_routiers.shp',\n",
    "                      r'D:\\temp\\otv\\Donnees_source\\CD16\\pigma\\position_compteurs_2019\\position_compteurs.shp',2018)\n",
    "cd16.comptage_forme()\n",
    "cd16.classer_comptage_update_insert('local_otv', 'na_2010_2018_p')\n",
    "\n",
    "cd16.classer_comptage_update_insert('local_otv', 'na_2010_2018_p')\n",
    "\n",
    "cd16.update_bdd_16('local_otv','comptage','na_2010_2018_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019\n",
    "cd16 = it.Comptage_cd16(r'D:\\temp\\otv\\2019\\Donnees_source\\CD16\\B15_2019.xlsx', r'D:\\temp\\otv\\2019\\Donnees_source\\CD16\\SIG_Comptages_CD16\\Comptages_routiers.shp',\n",
    "                        r'D:\\temp\\otv\\2019\\Donnees_source\\CD16\\SIG_Comptages_CD16\\Position_compteurs.shp',2019)\n",
    "cpt_a_ignorer = ('16-D731-27+45','16-D910-23+821', '16-D1000-16+35')\n",
    "cd16.comptage_forme(7,('16-D731-27+45','16-D910-23+821', '16-D1000-16+35'),r'D:\\temp\\otv\\2019\\Donnees_source\\CD16\\Comptages_secondaires_CD16_2019')\n",
    "cd16.classer_comptage_update_insert('local_otv_station_gti', 'na_2010_2019_p')\n",
    "# cd16.update_bdd_16('local_otv_station_gti','comptage', 'na_2010_2019_p')\n",
    "# cd16.insert_bdd('local_otv_station_gti','comptage','na_2010_2019_mensuel',cd16.df_attr_mens)\n",
    "# cd16.insert_bdd('local_otv_station_gti','comptage','na_2010_2019_horaire',cd16.df_attr_horaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Année 2020 : \n",
    "> récupération des données horaires à partir du format IRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd16 = it.Comptage_cd16(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD16\\en_cours\\B15_2020.pdf','toto', 'tata', '2020',\n",
    "                        r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD16\\en_cours\\CD16_IRIS_TV',\n",
    "                        r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD16\\en_cours\\CD16_IRIS_PL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# réation des données Horaires completes\n",
    "dataHoraireCompelete = cd16.creerDTtjoursttIndicIris()\n",
    "\n",
    "# filtre des jours non conforme\n",
    "dfHoraireFichierFiltre, dfJourIdcptARetirer = verifValiditeFichier(dataHoraireCompelete, 24)\n",
    "\n",
    "# verif sur la concordance des 2 sens de circulation\n",
    "comparer2Sens(dfHoraireFichierFiltre, attributSens='sens' )[1]\n",
    "\n",
    "# concatener les deux sens\n",
    "dfHoraireConcat = concatIndicateurFichierHoraire(dfHoraireFichierFiltre,\n",
    "                                                 'indicateur')\n",
    "\n",
    "# calcul des TMJAs\n",
    "indic_agrege = tmjaDepuisHoraire(dfHoraireConcat.assign(annee=cd16.annee))\n",
    "\n",
    "# calcul du mensuel\n",
    "tmjMens = mensuelDepuisHoraire(dfHoraireConcat.assign(annee=cd16.annee))\n",
    "tmjMens = tmjMens.loc[~tmjMens.valeur.isna()].copy()\n",
    "\n",
    "# verif que tous les id_comptag existent deja en bdd\n",
    "dfIdsConnus, dfIdsInconnus = cd16.scinderComptagExistant(indic_agrege,\n",
    "                                                         '2020',\n",
    "                                                         dep='16')\n",
    "dfIdsInconnus.empty\n",
    "\n",
    "# insertion des donnees de comptage\n",
    "cd16.insererComptage(dfIdsConnus.drop_duplicates(['id_comptag', 'annee'])[[\n",
    "    'id_comptag', 'annee']].assign(src='donnees horaire IRIS', type_veh='tv/pl'))\n",
    "\n",
    "# insertion des données agrege\n",
    "cd16.insererAgrege(indic_agrege.merge(\n",
    "    cd16.recupererIdUniqComptage(indic_agrege.id_comptag.tolist(), '2020')\n",
    "    ).assign(obs='calcule depuis donnees horaire IRIS'\n",
    "    ).merge(dfHoraireConcat[['id_comptag', 'fichier']].drop_duplicates(['id_comptag', 'fichier']).sort_values('id_comptag').groupby('id_comptag').agg(\n",
    "     {'fichier' : lambda x : ','.join(x)}), on='id_comptag').drop(['id_comptag', 'annee'], axis=1))\n",
    "\n",
    "# insertion des données mensuelles\n",
    "cd16.insererMensuel(tmjMens.merge(\n",
    "    cd16.recupererIdUniqComptage(indic_agrege.id_comptag.tolist(), '2020')\n",
    "    ).merge(dfHoraireConcat[['id_comptag', 'fichier']].drop_duplicates(['id_comptag', 'fichier']).sort_values('id_comptag').groupby('id_comptag').agg(\n",
    "     {'fichier' : lambda x : ','.join(x)}), on='id_comptag').drop(['id_comptag', 'annee'], axis=1))\n",
    "\n",
    "#insertion des données hoarires\n",
    "cd16.insererHoraire(dfHoraireConcat.merge(\n",
    "    cd16.recupererIdUniqComptage(indic_agrege.id_comptag.tolist(), '2020'), on='id_comptag').drop(['mois', 'annee_x', 'annee_y', 'id_comptag'], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> récupération des données de compmtages temporaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd16 = it.Comptage_cd16(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD16\\en_cours\\B15_2020.pdf',\n",
    "                        r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD16\\historique\\2019\\SIG_Comptages_CD16\\Comptages_routiers.shp',\n",
    "                        r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD16\\historique\\2019\\SIG_Comptages_CD16\\Position_compteurs.shp',\n",
    "                        '2020',\n",
    "                        r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD16\\en_cours\\CD16_IRIS_TV',\n",
    "                        r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD16\\en_cours\\CD16_IRIS_PL',\n",
    "                        r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\CD16\\en_cours\\CD16_Temporaires')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recupération des données PIGMA et mise en forme des données horaire\n",
    "donnees_tmp_filtrees = cd16.cpt_tmp_pigma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creer et mettre en forme les donnees horaires, et les données de comptage\n",
    "cd16.donnees_horaires(donnees_tmp_filtrees)\n",
    "dfComptag = cd16.df_attr_horaire[['id_comptag', 'qualite', 'periode', 'sens_cpt']].drop_duplicates().assign(annee=cd16.annee)\n",
    "dfComptag = dfComptag.groupby(['id_comptag','sens_cpt', 'annee']).agg({'qualite': min, 'periode': lambda x : ' ; '.join(list(x))}).reset_index()\n",
    "cd16.corresp_nom_id_comptag(dfComptag)\n",
    "cd16.df_attr_horaire = concatIndicateurFichierHoraire(cd16.df_attr_horaire, attributIndicateur='indicateur')\n",
    "dfIndicAgrege = tmjaDepuisHoraire(cd16.df_attr_horaire.assign(annee=cd16.annee))\n",
    "dfIndicAgrege = dfIndicAgrege.merge(cd16.df_attr_horaire[['id_comptag', 'fichier']].drop_duplicates(['id_comptag', 'fichier']), on='id_comptag'\n",
    "                        ).groupby(['id_comptag','indicateur', 'annee', 'valeur']).agg({'fichier': lambda x : ' ; '.join(list(x))}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insertion des données \n",
    "cd16.insererComptage(cd16.creer_comptage(dfComptag.id_comptag.tolist(),'2020', 'gestionnaire', obs='fichiers FIM', periode=dfComptag.periode, type_veh='vl/pl'))\n",
    "cd16.insererAgrege(cd16.recupererIdUniqComptage(dfIndicAgrege).drop(['id_comptag', 'annee'], axis=1))\n",
    "cd16.insererHoraire(cd16.recupererIdUniqComptage(cd16.df_attr_horaire.assign(annee='2020')).drop(['id_comptag', 'annee'], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***CD 86***\n",
    "Attention , dans ce département parfois ce sont les données en PLOD et ASCD qui sont ok, parfois c'est le cumulD <br>\n",
    "Dans ce Dept, les Compmtages dites 'Secondaires' sont équivalent à 'tournants', et 'Tournants' equivalent à 'ponctuel'\n",
    "- Année 2018 : \n",
    "> à partir des fichier D:\\temp\\otv\\Donnees_source\\CD86\\comptages permanents 2018.xlsx et  D:\\temp\\otv\\Donnees_source\\CD86\\Postes secondaires 2018.xls on traite les permanents et secondaires <br> il y a un petit pb sur les compteurs permanents entre la donnees pr+abs chez nous et la leur dans le tableau, donc il faut la premiere fois tout passer dans la table de correspondance.<br> dans ce dept pas de nouveau points\n",
    "- Année 2019 : \n",
    "> un seul fichier avec les comptages sur 2feuilles : permanents et tournants.<br> la feuille permanent contient aussi des données 'Tournant' qui sont masquées, pour lesquelles les reference en abscisse sont tuojours à 0<br> 3 nouveaux points tournants ajoutés à  la main, le reste des ponctuels en auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2018\n",
    "cd86=it.Comptage_cd86(r'D:\\temp\\otv\\Donnees_source\\CD86\\comptages permanents 2018.xlsx',r'D:\\temp\\otv\\Donnees_source\\CD86\\Postes secondaires 2018.xls')\n",
    "\n",
    "#si besoin de dico corresp : \n",
    "corr=cd86.corresp_perm('local_otv', 'na_2010_2018_p')\n",
    "cd86.insert_bdd('local_otv', 'comptage','corresp_id_comptag',corr)\n",
    "\n",
    "#sinon\n",
    "cd86.comptage_forme()\n",
    "cd86.classer_comptage_update_insert('local_otv', 'na_2010_2018_p')\n",
    "cd86.update_bdd_86('local_otv','comptage','na_2010_2018_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2019\n",
    "cd86=it.Comptage_cd86(r'D:\\temp\\otv\\2019\\Donnees_source\\CD86\\Comptages globaux 2019 tournants et permanents.xlsx',r'D:\\temp\\otv\\2019\\Donnees_source\\CD86\\Comptages globaux 2019 tournants et permanents.xlsx',2019,\n",
    "                     'permanents','secondaires')\n",
    "cd86.comptage_forme('local_otv_station_gti', 'na_2010_2019_p')\n",
    "cd86.classer_comptage_update_insert('local_otv_station_gti', 'na_2010_2019_p')\n",
    "cd86.update_bdd_86('local_otv_station_gti','comptage','na_2010_2019_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd86.classer_comptage_update_insert('local_otv_station_gti', 'na_2010_2019_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd86.df_attr_insert['dep']='86'\n",
    "cd86.df_attr_insert['reseau']='RD'\n",
    "cd86.df_attr_insert['gestionnai']='CD86'\n",
    "cd86.df_attr_insert['concession']='N'\n",
    "cd86.df_attr_insert['obs']=\"nouveau_point 2019, denomination CD86='tournant'\"\n",
    "cd86.df_attr_insert.rename(columns={'absc' : 'abs', 'tmja':'tmja_'+str(cd86.annee),'pc_pl':'pc_pl_'+str(cd86.annee),'obs':'obs_'+str(cd86.annee), 'src':'src_'+str(cd86.annee)},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd86.insert_bdd_86('local_otv_station_gti', 'comptage','na_2010_2019_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ct.ConnexionBdd('local_otv_gti', localisation='maison') as c : \n",
    "    ct.ogr2ogr_csv2pg(c.connstringOgr, r'F:\\Boulot\\otv\\corresp_id_comptag.csv',schema='public', table='corr_id',encodageClient='UTF-8', headers='YES')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***CD 24***\n",
    "- Année 2018 : \n",
    "> à partir des fichier D:\\temp\\otv\\Donnees_source\\CD24\\2018_CD24_trafic.csv <br> il n'y a que les compteurs permanents.<br> **Données Mensuelles dispos**.<br> Pensez que des céhanges ont ue lieu pour récupérer tous les points de comptages (perm, tourn, ponct). <br> ***Gros pb de geooloc des PR ign***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd24=it.Comptage_cd24(r'D:\\temp\\otv\\Donnees_source\\CD24\\2018_CD24_trafic.csv')\n",
    "cd24.comptage_forme()\n",
    "cd24.classer_comptage_update_insert('local_otv_station_gti', 'na_2010_2018_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd24.update_bdd_24('local_otv_station_gti', 'comptage', 'na_2010_2018_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd24.insert_bdd_24('local_otv_station_gti', 'comptage', 'na_2010_2018_p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Année 2019 : \n",
    ">à partir du fichier Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\CD24\n",
    "que les compteurs permanents et tournants.\n",
    "a voir pour les ponctuels, possibilité aussi de récupérer des données à partirde leur Web SIG : https://dordogne.maps.arcgis.com/apps/MapTools/index.html?appid=34558f68af514a63b6b7426ed77d055f en scrolant et enregistrant les différents fichiers html. ensuite pandas a une fonction read_html qu el'on applique sur des slices du fichiers html (car la fonction renvoi tout les elements dans des slices diffrentes : ligne du tableau, carte, etc...)<br> IL POURRAIT ETRE INTERESSANT DE METTRE A JOUR LES DONNEES DE GEOM SI BESOIN AVCE LES LONG/LAT issues du fichier source du CD24 quand c'est possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd24=it.Comptage_cd24(r'D:\\Boulot\\AffairesEnCours\\OTV\\24_donnees_sources\\EXPORT SIG COMPTAGES CD24.csv',2019)\n",
    "cd24.comptage_forme()\n",
    "cd24.classer_comptage_update_insert('local_otv_gti', 'na_2010_2019_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd24.update_bdd_24('local_otv_gti', 'comptage', 'na_2010_2019_p')\n",
    "cd24.insert_bdd('local_otv_gti', 'comptage', 'na_2010_2019_p', cd24.df_attr_insert)\n",
    "cd24.insert_bdd('local_otv_gti', 'comptage', 'na_2010_2019_mensuel', cd24.df_attr_mens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***CD 33***\n",
    "- Année 2019 : \n",
    "> à partir du fichier de comptage C:\\Users\\martin.schoreisz\\Box\\Dossier_Personnel_de_Martin_SCHOREISZ\\OTV\\33\\CD33\\export  2019 pour DREAL.xlsx (aussi présent sur les anciens serveurs) et du fichier de sectionnement C:\\Users\\martin.schoreisz\\Box\\Dossier_Personnel_de_Martin_SCHOREISZ\\OTV\\33\\CD33\\SECT_2021_CAT en cours.shp <br> On va chercher à recouper les comptages avec les notres en associant l'identifiant de troncon.<br> les troncons du CD ont l'air cohérents, on va qd mm checker les regrouepemnt <br> **Données Mensuelles dispos**<br> environ 70 cpt permanents et 60 tournants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cptPerm33 = it.Comptage_cd33( r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\CD33\\export_2019_pour_DREAL.xlsx',2019,\n",
    "                         r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\CD33\\SECT_2021_CAT en cours.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trouver les connus et inconnus\n",
    "GdfPerm,gdfPermConnus, gdfPermInconnus=cptPerm33.trierPermConnus('local_otv_boulot', 'na_2010_2019_p', 'boulot')\n",
    "# assigner les inconnu manuellement\n",
    "dico_corresp={'0106_03':'33-D106-35+835'}\n",
    "cptPerm33.assignerCptInconnus(dico_corresp,gdfPermInconnus)\n",
    "# fusion\n",
    "gdfPermConnus=pd.concat([gdfPermConnus, gdfPermInconnus.loc[~gdfPermInconnus.id_comptag.isna()]])\n",
    "gdfPermInconnus=gdfPermInconnus.loc[gdfPermInconnus.id_comptag.isna()]\n",
    "GdfPerm=pd.concat([gdfPermConnus,gdfPermInconnus])\n",
    "# mensuel\n",
    "donnees_mens_perm=GdfPerm[['troncon']+[m for m in it.dico_mois.keys()]].assign(donnees_type='tmja')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comptages tournants\n",
    "tournant=cptPerm33.analyseTourn()\n",
    "donneesMensTour=cptPerm33.donneesMensTournant(tournant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chercher les correspondance\n",
    "rqtPpvCptTournant = \"\"\"SELECT DISTINCT ON (c.troncon) t.id_ign, c.troncon\n",
    " FROM test_affectation_cd33_tournant t JOIN tournant_geoloc_l93 c ON st_dwithin(c.geom, t.geom,30)\n",
    " ORDER BY c.troncon, st_distance(t.geom, c.geom)\"\"\"\n",
    "rqtCptExistant = \"select id_ign, id_comptag from lineaire.traf2019_bdt33_ed19_l\"\n",
    "rqtGeomReferentielEpure = 'select id_ign, geom from test_affectation_cd33_tournant'\n",
    "rqtPpvCptBdd = \"\"\"SELECT DISTINCT ON (t.id_ign) t.id_ign, c.id_comptag\n",
    " FROM test_affectation_cd33_tournant t JOIN comptage.na_2010_2019_p c ON st_dwithin(c.geom, t.geom,30)\n",
    " WHERE c.gestionnai='CD33'\n",
    " ORDER BY t.id_ign, st_distance(t.geom, c.geom)\"\"\"\n",
    "correspTournant, inconnuTournant = cptPerm33.correspondanceTournant('gti_otv_pg11', 'boulot', rqtPpvCptTournant, rqtCptExistant, rqtGeomReferentielEpure, rqtPpvCptBdd,\n",
    "                               'public', 'test_affectation_cd33_tournant','test_affectation_cd33_tournant_vertices_pgr', tournant )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apres analyse mano : \n",
    "dicoCorrespTourn={'0005_06':'33-D5-76+0',\n",
    "                  '0012_11':'33-D12-17+200',\n",
    "                  '0115_06' : '33-D115-103+0',\n",
    "                 '0116_01':'33-D116-23+0',\n",
    "                 '0216_02':'33-D216-15+0',\n",
    "                 '0222_02':'33-D222-16+0',\n",
    "                 '0655_01':'33-D655-10+0'}\n",
    "cptTournantAffecte=cptPerm33.correctionCorrespondanceTournant(dicoCorrespTourn,tournant,correspTournant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creer les df_attr sur le mm schema que les habituels\n",
    "cptPerm33.df_attr_update=pd.concat([cptTournantAffecte.loc[cptTournantAffecte.correspondance==True][['id_comptag', 'tmja_2019', 'pc_pl_2019', 'obs_2019', 'src_2019', 'fichier']],\n",
    "gdfPermConnus[['id_comptag', 'tmja_2019', 'pc_pl_2019', 'src_2019', 'fichier']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creer nouveaux points tournants\n",
    "dicoNewCpt={'troncon':['0652_00','0003_17','0005_00','0009_02','0011_05','0012_10','0012_13','0110_01','0214_00','0222_01','0651_02','0932_03'],\n",
    "             'pr':[4,163,61,32,55,11,39,15,3,5,34,0],\n",
    "             'absc':[280,60,600,90,760,0,330,885,980,280,20,812]}\n",
    "cptPerm33.df_attr_insert=cptPerm33.creerNouveauPointTournants(cptTournantAffecte,dicoNewCpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cptPerm33.df_attr_insert\n",
    "cptPerm33.df_attr_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#donnees mensuelles\n",
    "donnees_mens_perm.merge(GdfPerm[['troncon', 'id_comptag']], on='troncon')\n",
    "df_corresp_mens=cptTournantAffecte[['troncon','id_comptag']].merge(cptPerm33.df_attr_insert[['troncon','id_comptag']], on='troncon', how='left')\n",
    "df_corresp_mens['id_comptag']=df_corresp_mens.apply(lambda x : x['id_comptag_x'] if not pd.isnull(x['id_comptag_x']) else x['id_comptag_y'], axis=1)\n",
    "df_attr_mens=pd.concat([donneesMensTour.merge(df_corresp_mens[['troncon', 'id_comptag']], on='troncon'),\n",
    "                        donnees_mens_perm.merge(GdfPerm[['troncon', 'id_comptag']], on='troncon')]).drop('troncon', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cptPerm33.insert_bdd('gti_otv_pg11', 'comptage', 'na_2010_2019_mensuel',df_attr_mens.assign(annee=str(cptPerm33.annee)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***SCA***\n",
    "- Année 2018 : \n",
    "> Concerne COFIROUTE, VINCI, ALIENOR, ATLANDES.<br> Des données de correspondances id_comptages sont dans la table source de la base de données otv.<br> **Donnees TMJM dispos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## COFIROUTE \n",
    "> l'id_comptage est ajouté manuellement dans le fichier source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation\n",
    "fichier = r'C:\\Users\\martin.schoreisz\\Box\\Dossier_Perso\\OTV\\donnees_gestionnaires\\COFIROUTE\\en_cours\\Resultats_2020.xlsx'\n",
    "annee = '2020'\n",
    "cofi = it.Comptage_Cofiroute(annee, fichier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation / insertion (penser au parametre inserer des fonctions)\n",
    "dfComptage = cofi.insererDonneesComptageBdd()\n",
    "dfAgrege = cofi.insererDonneesAgregeBdd()\n",
    "dfMensuel = cofi.insererDonneesMensuelleBdd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\" ></a>\n",
    "- ## VINCI \n",
    "> L'idée c'est d'importer le tableur et les données et de faire la jointure pour mise à jour.<br>**ATTENTION : rien de prévu si nouveau points** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018\n",
    "cpt = it.Comptage_vinci(r'D:\\temp\\otv\\Donnees_source\\VINCI\\2018_comptage_vitesse_moyenne_VINCI.xlsx')\n",
    "cpt.update_bdd_Vinci('local_otv_station_gti', 'comptage', 'na_2010_2018_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019\n",
    "cpt = it.Comptage_vinci(r'D:\\temp\\otv\\2019\\Donnees_source\\ASF\\bdd_point_comptage et vitesse moyenne 2019.xlsx', 2019)\n",
    "cpt.update_bdd_Vinci('local_otv_station_gti', 'comptage', 'na_2010_2019_p')\n",
    "# cpt.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_mensuel',cpt.df_attr_mens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020 : pb de jointure entre les donnees et les id_comptag en base, donc je fais simple et je copie d'id comptage manuellement\n",
    "cpt = it.Comptage_vinci(r'C:\\Users\\martin.schoreisz\\Box\\Dossier_Perso\\OTV\\donnees_gestionnaires\\ASF\\en_cours\\bdd_point_comptage et vitesse moyenne 2020.xlsx', 2020)\n",
    "cpt.classer_comptage_update_insert('local_otv_boulot', 'compteur')\n",
    "# cpt.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_mensuel',cpt.df_attr_mens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insertion comptage\n",
    "cpt.insert_bdd('local_otv_boulot', 'comptage', 'comptage',cpt.creer_comptage(cpt.df_attr.id_comptag.tolist(), cpt.annee, 'tableur Vinci', 'tv/pl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insertion agrege\n",
    "cpt.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege',\n",
    "               cpt.structureBddOld2NewForm(cpt.df_attr_update, cpt.annee,['id_comptag', 'annee', 'fichier'],['tmja', 'pc_pl'], 'agrege'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insertion mensuel\n",
    "cpt.insert_bdd('local_otv_boulot', 'comptage', 'indic_mensuel',cpt.structureBddOld2NewForm(cpt.df_attr_mens, \n",
    "               cpt.annee,['id_comptag', 'annee', 'fichier', 'donnees_type'],['janv', 'fevr', 'mars', 'avri', 'mai', 'juin', 'juil', 'aout', 'sept',\n",
    "               'octo', 'nove', 'dece'], 'mensuel'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\" ></a>\n",
    "- ## ALIENOR / ATLANDES\n",
    "> Que 7 points chaucun, j'utilise surtout là pour les donees mensuelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alienor = it.Comptage_alienor(r'D:\\temp\\otv\\2019\\Donnees_source\\ALIENOR\\ALIENOR_trafic_2019.xlsx', 2019)\n",
    "alienor.ouvrir_et_separe_donnees()\n",
    "alienor.update_bdd_Alienor('local_otv_station_gti', 'comptage', 'na_2010_2019_p')\n",
    "alienor.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_mensuel',alienor.df_attr_mens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlandes = it.Comptage_atlandes(r'D:\\temp\\otv\\2019\\Donnees_source\\ATLANDES\\2019_trafic_atlandes_7_boucles.xls', 2019)\n",
    "atlandes.donnees_mens()\n",
    "atlandes.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_mensuel',atlandes.df_attr_mens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020\n",
    "alienor = it.Comptage_alienor(r'C:\\Users\\martin.schoreisz\\Box\\Dossier_Perso\\OTV\\donnees_gestionnaires\\ALIENOR\\en_cours\\ALIENOR_trafic_2020.xlsx', '2020')\n",
    "alienor.ouvrir_et_separe_donnees()\n",
    "alienor.insererComptage(alienor.creer_comptage(alienor.df_attr.id_comptag.tolist(),\n",
    "                        '2020', 'tableau DIT', 'vl/pl', obs='attention, dans le tableau DIT 2020 les id_comptag sont décalés par rapport aux id_comptag ALIENOR 2019'))\n",
    "alienor.insererAgrege(alienor.structureBddOld2NewForm(alienor.df_attr.assign(annee='2020').rename(columns={'tmja_2020': 'tmja', 'pc_pl_2020': 'pc_pl'}),\n",
    "                      '2020', ['id_comptag', 'src', 'annee', 'fichier'], ['tmja', 'pc_pl'], 'agrege'))\n",
    "alienor.insererMensuel(alienor.structureBddOld2NewForm(alienor.df_attr_mens, '2020', ['id_comptag', 'donnees_type', 'annee', 'fichier'], \n",
    "                                list(dico_mois.keys()), 'mensuel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020\n",
    "atlandes = it.Comptage_atlandes(r'C:\\Users\\martin.schoreisz\\Box\\Dossier_Perso\\OTV\\donnees_gestionnaires\\ATLANDES\\en_cours\\Trafic atlandes 2020 - 7 boucles DREAL.xls', '2020')\n",
    "donnees = atlandes.miseEnForme()\n",
    "atlandes.insert_bdd('local_otv_boulot', 'comptage', 'comptage', atlandes.donneesAgregees()[['id_comptag', 'src', 'type_veh', 'annee']] )\n",
    "atlandes.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege',\n",
    "                    atlandes.structureBddOld2NewForm(atlandes.donneesAgregees(), atlandes.annee, ['id_comptag', 'annee', 'fichier'], ['tmja', 'pc_pl'], 'agrege'))\n",
    "atlandes.insert_bdd('local_otv_boulot', 'comptage', 'indic_mensuel',\n",
    "                    atlandes.structureBddOld2NewForm(atlandes.df_attr_mens, atlandes.annee, ['id_comptag', 'donnees_type', 'annee', 'fichier'], \n",
    "                                                     ['janv', 'fevr', 'mars', 'avri', 'mai', 'juin', 'juil', 'aout', 'sept', 'octo', 'nove', 'dece'], 'mensuel' ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Grand Poitiers***\n",
    "> on a deja un fichier dans la base de donnees : on va chercher a greffer les donnees et a cree un nouvel id_comptag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ouvrir un fichier\n",
    "dossie r= r'D:\\temp\\otv\\2019\\Donnees_source\\GP\\Automatiques 2019'\n",
    "cpt = it.Comptage_GrandPoitiers(r'D:\\temp\\otv\\2019\\Donnees_source\\GP\\Automatiques 2019',2019)\n",
    "cpt.comptage_forme('local_otv_station_gti')\n",
    "cpt.update_bdd_grdPoi('local_otv_station_gti', 'comptage', 'na_2010_2019_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_horaire', cpt.df_attr_horaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=10 ></a>\n",
    "# ***Ville Anglet***\n",
    "> Ci-dessous simplement un exemple d'ouverture de fcihier .mdb, de liste des tables et de lecture d'une table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Anglet = it.Comptage_Anglet('2016',r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\Anglet\\COMPTAGES ANGLET\\Comptages 2016',\n",
    "                            r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\Anglet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epxortdu fichier csv seravnt a la geoloc\n",
    "Anglet.exporterCsvAGeocoder()\n",
    "# enuiste on geoloc a la main (via l'appli 'mongoecodeur de l'IGN), dans le repertoir dossierResume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# puis on recupere la geoloc et on creer la df permettantde creer des compteurs\n",
    "Anglet.creerDfGeoloc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation des df hoarires et agrege sans filtre\n",
    "Anglet.indicsTousFichiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPPV = Anglet.plusProcheVoisinBddRegroupe('traf2020_bdt_na_ed20_simpli_l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trouver les doublons situés sur un même troncon homogène de trafic\n",
    "listCptDoublons = Anglet.isolerComptagesDoublons(dfPPV).id_comptag.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rechercher des doublons a passer dans comptage_assoc de façon manuelle\n",
    "dfPPV.loc[dfPPV.id_comptag.isin(listCptDoublons)]\n",
    "# on va garder certains, qui vont peut etre etre associé à des "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apres verif on conserve\n",
    "dicoAssoc = {'Anglet-13_rue_de_Lauzin--1.5287;43.4894':['Anglet-7_ter_rue_de_Lauzin--1.5287;43.4895',], 'Anglet-86_rue_de_Chassin--1.5289;43.4916':['Anglet-100_rue_de_Chassin--1.5286;43.4929']}\n",
    "#filtre \n",
    "dfPPVCptRef, dfPPVCptAssoc = Anglet.cptSsDblEtSsGeom(dfPPV, dicoAssoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserer donnees : ATTENTION : ON NE CONSERVE PAS LES POINTS TROP LOIN (a faire ulterieurement)\n",
    "Anglet.insererDatas(dfPPVCptRef.loc[~dfPPVCptRef.gid.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserer les qualites faibles\n",
    "Anglet.insererQualiteFaible(dfPPVCptRef.loc[~dfPPVCptRef.gid.isna()][['id_comptag_bdd', 'id_comptag', \n",
    "                            'note_manuelle_qualite', 'obs_qualite']].rename(columns={'note_manuelle_qualite':'note_manuelle','obs_qualite':'obs' }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insérer les comptages associés\n",
    "# creer la df et les comptages en bdd au passage\n",
    "dfAssoc = Anglet.creerComptageAssoc(dfPPVCptAssoc)\n",
    "dfIndicAgregeAssoc, dfHoraireasso = Anglet.creerIndicsAssoc(dfAssoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Ville Angouleme***\n",
    "> 2021 : une 40aine de points, format MHCorbin, mais un fihcier par sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ang = it.Comptag_Angouleme('2020', r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\Angouleme\\en_cours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dFDataBrutes, dfHshdr = ang.extraireDonneesBrutes()\n",
    "ang.assignerDossierRefEtAdresse(dFDataBrutes, dfHshdr)\n",
    "dfAdresse = ang.adresseUniques(dfHshdr)\n",
    "dfAdresse.adresse.replace('72 St Roch', '70 St Roch', inplace=True)#correction à posteriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visu des adresse sans donnees et creation d'un dico  avec en clé le dossier de reference et ene value une adresse, ou une geoloc en WGS84 si adresse pas dispo\n",
    "dfAdresse.loc[dfAdresse['adresse'].isna()].dir_ref.unique()\n",
    "dicoAdresseMano = {'bd allende section tourgarnier-alsace lorraine': '10 bd salvador allende',\n",
    "                   'bordeaux carrefour st cybard_rue montauzier': '175 rue de bordeaux',\n",
    "                   'bordeaux section montauzier_colone': '161 rue de bordeaux',\n",
    "                   'bd de bury section durosel-gatine': '27 bd de bury',\n",
    "                   'bd de bury section poincaré-durosel': '1 bd de bury',\n",
    "                   'DUROSELLE': '46 r du docteur duroselle', 'JULES FERRY': '3 av jules ferry',\n",
    "                   'bd de liédot section lorraine-olry': '6 bd liedot',\n",
    "                   'limoges section commandant berger_rue paul bert': '206 r de limoges',\n",
    "                   'maréchal juin': '28 av du maréchal juin',\n",
    "                   'montmoreau section bézines_abadie': '90 r de montmoreau',\n",
    "                   'poincarre-citéAdministrative': '10 r raymond poincare',\n",
    "                   'section bellamy-thiers': '45.650174, 0.172777',\n",
    "                   'section léonide lacroix_place mulac': '54 r de saintes',\n",
    "                   'section place mulac_quai du hallage': '36 r de saintes',\n",
    "                   'section quai du hallage_rue de bordeaux': '7 r de saintes',\n",
    "                   'section croix maillot_rue du pont sec': '112 r de saintes',\n",
    "                   'duroselle-montmoreau': '45.643218, 0.160635',\n",
    "                   'rue pierre sémard_rue de la loire': '45.652617, 0.165367',\n",
    "                   'sectiion d1000_bd jean moulin': '45.630431, 0.144746',\n",
    "                   'valette-jean-moulin': ' 45.638887, 0.145055',\n",
    "                   'valette-montmoreau': '45.642477, 0.151709',\n",
    "                   'bretelle entree voie europe-loire': '45.644964, 0.162379'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAdresse2 = ang.assignerAdressesManuelles(dfAdresse, dicoAdresseMano)\n",
    "# ang.exporterCsvAGeocoder(dfAdresse2)\n",
    "ang.creerDfGeoloc(dfAdresse2)\n",
    "ang.creerIndicsTousFichiers(dFDataBrutes)\n",
    "ang.ajouterFichierConcatener()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tester les doublons par section homogene proche\n",
    "dfPPV=ang.plusProcheVoisinBddRegroupe('traf2020_bdt_na_ed20_simpli_l', distance=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trouver les doublons situés sur un même troncon homogène de trafic\n",
    "listCptDoublons = ang.isolerComptagesDoublons(dfPPV).id_comptag.unique()\n",
    "listCptDoublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ang.gdfGeoloc.merge(ang.dfIndicAgrege.loc[ang.dfIndicAgrege.id_comptag.isin(listCptDoublons) & (ang.dfIndicAgrege.indicateur=='tmja')], on='id_comptag').to_file(\n",
    "os.path.join(ang.dossierSource, 'doublons.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apres verif on conserve\n",
    "dicoAssoc = {'Angouleme-27_bd_de_bury-0.165;45.6476':['Angouleme-13_Bury-0.1648;45.6476',], \n",
    "             'Angouleme-6_BD_ALLENDE-0.1671;45.6472':['Angouleme-10_bd_salvador_allende-0.1673;45.6472'],\n",
    "             'Angouleme-8_BD_LIEDOT-0.1701;45.6464':['Angouleme-6_bd_liedot-0.1699;45.6465'],\n",
    "            'Angouleme-195_St_Roch-0.1724;45.6493':['Angouleme-194_St_Roch-0.1725;45.6494'],}\n",
    "# filtre \n",
    "dfPPVCptRef, dfPPVCptAssoc = ang.cptSsDblEtSsGeom(dfPPV, dicoAssoc, True)\n",
    "# liste des comptages à forcer\n",
    "CptAForcer = ('Angouleme-65_besson_bey-0.1578;45.654',\n",
    "                'Angouleme-206_r_de_limoges-0.1779;45.6598',\n",
    "                'Angouleme-28_av_du_maréchal_juin-0.1746;45.6617',\n",
    "                'Angouleme-195_St_Roch-0.1724;45.6493',\n",
    "                'Angouleme-52_BD_LIEDOT-0.173;45.6458',\n",
    "                'Angouleme-3_av_jules_ferry-0.1553;45.6446',\n",
    "                'Angouleme--0.1447;45.6304',\n",
    "                'Angouleme--0.1451;45.6389',\n",
    "                'Angouleme-18_bd_besson_bey-0.1613;45.6601',\n",
    "                'Angouleme-57_BD_CHABASSE-0.1728;45.6468',\n",
    "                'Angouleme-70_St_Roch-0.1641;45.6505')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfert de comptages associés suite à plantage inserion : \n",
    "listCptAssoc=('Angouleme-179_av_Gambetta-0.1613;45.6504',)\n",
    "dfPPVCptRef, dfPPVCptAssoc=ang.transfererAssocSupp(dfPPVCptRef, dfPPVCptAssoc, listCptAssoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insertion des donnees\n",
    "ang.insererDatas(dfPPVCptRef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transférer les comptages associés (ATTENTION, certains CPT -ceux ajoutés à la suite) ne sont pas passé )\n",
    "dfAssoc=ang.creerComptageAssoc(dfPPVCptAssoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Ville Niort***\n",
    "> 2020 : une dizaine de ponts de comptage. l'enjeu est sur al localisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation des donnees a transferer\n",
    "cpt_niort = it.Comptage_Niort(r'D:\\temp\\otv\\2019\\Donnees_source\\Niort\\NIORT_COMPTAGE_ROUTIER_2020\\2020',2020)\n",
    "dico_id_comptag = {\n",
    "                    'Niort-rue_alsace_lorraine--0,4580;46,3287': '01 2020 Alsace Lorraine',\n",
    "                    'Niort-boulevard_cassin--0,4523;46,3223': '01 2020 Rue Terraudiere Bld Cassin_2',\n",
    "                    'Niort-rue_terraudiere--0,4524;46,3228': '01 2020 Rue Terraudiere Bld Cassin_1',\n",
    "                    'Niort-rue_chateau_menu--0,4524;46,3592': '02 2020 Chateau Menu',\n",
    "                    'Niort-rue_de_souche--0,4345;46,3260': '02 2020 rue de Souché',\n",
    "                    'Niort-rue_du_24_fevrier--0,4628;46,3212': '03 2020 24 Février',\n",
    "                    'Niort-avenue_de_paris--0,4458;46,3285': '03 2020 Paris',\n",
    "                    'Niort-avenue_saint_jean_angely--0,4656;46,3203': '03 2020 St Jean',\n",
    "                    'Niort-rue_14_juillet--0,4560;46,3233': '01 2020 Limoges 14 Juillet_2',\n",
    "                    'Niort-rue_marechal_leclerc--0,4400;46,3527': '01 2020 Mal Leclerc',\n",
    "                    'Niort-avenue_de_limoges--0,4565;46,3221': '01 2020 Limoges 14 Juillet_1',\n",
    "                    'Niort-rue_de_la_la_gare--0,4578;46,3203': '01 2020 rue de la gare'}\n",
    "dico_fichiers_final = cpt_niort.creer_dico(dico_id_comptag)\n",
    "cpt_niort.horaire_tout_cpt(dico_fichiers_final)\n",
    "cpt_niort.agrege_tout_cpt(dico_fichiers_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_niort.df_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_txt=cpt_niort.creer_valeur_txt_update(cpt_niort.df_attr, ['id_comptag','tmja','pc_pl', 'src'])\n",
    "cpt_niort.update_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_p', val_txt,{f'tmja_{str(cpt_niort.annee)}':'tmja',f'pc_pl_{str(cpt_niort.annee)}':'pc_pl', f'src_{str(cpt_niort.annee)}':'src'})\n",
    "cpt_niort.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_horaire', cpt_niort.df_attr_horaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 2016 a 2019 : \n",
    "on peut creer le dico_id_comptag a partir des donnees stockes dans la table (geom, id des fchiers, reference du dossier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dossier_src=r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\Niort\\comptages_2016_2019\\CEREMA'\n",
    "annees=['2016','2017','2018','2019']\n",
    "dico_dossier_src={annee:os.path.join(dossier_src, annee) for annee in annees}\n",
    "#obtenir le lien entre les fichiers et de compatg et l'id_comptag, precedemmnet entre dans la bdd via qgis\n",
    "with ct.ConnexionBdd('gti_otv_pg11') as c : \n",
    "    rqt=\"select id_comptag, id_cpt, fichier from comptage.na_2010_2019_p where id_comptag like 'Niort%%' and fichier IS NOT null\"\n",
    "    ids=pd.read_sql(rqt, c.sqlAlchemyConn)\n",
    "#formater pour pouvoir utiliser le code creer pour 2020\n",
    "dico_id_comptag={id_comptag:[os.path.join(d,f) for f in id_cpt.split(';')] for id_comptag,id_cpt,d in \n",
    "                 zip(ids.id_comptag.tolist(),ids.id_cpt.tolist(),ids.fichier.tolist()) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculer les données et les insérer\n",
    "for a,val in dico_dossier_src.items():\n",
    "    dico_limite={k:v for k,v in dico_id_comptag.items() if all([val in e for e in v])}\n",
    "    cpt_niort=it.Comptage_Niort(val,a)\n",
    "    cpt_niort.agrege_tout_cpt(dico_limite)\n",
    "    cpt_niort.horaire_tout_cpt(dico_limite)\n",
    "    cpt_niort.df_attr=cpt_niort.df_attr.loc[~cpt_niort.df_attr.tmja.isna()].copy()\n",
    "    cpt_niort.df_attr_horaire=cpt_niort.df_attr_horaire.loc[cpt_niort.df_attr_horaire.id_comptag.isin(cpt_niort.df_attr.id_comptag.tolist())].copy()\n",
    "    cpt_niort.insert_bdd('gti_otv_pg11', 'comptage', 'na_2010_2019_horaire',cpt_niort.df_attr_horaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Grand Dax***\n",
    "> une 20aine de points de comptage. l'enjeu est sur la localisation : faite à la main pour aller plus vite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cptDax=it.Comptage_GrandDax(r'D:\\temp\\otv\\2019\\donnees_produite\\points_Dax_temp.shp')\n",
    "cptDax.creer_df_agrege()\n",
    "cptDax.df_horaire_final()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cptDax.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_p', cptDax.df_attr)\n",
    "cptDax.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_horaire',cptDax.df_attr_horaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Limoges Metropole***\n",
    "> un Webservice est dispo ici : https://siglm.agglo-limoges.fr/servernf/rest/services/_TRANSPORTS/transports_consult/featureServer\n",
    "on peut y acceder via Qgis, ce qui permet de creer un shape : Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\LIMOGES\\Limoge_Web_service.shp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## isoler les points représentatifs du trafic total\n",
    "1. ajouter des attributs d'identification : de la représentativité, de groupement\n",
    "1. Checker la validité des attributs et déterminer sur lesquels s'appuyer\n",
    "1. Regrouper les points avec un identfiant\n",
    "1. Conserver les points avec 'type' == 'Double' ie 'representatif'=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POUR INFO\n",
    "#rechreche incohérence entre direction et type : direction 2 sens et type Simple\n",
    "limMet.loc[(limMet.apply(lambda x : any([a.lower() in x['direction'].lower() \n",
    "            for a in ('2 sens','2  sens', 'deux sens', 'double sens', 'cumul') if x['direction']]), axis=1)) & (limMet['type']=='Simple')].objectid.tolist()\n",
    "\"\"\"objectId in (40390.0, 40844.0, 41639.0, 42174.0, 42175.0, 42176.0, 42177.0, 42432.0, 42599.0, 43066.0, 43720.0, \n",
    "52077.0, 39017.0, 39274.0, 39586.0, 39959.0, 40014.0, 40015.0) prioriser 'type'=='Double', ne pas trop s'appuyer sur le type\"\"\"\n",
    "#rechreche incohérence entre direction et type : direction != 2 sens et type Double : là aussi, ça confirme de s'appuyer sur le type Double\n",
    "limMet.loc[(limMet.apply(lambda x : all([a.lower() not in x['direction'].lower() \n",
    "            for a in ('2 sens','2  sens', 'deux sens', 'double sens', 'cumul') if x['direction']]), axis=1)) & (limMet['type']=='Double')].objectid.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limMet=it.Comptage_Limoges_Metropole(r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\LIMOGES\\Limoge_Web_service.shp',\n",
    "                                    r'D:\\temp\\otv\\2019\\donnees_produite\\test_limoges\\zone_equi_cpt.shp')\n",
    "limMet.groupe_point()\n",
    "limMet.df_regroupee_complete(limMet.df_regroupee())\n",
    "limMet.insert_bdd('gti_otv_pg11', 'comptage', 'na_2010_2019_p', limMet.df_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Agglo LaRochelle***\n",
    "> bcp de donnée éparpillées u peu n'importe comment ici : <br> Chaque commune à sa façon de bosser..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Exemple sainte-SOulle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dossier=r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\La_Rochelle\\donnees-la-rochelle\\Données La Rochelle\\7-Communes\\SteSoulle'\n",
    "toto=it.Comptage(os.path.join(dossier,'rue des Fortiness.txt'))\n",
    "SteSoulle=pd.read_csv(os.path.join(dossier,'rue des Fortines.txt'), sep=' ')\n",
    "SteSoulle.rename(columns={'Nombrevéhicules':'nbveh', 'Date':'heure'}, inplace=True)\n",
    "SteSoulle.reset_index(inplace=True)\n",
    "SteSoulle.rename(columns={'Nombrevéhicules':'nbveh', 'Date':'heure', 'index':'jour'}, inplace=True)\n",
    "SteSoulle.set_index(SteSoulle.apply(lambda x : pd.to_datetime(x['jour']+ ' ' + x.heure, dayfirst=True), axis=1), inplace=True)\n",
    "#les données sur le 4,10 et 11 février sont bizarres, on les exclus,du coup pour ne pas fausser le tmja avec trop de WE je ne garde que les jours ouvrés et je fais un tmjo\n",
    "#SteSoulle=SteSoulle.loc[(~SteSoulle.index.dayofyear.isin([pd.to_datetime(x).dayofyear for x in (('2016-03-28','2016-03-23','2016-04-02'))]))\n",
    "                       #& (~SteSoulle.index.dayofweek.isin((5,6)))][['nbveh', 'jour', 'heure']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcul tmja (basé sur calcul_indicateurs_agreges() de la classe FIM)\n",
    "df_jour=SteSoulle[['nbveh']].resample('1D').sum()\n",
    "df_jour=df_jour.loc[df_jour['nbveh']!=0].copy()\n",
    "if len(df_jour)<7 : \n",
    "    raise it.PasAssezMesureError(len(df_jour))\n",
    "elif len(df_jour) in (7,8) : \n",
    "    traf_list=df_jour.nbveh.tolist()\n",
    "    tmjo=int(statistics.mean([traf_list[0]+traf_list[-1]]+traf_list[1:-1]))\n",
    "else : \n",
    "    tmjo=int(df_jour.iloc[1:-1].nbveh.mean())*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_horaire=SteSoulle[['jour', 'heure', 'nbveh']].pivot(index='jour', columns='heure', values='nbveh').fillna(0)*2\n",
    "df_horaire.columns=[f'h{str(int(c.split(\":\")[0]))}_{str(int(c.split(\":\")[0])+1)}' for c in df_horaire.columns]\n",
    "df_horaire=df_horaire.reset_index().assign(type_veh='TV', id_comptag='LaRoche-r des fortines--1.0391;46.188')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toto.insert_bdd('gti_otv_pg11', 'comptage', 'na_2010_2019_horaire', df_horaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## La Rochelle\n",
    "plusieurs dossier contenant desfichiers de comptages, : Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\La_Rochelle\\campagne-comptages-2015\\trafic_aggloLR_SMOB2015 ; Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\La_Rochelle\\comptages_delattre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Larochelle.update_bdd_LaRochelle('gti_otv_pg11', 'comptage', 'na_2010_2019_p')\n",
    "Larochelle.insert_bdd('gti_otv_pg11', 'comptage', 'na_2010_2019_horaire', Larochelle.df_attr_horaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepar donnees\n",
    "Larochelle=it.Comptage_LaRochelle(r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\La_Rochelle\\donnees-la-rochelle\\Données La Rochelle\\7-Communes\\LaRochelle_LaPalice')\n",
    "ids=Larochelle.listCptCreer()\n",
    "Larochelle.creer_dfs(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ct.ConnexionBdd('gti_otv_pg11') as c : \n",
    "            rqt=\"select id_comptag, id_cpt from comptage.na_2010_2019_p where id_comptag in ('LaRoch-r marcel deflandre--1.2128;46.1698','LaRoch-r de bethencourt--1.2028;46.1712','LaRoch-r de bethencourt--1.2014;46.172')\"\n",
    "            ids=pd.read_sql(rqt, c.sqlAlchemyConn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fichier=r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\La_Rochelle\\donnees-la-rochelle\\Données La Rochelle\\7-Communes\\LaRochelle_LaPalice\\SEMAINE 2\\P1-RUE MARCEL DEFLANDRE SENS 2 SEMAINE 2.xls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(fichier)\n",
    "tmja=round(df.loc[38,'Unnamed: 6'])\n",
    "pl=round(df.loc[42,'Unnamed: 6'])\n",
    "periode=df.iloc[1,16]\n",
    "index_date=pd.date_range(start=pd.to_datetime(periode.split(' au ')[0][3:], dayfirst=True), end=pd.to_datetime(periode.split(' au ')[1], dayfirst=True))\n",
    "df_pl=df.iloc[17:24,2:26].copy()\n",
    "df_tv=df.iloc[27:34,2:26].copy()\n",
    "df_pl.columns=[f'h{str(i)}_{str(i+1)}' for i in range(24)]\n",
    "df_tv.columns=[f'h{str(i)}_{str(i+1)}' for i in range(24)]\n",
    "df_pl=df_pl.assign(jour=index_date, type_veh='PL')\n",
    "df_tv=df_tv.assign(jour=index_date, type_veh='TV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\" ></a>\n",
    "# ***DIRA***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Année 2019\n",
    "> il existe trois sorte de données, TMJA, TMJM et horaires. les données TMJA DOIVENT etre issu de (ordre de priorité) :<br>\n",
    "1. de la carto DIRA si le point est représenté\n",
    "1. du fichier global (Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\DIRA\\0_tmja_dira_par_section_20200106.ods)\n",
    "1. des fichiers horaires \n",
    "<br> les données horaires ne peuvent etre issue que des fichiers horaires Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\DIRA\\0_Annee_Complete_2019\n",
    "- des graphs dispo dans le notebook Graph_tafics\n",
    "- attention, certaines données de TMJA sont mises à jour apres prises en comptes des données horares,,quand une données horaire est dispo et le TMJA non. fait sous sql  \n",
    "***ATTENTION : EN 2020 IL Y  A EU CONFUSION NETRE LES POINTS rn150 MEDIS ET ST-ROMAIN-DE-BENET / BIEN CHECKER QUE TOUS LES IDENTFIANTS LIES AU BOUCLE ET AUTRES SONT OK***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## *TMJA / TMJM*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation de l'objet\n",
    "dira=it.Comptage_Dira(r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\DIRA\\0_tmja_dira_par_section_20200106.ods',\n",
    "                      r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\DIRA\\0_Annee_Complete_2019',\n",
    "                     '2019','gti_otv_pg11', 'na_2010_2019_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mise en form edes données\n",
    "dfMensGrp=dira.MiseEnFormeMensuelleAnnuelle(dira.verifValiditeMensuelle(dira.jointureExistantFichierTmja('gti_otv_pg11', 'na_2010_2019_p')))\n",
    "dira.MiseEnFormeAnnuelle(dfMensGrp,'16-N10-2+700')\n",
    "dira.MiseEnFormeMensuelle(dfMensGrp,'16-N10-2+700')\n",
    "#mise à jour de la Bdd\n",
    "dira.update_bdd_Dira('gti_otv_pg11', 'comptage', 'na_2010_2019_p', nullOnly=True)\n",
    "dira.insert_bdd('gti_otv_pg11','comptage', 'na_2010_2019_mensuel', dira.df_attr_mens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2020\n",
    "dira=it.Comptage_Dira(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\DIRA\\0_tmja_dira_par_section_20210101.ods',\n",
    "                      r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\DIRA\\GrosFichiers - JP CASSOU\\0_Annee_Complete_2020',\n",
    "                      r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\DIRA\\dira_tmja_2020.ods',\n",
    "                     '2020','local_otv_boulot', 'compteur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mise en forme des données \n",
    "dfMensGrp=dira.MiseEnFormeMensuelleAnnuelle(dira.verifValiditeMensuelle(dira.jointureExistantFichierTmja()))\n",
    "dira.MiseEnFormeAnnuelle(dfMensGrp)\n",
    "dira.MiseEnFormeMensuelle(dfMensGrp)\n",
    "#insertion des comptages\n",
    "dira.insert_bdd('local_otv_boulot', 'comptage', 'comptage', dira.creer_comptage(dira.df_attr.id_comptag.unique(), dira.annee, 'tableau annuel DIRA', 'tv/pl'))\n",
    "#insertion des indicateurs agreges\n",
    "dira.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege',dira.structureBddOld2NewForm(dira.df_attr, dira.annee,['id_comptag', 'annee', 'fichier'],['tmja', 'pc_pl'], 'agrege'))\n",
    "#insertion des indicateurs mensuel\n",
    "dira.insert_bdd('local_otv_boulot', 'comptage', 'indic_mensuel',dira.structureBddOld2NewForm(dira.df_attr_mens.replace(-99, np.nan), \n",
    "            dira.annee,['id_comptag', 'annee', 'fichier', 'donnees_type'],['janv', 'fevr', 'mars', 'avri', 'mai', 'juin', 'juil', 'aout', 'sept',\n",
    "       'octo', 'nove', 'dece'], 'mensuel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gestion des données carto\n",
    "donneesAgregeesUpdate, donneesAgregeesInsert=dira.cptCartoInsertUpdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update comptages\n",
    "dira.update_bdd('comptage', 'comptage', dira.creer_valeur_txt_update(donneesAgregeesUpdate.loc[donneesAgregeesUpdate.obs.isna()], ['id', 'src']),\n",
    "                {'src':'src'}, identifiant='id')\n",
    "dira.update_bdd('comptage', 'comptage', dira.creer_valeur_txt_update(donneesAgregeesUpdate.loc[~donneesAgregeesUpdate.obs.isna()], ['id', 'src', 'obs']),\n",
    "                {'src':'src', 'obs':'obs'}, identifiant='id')\n",
    "#update tmja\n",
    "dira.update_bdd('comptage', 'indic_agrege', dira.creer_valeur_txt_update(donneesAgregeesUpdate.assign(id_comptag_uniq=donneesAgregeesUpdate.id)\n",
    "                                                                         , ['id_comptag_uniq', 'tmja']), {'valeur':'tmja'}, identifiant='id_comptag_uniq',\n",
    "                filtre = \"indicateur='tmja'\")\n",
    "#update pc_pl\n",
    "dira.update_bdd('comptage', 'indic_agrege', dira.creer_valeur_txt_update(donneesAgregeesUpdate.assign(id_comptag_uniq=donneesAgregeesUpdate.id)\n",
    "                                                                         , ['id_comptag_uniq', 'pc_pl']), {'valeur':'pc_pl'}, identifiant='id_comptag_uniq',\n",
    "                filtre = \"indicateur='pc_pl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserer comptages\n",
    "dira.insert_bdd('local_otv_boulot', 'comptage', 'comptage',dira.creer_comptage(donneesAgregeesInsert.id_comptag.unique(), dira.annee, 'carto dira 2020', 'tv/pl', obs=donneesAgregeesInsert.obs.tolist()))\n",
    "dira.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege',dira.structureBddOld2NewForm(donneesAgregeesInsert, dira.annee,['id_comptag', 'annee', 'fichier'],['tmja', 'pc_pl'], 'agrege'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## *Donnees horaires*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time dfTousFichier,idCptNonAffectes,dblATraiter=dira.concatTousFichierHoraire()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vérifier\n",
    "dblATraiter\n",
    "idCptNonAffectes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Séparer les données horaires entres comptages existants et comptages a creer\n",
    "dfHoraireIdConnus, dfHoraireIdsInconnus=dira.scinderComptagExistant(dfTousFichier, dira.annee, table='comptage')\n",
    "dfHoraireIdsInconnus.rename(columns={'type_veh':'indicateur'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comptages a creer\n",
    "#mise en forme des donnees horaire vers du tmja\n",
    "dfTmjaPcpl=tmjaDepuisHoraire(dfHoraireIdsInconnus)\n",
    "dfMeltInconnusPeriode=periodeDepuisHoraire(dfHoraireIdsInconnus)\n",
    "\n",
    "#scinder les tablesvers comptages et indics_agrege\n",
    "#creer les comptages manquants puis recuperer les ids correspondants\n",
    "dfToutTable=dfTmjaPcpl.merge(dfMeltInconnusPeriode[['id_comptag', 'periode']], on=['id_comptag']).assign(\n",
    "    src='tmja reconstitue depuis donnees horaires 2020', type_veh='tv/pl')\n",
    "dfComptages=dfToutTable[['id_comptag','annee', 'periode', 'src', 'type_veh']].drop_duplicates(['id_comptag','annee', 'periode', 'src', 'type_veh'])\n",
    "dira.insert_bdd('local_otv_boulot', 'comptage', 'comptage', dfComptages)\n",
    "dfIdCptUniqsNew=dira.recupererIdUniqComptage(dfComptages.id_comptag.tolist(), '2020', 'local_otv_boulot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserer les indicateurs agreges\n",
    "dfIndicAgreges=dfToutTable[['id_comptag', 'annee', 'indicateur', 'valeur']].merge(dfHoraireIdsInconnus.assign(fichier=dfHoraireIdsInconnus.fichier.apply(\n",
    "    lambda x : ';'.join(set(x.split('.xls'))).strip(';'))).groupby('id_comptag').fichier.agg(lambda x : ';'.join(set(tuple(x)))).reset_index(), on='id_comptag').merge(\n",
    "    dfIdCptUniqsNew, on=['id_comptag','annee']).rename(columns={'id':'id_comptag_uniq'}).drop(['id_comptag', 'annee'], axis=1)\n",
    "dira.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege', dfIndicAgreges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#refaire tourner  l'identification des comptages existant ou non (nromalement tout le monde defvrait etre existant) puis inserer\n",
    "dfHoraireIdConnus, dfHoraireIdsInconnus=dira.scinderComptagExistant(dfTousFichier, dira.annee, table='comptage')\n",
    "dira.insert_bdd('local_otv_boulot', 'comptage', 'indic_horaire',dfHoraireIdConnus.drop(['id_comptag', 'index', 'annee'], axis=1).assign(fichier=dfHoraireIdConnus.fichier.apply(\n",
    "    lambda x : ';'.join(set(x.split('.xls'))).strip(';'))).rename(columns={'type_veh':'indicateur'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Année 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOUVELLE SOURCE DE DONNEES VIA Christophe Damas et DtecTV**\n",
    "on va aussi chercher à obtenir les données DIRA, mais d'abord on puet checker celles contenues dans les fichiersde TV ici : \n",
    "Q:\\DAIT\\TI\\DREAL33\\2021\\OTV\\Doc_travail\\Donnees_sources\\DIRA\\Donnees_Tipi_TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donneesMinutes=pd.read_csv(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\DIRA\\tipi_alienor_raw.v2.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#liste des stations TIPI\n",
    "listIdCompteurTipi=donneesMinutes.PME_ID.unique()\n",
    "#liste des stations OTV\n",
    "with ct.ConnexionBdd('local_otv_boulot') as c : \n",
    "    listObsSupl=pd.read_sql(\"select distinct id_comptag, id_cpt, obs_supl from comptage.compteur where gestionnai='DIRA'\", c.sqlAlchemyConn)\n",
    "listStationOtvBrut=listObsSupl.obs_supl.apply(lambda x : x.split(';')[1].split('station : ')[1] if not pd.isnull(x) and 'EMC' not in x and ';' in x else x).unique()\n",
    "listStationOtvBrut2=[e.split(',') for e in listStationOtvBrut if e and re.search('^M.*\\.._.*$', e)]\n",
    "listStationOtv=[a.strip().replace('_','') for b in listStationOtvBrut2 for a in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#station TIPI non présentes dans OTV : \n",
    "StationTipiHorsOTV=[s for s in listIdCompteurTipi if s not in listStationOtv]\n",
    "StationOtvHorsTipi=[s for s in listStationOtv if s not in listIdCompteurTipi]\n",
    "StationOtvTipi=[s for s in listIdCompteurTipi if s in listStationOtv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"8\" ></a>\n",
    "# ***DIRCO***\n",
    "- Année 2019 : \n",
    "> il existe trois sorte de données, TMJA, TMJM et horaires. les données TMJA et TMJM chaque source de données à sonpropre fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2019\n",
    "fichierMja=r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\DIRCO\\TMJA DIRCO-NA 2019_unfused.csv'\n",
    "fichierMjM=r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\DIRCO\\TMJM DIRCO-NA 2019.ods'\n",
    "dossierHoraire=r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\DIRCO\\données dirco'\n",
    "dirco=it.Comptage_Dirco(fichierMja,fichierMjM,dossierHoraire,'2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2020\n",
    "fichierMja=r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\DIRCO\\TMJA DIRCO 2020 NA.ods'\n",
    "fichierMjM=r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\DIRCO\\TMJM DIRCO 2020 NA.ods'\n",
    "dossierHoraire=r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\DIRCO\\Re_ Observatoire des trafics routiers DREAL NA 2020'\n",
    "dirco=it.Comptage_Dirco(fichierMja,fichierMjM,dossierHoraire,'2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## TMJA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import des données et mise en forme des données\n",
    "dfTrafic=dirco.miseEnFormeMJA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#verifier et creer des compteurs si besoin\n",
    "dfIdsConnus, dfIdsInconnus=dirco.scinderComptagExistant(dfTrafic, '2020', gest='DIRCO')\n",
    "#modfi de la mise en forme\n",
    "dfIdsConnus['obs_supl']=dfIdsConnus.merge(dirco.existant[['obs_supl', 'id_comptag']], on='id_comptag').apply(lambda x : x['obs_supl_y']+';'+x['obs_supl_x'] if x['obs_supl_y'] else x['obs_supl_x'], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#MaJ de l'obs_supl\n",
    "dirco.update_bdd('comptage', 'compteur', dirco.creer_valeur_txt_update(dfIdsConnus.loc[~dfIdsConnus.obs_supl.isna()], ['id_comptag', 'obs_supl']), {'obs_supl':'obs_supl'})\n",
    "#creation des comptages\n",
    "dirco.insert_bdd('local_otv_boulot', 'comptage', 'comptage', dirco.creer_comptage(dfIdsConnus.id_comptag.tolist(), dirco.annee, 'tableau TMJA DIRCO', 'tv/pl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#insertion des données agrégées\n",
    "dirco.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege', \n",
    "                 dirco.structureBddOld2NewForm(dfIdsConnus, '2020', ['id_comptag', 'fichier', 'annee'], ['tmja', 'pc_pl'], 'agrege'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## TMJM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2019\n",
    "dfMensuel=dirco.indicateurGlobalFichierMJM('gti_otv_pg11','3-N145-9+573')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirco.insert_bdd('gti_otv_pg11','comptage', 'na_2010_2019_mensuel', dfMensuel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2020\n",
    "dfMensuel=dirco.indicateurGlobalFichierMJM('local_otv_boulot', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trouver les comptages inconnus en 2020, verifier qu'il ne manque pas de compteur (termine a la main)\n",
    "dfIdsConnus, dfIdsInconnus=dirco.scinderComptagExistant(dfMensuel, '2020', 'comptage', gest='DIRCO')\n",
    "dfIdsInconnus.loc[~dfIdsInconnus.id_comptag.isin(dirco.existant.id_comptag.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creer les commptages inconnus (que si les compteurs existent)\n",
    "dirco.insert_bdd('local_otv_boulot', 'comptage', 'comptage', dirco.creer_comptage(dfIdsInconnus.id_comptag.unique(), dirco.annee, 'tableau TMJM DIRCO', 'tv/pl', obs='1 seul sens disponible'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trouver les comptages ayant des donnees mensuelles mais pas de donnees TMJA\n",
    "dfCptSansTmja=dirco.recupererComptageSansTrafic(dfIdsConnus.id_comptag.tolist(), '2020')\n",
    "dfCptSansTmja2=dfIdsConnus.loc[dfIdsConnus.id_comptag.isin(dfCptSansTmja.id_comptag.tolist())].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculer les indicateurs agreges des comptages sans tmja\n",
    "dfCptSansTmja2['tmja']=dfCptSansTmja2.loc[dfCptSansTmja2.donnees_type=='tmja'].apply(lambda x : int(mean([x[e] for e in dfCptSansTmja2.columns if e not in ('id_comptag', 'donnees_type', 'annee', 'id_comptag_uniq', 'obs')])), axis=1)\n",
    "dfCptSansTmja2['pc_pl']=dfCptSansTmja2.loc[dfCptSansTmja2.donnees_type=='pc_pl'].apply(lambda x : round(mean([x[e] for e in dfCptSansTmja2.columns if e not in ('id_comptag', 'donnees_type', 'annee', 'id_comptag_uniq', 'obs') and not pd.isnull(x[e])]),2), axis=1)\n",
    "#dfCptSansTmja2['valeur']=dfCptSansTmja2.apply(lambda x : x['tmja'] if not pd.isnull(x['tmja']) else x['pc_pl'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserer\n",
    "#agerege\n",
    "dirco.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege', dfCptSansTmja2.rename(columns={'donnees_type':'indicateur'}).assign(fichier=os.path.basename(dirco.fichierTmjm))[['id_comptag_uniq','indicateur','valeur','obs', 'fichier']])\n",
    "#mensuel\n",
    "dirco.insert_bdd('local_otv_boulot', 'comptage', 'indic_mensuel', dirco.structureBddOld2NewForm(dfIdsConnus.assign(fichier=os.path.basename(dirco.fichierTmjm)), \n",
    "                        dirco.annee, ['id_comptag', 'annee','obs', 'fichier', 'donnees_type'], ['janv', 'fevr', 'mars', 'avri', 'mai', 'juin', 'juil', 'aout', 'sept',\n",
    "       'octo', 'nove', 'dece'], 'mensuel' ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Horaire\n",
    "on ne dispose que de donnees TV, et il faut au prealable joindre les id_comptagavec les code_sation des donnes horaire. POur ça on utilise le fichier de tmja comme pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFichierTmja=dirco.miseEnFormeFichierTmjaPourHoraire()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicoCptOkTot,dicoCptErrorTot=dirco.tousFichierHoraires(dfFichierTmja)\n",
    "dicoCptErrorTot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trouver les comptages inconnus en 2020, verifier qu'il ne manque pas de compteur (termine a la main)\n",
    "dirco.corresp_nom_id_comptag(dirco.df_attr_horaire)\n",
    "dfIdsConnus, dfIdsInconnus=dirco.scinderComptagExistant(dirco.df_attr_horaire, '2020', 'comptage', gest='DIRCO')\n",
    "dfIdsInconnus.loc[~dfIdsInconnus.id_comptag.isin(dirco.existant.id_comptag.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfIdsInconnus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creer les commptages inconnus (que si les compteurs existent)\n",
    "dirco.insert_bdd('local_otv_boulot', 'comptage', 'comptage', dirco.creer_comptage(dfIdsInconnus.id_comptag.unique(), dirco.annee, 'donnees horaires DIRCO', 'tv', obs='tmja recalcule a partirdes donnees horaires'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trouver les comptages ayant des donnees horaires mais pas de donnees TMJA\n",
    "dfCptSansTmja=dirco.recupererComptageSansTrafic(dfIdsConnus.id_comptag.tolist(), '2020')\n",
    "dfCptSansTmja2=dfIdsConnus.loc[dfIdsConnus.id_comptag.isin(dfCptSansTmja.id_comptag.tolist())].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mettre en forme les données\n",
    "dfTmja=dfCptSansTmja2[['id_comptag_uniq', 'jour','fichier']+attributsHoraire].assign(tmj=lambda x : sum([x[e] for e in dfCptSansTmja2.columns if e in attributsHoraire])).groupby(['id_comptag_uniq', 'fichier']\n",
    "    ).agg(trafSum=pd.NamedAgg(column='tmj',aggfunc='sum'), \n",
    "        nbJour=pd.NamedAgg(column='jour',aggfunc='count'))\n",
    "dfTmja['valeur']=round(dfTmja['trafSum']/dfTmja['nbJour'])\n",
    "dfTmja['indicateur']='tmja'\n",
    "dfTmja['obs']='tmja recalcule depuis donnees horaires'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserer les donnes agregees non connue\n",
    "dirco.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege',dfTmja.drop(['trafSum', 'nbJour'], axis=1).reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserer les donnes horaires\n",
    "dirco.insert_bdd('local_otv_boulot', 'comptage', 'indic_horaire',dirco.structureBddOld2NewForm(dirco.df_attr_horaire, dirco.annee, ['id_comptag', 'annee'], ['toto'], 'horaire'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"9\" ></a>\n",
    "# ***DIRSO***\n",
    "- Année 2020 : \n",
    "> il n'y a que 2 points, dont les données sont téléchargées directement sur le site de la DIRCO (cf src.txt sur Box)\n",
    "les 2 seuls poijnts qui nous interessent sont MAZERES N524 8+890 et  LAPEYRADE N524 64+800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ficherMensuel=r'C:\\Users\\martin.schoreisz\\Box\\Dossier_Perso\\OTV\\donnees_gestionnaires\\DIRSO\\en_cours\\hors_convention\\tmja_2020_cumule.xls'\n",
    "dirso=it.Comptage(ficherMensuel)\n",
    "dfMens=pd.read_excel(dirso.fichier, skiprows=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMensSo=dfMens.iloc[sorted([a for a in dfMens.loc[dfMens['Intitulé du PM'].isin(('MAZERES', 'LAPEYRADE'))].index]+[a-1 for a in dfMens.loc[dfMens['Intitulé du PM'].isin(\n",
    "    ('MAZERES', 'LAPEYRADE'))].index])].copy()\n",
    "dfMensSo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMensSoTmja=dfMensSo.loc[~dfMensSo.Evts.isna()][[a for b in it.dico_mois.values() for a in b if a in dfMensSo.columns]].assign(\n",
    "    donnees_type='tmja', id_comptag=['33-N524-8+890','40-N524-64+800'],fichier=os.path.basename(ficherMensuel), annee='2020').T.drop_duplicates().T\n",
    "dfMensSoPcpl=dfMensSo.loc[dfMensSo.Evts.isna()][[a for b in it.dico_mois.values() for a in b if a in dfMensSo.columns]].applymap(lambda x : x*100).assign(\n",
    "    donnees_type='pc_pl', id_comptag=['33-N524-8+890','40-N524-64+800'],fichier=os.path.basename(ficherMensuel), annee='2020').T.drop_duplicates().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dirso.insert_bdd('local_otv_boulot', 'comptage', 'indic_mensuel',\n",
    "                 dirso.structureBddOld2NewForm(pd.concat([dirso.renommerMois(dfMensSoPcpl),dirso.renommerMois(dfMensSoTmja)]), '2020', ['id_comptag', 'annee', 'donnees_type'], \n",
    "                                               [k for k in it.dico_mois.keys()], 'mensuel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.read_json(dfMensSo.loc[~dfMensSo.Evts.isna()][[a for b in it.dico_mois.values() for a in b if a in dfMensSo.columns]].T.drop_duplicates().T.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***TESTS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DETAILS OPERATIONS CD87\n",
    "\n",
    "#regrouper les différentes données issues de ficiers et les ajouter au dico\n",
    "for k, v in d87.dico_voie.items() : \n",
    "    for i,e in enumerate(v) : \n",
    "        if len(e['fichiers'])==1 : \n",
    "            print(e['fichiers'][0])\n",
    "            obj_fim=it.FIM(os.path.join(d87.dossier,e['fichiers'][0]))\n",
    "            try : \n",
    "                obj_fim.resume_indicateurs()\n",
    "            except obj_fim.fim_PasAssezMesureError : \n",
    "                continue\n",
    "            except Exception as ex : \n",
    "                print(f\"erreur : {ex} \\n dans fichier : {e['fichiers'][0]}\")\n",
    "            e['tmja'], e['pc_pl'], e['date_debut'], e['date_fin']=obj_fim.tmja, obj_fim.pc_pl, obj_fim.date_debut,obj_fim.date_fin\n",
    "        elif len(e['fichiers'])>1 :\n",
    "            list_tmja=[]\n",
    "            list_pc_pl=[]\n",
    "            for f in e['fichiers'] : \n",
    "                obj_fim=it.FIM(os.path.join(d87.dossier,f))\n",
    "                print(f)\n",
    "                try : \n",
    "                    obj_fim.resume_indicateurs()\n",
    "                except (obj_fim.fim_PasAssezMesureError,obj_fim.fimNbBlocDonneesError)  : \n",
    "                    continue\n",
    "                except Exception as ex : \n",
    "                    print(f\"erreur : {ex} \\n dans fichier : {f}\")\n",
    "                list_tmja.append(obj_fim.tmja)\n",
    "                list_pc_pl.append(obj_fim.pc_pl)\n",
    "            e['tmja'], e['pc_pl'], e['date_debut'], e['date_fin']=int(mean(list_tmja)), round(mean(list_pc_pl),2),np.NaN, np.NaN\n",
    "\n",
    "#renseigner le type de poste\n",
    "for k, v in d87.dico_voie.items() : \n",
    "    for e in v : \n",
    "        if len(e['fichiers']) > 4 :\n",
    "            e['type_poste']='permanent'\n",
    "        elif 1<len(e['fichiers'])<=4 : \n",
    "            e['type_poste']='tournant'\n",
    "        elif len(e['fichiers'])== 1 :\n",
    "            e['type_poste']='ponctuel'\n",
    "        else : \n",
    "            e['type_poste']='NC'\n",
    "\n",
    "#faire une df avec les points de comptage\n",
    "d87.df_attr=pd.DataFrame([[k, e['pr'], e['abs'], e['tmja'], e['pc_pl'], e['type_poste'],\n",
    "                      e['date_debut'],e['date_fin']] for k, v in d87.dico_voie.items() for e in v if 'tmja' in e.keys()], \n",
    "             columns=['route','pr','absc','tmja','pc_pl','type_poste','date_debut','date_fin'])\n",
    "d87.df_attr['id_comptag']=d87.df_attr.apply(lambda x :'87-'+x['route']+'-'+str(x['pr'])+'+'+str(x['absc']), axis=1)\n",
    "\n",
    "#filtre cpt ponctuel\n",
    "d87.df_attr=d87.df_attr.loc[d87.df_attr.apply(lambda x : x['date_debut'].month not in [7,8] and x['date_fin'].month not in [7,8], \n",
    "                                                         axis=1)].copy()\n",
    "\n",
    "#fare le tri avec les comptages existants : \n",
    "#recuperer les compmtages existants\n",
    "d87.comptag_existant_bdd('gti_otv_pg11', 'na_2010_2018_p', schema='comptage',dep='87', type_poste=False)\n",
    "d87.df_attr_update=d87.df_attr.loc[d87.df_attr.id_comptag.isin(d87.existant.id_comptag.tolist())].copy()\n",
    "d87.df_attr_insert=d87.df_attr.loc[~d87.df_attr.id_comptag.isin(d87.existant.id_comptag.tolist())].copy()\n",
    "#obtenir une cle de correspondace pour les comptages tournants et permanents\n",
    "df_correspondance=d87.corresp_old_new_comptag('gti_otv_pg11', 'public','d87_cpt_temp','lineaire.traf2017_bdt87_ed17_l',\n",
    "                                'referentiel', 'troncon_route_bdt87_ed17_l','troncon_route_bdt87_ed17_l_vertices_pgr','id')\n",
    "\n",
    "#verifier si cette clé n'existent pas deja dans la table de correspondance et passer les nouvelles dedans\n",
    "rqt_corresp_comptg='select * from comptage.corresp_id_comptag'\n",
    "with ct.ConnexionBdd('gti_otv_pg11') as c:\n",
    "    corresp_comptg=pd.read_sql(rqt_corresp_comptg, c.sqlAlchemyConn)\n",
    "df_correspondance=df_correspondance.loc[~df_correspondance['id_comptag'].isin(corresp_comptg.id_gest.tolist())]\n",
    "if not df_correspondance.empty():\n",
    "    d87.insert_bdd('gti_otv_pg11', 'comptage', 'corresp_id_comptag', \n",
    "               df_correspondance.rename(columns={'id_comptag_lin':'id_gti','id_comptag':'id_gest'})[['id_gest','id_gti']])\n",
    "\n",
    "#faire la correspondance entre les noms de comptage\n",
    "d87.corresp_nom_id_comptag('gti_otv_pg11',d87.df_attr)\n",
    "\n",
    "#recalculer les insert et update\n",
    "d87.df_attr_update=d87.df_attr.loc[d87.df_attr.id_comptag.isin(d87.existant.id_comptag.tolist())].copy()\n",
    "d87.df_attr_insert=d87.df_attr.loc[~d87.df_attr.id_comptag.isin(d87.existant.id_comptag.tolist())].copy()\n",
    "\n",
    "#mettre en forme pour update\n",
    "d87.df_attr_update['obs']=d87.df_attr_update.apply(lambda x : x['date_debut'].strftime('%d/%m/%Y')+'-'+ x['date_fin'].strftime('%d/%m/%Y') if not pd.isnull(x['date_debut']) else '', axis=1)\n",
    "d87.df_attr_update.loc[d87.df_attr_update.pc_pl.isna(),'obs']='pc_pl inconnu'\n",
    "d87.df_attr_update.loc[d87.df_attr_update.pc_pl.isna(),'pc_pl']=-99\n",
    "\n",
    "#preparer update\n",
    "valeurs_txt=d87.creer_valeur_txt_update(d87.df_attr_update, ['id_comptag','tmja','pc_pl','obs'])\n",
    "dico_attr={'tmja_2018':'tmja','pc_pl_2018':'pc_pl','obs_2018':'obs'}\n",
    "#update\n",
    "d87.update_bdd('gti_otv_pg11', 'comptage', 'na_2010_2018_p', valeurs_txt,dico_attr)\n",
    "\n",
    "#mettre en forme le insert\n",
    "dbl=d87.df_attr_insert.loc[d87.df_attr_insert.duplicated('id_comptag', False)].copy()\n",
    "ss_dbl=d87.df_attr_insert.loc[~d87.df_attr_insert.index.isin(dbl.index.tolist())].copy()\n",
    "dbl=dbl.dropna()\n",
    "dbl_traite=dbl.loc[dbl.tmja==dbl.groupby('id_comptag').tmja.transform(max)].drop_duplicates().copy()\n",
    "d87.df_attr_insert=pd.concat([dbl_traite,ss_dbl], axis=0, sort=False)\n",
    "d87.df_attr_insert.pc_pl.fillna(-99, inplace=True)\n",
    "annee='2018'\n",
    "d87.df_attr_insert['dep']='87'\n",
    "d87.df_attr_insert['reseau']='RD'\n",
    "d87.df_attr_insert['gestionnai']='CD87'\n",
    "d87.df_attr_insert['concession']='N'\n",
    "d87.df_attr_insert['obs']=d87.df_attr_insert.apply(lambda x : f\"\"\"nouveau_point,{x['date_debut'].strftime(\"%d/%m/%Y\")}-{x['date_fin'].strftime(\"%d/%m/%Y\")}\"\"\" if not (pd.isnull(x['date_debut']) and  pd.isnull(x['date_fin'])) else None,axis=1)\n",
    "d87.df_attr_insert.rename(columns={'absc' : 'abs', 'tmja':'tmja_'+annee,'pc_pl':'pc_pl_'+annee,'obs':'obs_'+annee},inplace=True)\n",
    "d87.df_attr_insert.drop(['date_debut','date_fin','route'],axis=1,inplace=True)\n",
    "\n",
    "#mettre à jour la geom\n",
    "d87.maj_geom('gti_otv_pg11', 'comptage', 'na_2010_2018_p', dep='87')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
