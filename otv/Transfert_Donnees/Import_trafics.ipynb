{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Import des données de comptage***\n",
    "> il y a un exemple de verification si doublons de point dans le 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\martin.schoreisz\\git\\otv\\otv\\Transfert_Donnees')\n",
    "sys.path.append(r'C:\\Users\\martin.schoreisz\\git\\Outils\\Outils\\Martin_Perso')\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import csv, re, os, statistics, filecmp\n",
    "import Connexion_Transfert as ct\n",
    "import Import_trafics as it\n",
    "import Outils\n",
    "from collections import Counter\n",
    "from shapely.geometry import LineString, MultiLineString\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "from Base_BdTopo import Import_outils as io\n",
    "from Base_BdTopo import Rond_points as rp\n",
    "from Base_BdTopo import Regroupement_correspondance as rc\n",
    "from sqlalchemy.schema import MetaData\n",
    "from statistics import mean\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CD 23**\n",
    "- Année 2018 : \n",
    "> à partir du fichier __Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD23\\2018_CD23_trafics.xls__<br>***attention : pour le point de comptage D941 6+152 à Aubusson, le pR est 32 et non 6. il faut donc corriger à la main le fihcier excel***\n",
    "<br> Pour le moment tous les points sont déjà dans  la base, dc pas de traitement de type insert prévus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ouvrir le classeur\n",
    "df_excel=pd.read_excel(r'Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD23\\2018_CD23_trafics.xls',skiprows=11)\n",
    "# renomer les champs\n",
    "df_excel_rennome=df_excel.rename(columns={'1er trimestre  du 01 janvier au 31 mars':'trim1_TV', 'Unnamed: 9':'trim1_pcpl',\n",
    "                         '2ème trimestre du 01 avril au 30 juin':'trim2_TV', 'Unnamed: 11':'trim2_pcpl',\n",
    "                         '3ème trimestre du 01 juillet au 30 septembre':'trim3_TV', 'Unnamed: 13':'trim3_pcpl',\n",
    "                         '4ème trimestre du 01 octobre au 31 décembre':'trim4_TV', 'Unnamed: 15':'trim4_pcpl',\n",
    "                         'Unnamed: 17':'pc_pl', 'TMJA 2018':'tmja'})\n",
    "#supprimer la 1ere ligne\n",
    "df_excel_filtre=df_excel_rennome.loc[1:,:].copy()\n",
    "#mise en forme attribut\n",
    "df_excel_filtre['Route']=df_excel_filtre.apply(lambda x : str(x['Route']).upper(), axis=1)\n",
    "annee_cpt='2018'\n",
    "#attribut id_comptag\n",
    "for i in ['DEP','PR','ABS'] : \n",
    "    df_excel_filtre[i]=df_excel_filtre.apply(lambda x : str(int(x[i])),axis=1)\n",
    "df_excel_filtre['id_comptag']=df_excel_filtre.apply(lambda x : '-'.join([x['DEP'],'D'+str(x['Route']),\n",
    "                                                                         x['PR']+'+'+x['ABS']]),axis=1)\n",
    "#donnees_mensuelles\n",
    "list_id_comptag=[val for val in df_excel_filtre.id_comptag.tolist() for _ in (0, 1)]\n",
    "donnees_type=['tmja','pc_pl']*len(df_excel_filtre.id_comptag.tolist())\n",
    "annee_df=['2018']*2*len(df_excel_filtre.id_comptag.tolist())\n",
    "janv, fev, mars,avril,mai,juin,juil,aout,sept,octo,nov,dec=[],[],[],[],[],[],[],[],[],[],[],[]\n",
    "for i in range(len(df_excel_filtre.id_comptag.tolist())) :\n",
    "    for j in (janv, fev, mars) :\n",
    "        j.extend([df_excel_filtre.trim1_TV.tolist()[i],df_excel_filtre.trim1_pcpl.tolist()[i]])\n",
    "    for k in (avril,mai,juin) :\n",
    "        k.extend([df_excel_filtre.trim2_TV.tolist()[i],df_excel_filtre.trim2_pcpl.tolist()[i]])\n",
    "    for l in (juil,aout,sept) :\n",
    "        l.extend([df_excel_filtre.trim3_TV.tolist()[i],df_excel_filtre.trim3_pcpl.tolist()[i]])\n",
    "    for m in (octo,nov,dec) :\n",
    "        m.extend([df_excel_filtre.trim4_TV.tolist()[i],df_excel_filtre.trim4_pcpl.tolist()[i]])\n",
    "donnees_mens=pd.DataFrame({'id_comptag':list_id_comptag,'donnees_type':donnees_type,'annee':annee_df,'janv':janv,'fevr':fev,'mars':mars,'avri':avril,\n",
    "              'mai':mai,'juin':juin,'juil':juil,'aout':aout,'sept':sept,'octo':octo,'nove':nov,'dece':dec})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-D941-77+25 ok, MaJ\n",
      "23-D941-60+270 ok, MaJ\n",
      "23-D941-57+639 ok, MaJ\n",
      "23-D941-24+257 ok, MaJ\n",
      "23-D914-0+600 ok, MaJ\n",
      "23-D940-39+944 ok, MaJ\n",
      "23-D997-24+86 ok, MaJ\n",
      "23-D915-5+595 ok, MaJ\n",
      "23-D951-8+150 ok, MaJ\n",
      "23-D990-59+690 ok, MaJ\n",
      "23-D942-1+585 ok, MaJ\n",
      "23-D942-23+698 ok, MaJ\n",
      "23-D1-14+725 ok, MaJ\n",
      "23-D1-22+760 ok, MaJ\n",
      "23-D912-15+739 ok, MaJ\n",
      "23-D5-35+590 ok, MaJ\n",
      "23-D913-9+780 ok, MaJ\n",
      "23-D951-28+425 ok, MaJ\n",
      "23-D6-20+56 ok, MaJ\n",
      "23-D6-0+826 ok, MaJ\n",
      "23-D940-50+116 ok, MaJ\n",
      "23-D940-66+431 ok, MaJ\n",
      "23-D990-16+988 ok, MaJ\n",
      "23-D942-31+637 ok, MaJ\n",
      "23-D990-27+817 ok, MaJ\n",
      "23-D990-45+295 ok, MaJ\n",
      "23-D11-6+857 ok, MaJ\n",
      "23-D11-22+776 ok, MaJ\n",
      "23-D917-7+372 ok, MaJ\n",
      "23-D917-12+491 ok, MaJ\n",
      "23-D993-4+638 ok, MaJ\n",
      "23-D915-18+907 ok, MaJ\n",
      "23-D997-35+417 ok, MaJ\n",
      "23-D996-21+935 ok, MaJ\n",
      "23-D4-82+80 ok, MaJ\n",
      "23-D990-65+576 ok, MaJ\n",
      "23-D941A-4+172 ok, MaJ\n",
      "23-D982-1+210 ok, MaJ\n",
      "23-D997-13+862 ok, MaJ\n",
      "23-D982-17+780 ok, MaJ\n",
      "23-D982-36+433 ok, MaJ\n",
      "23-D8-33+506 ok, MaJ\n",
      "23-D912-42+22 ok, MaJ\n",
      "23-D4-19+290 ok, MaJ\n",
      "23-D4-35+917 ok, MaJ\n",
      "23-D940-34+578 ok, MaJ\n",
      "23-D940-20+284 ok, MaJ\n",
      "23-D941-6+152 ok, MaJ\n",
      "23-D912-4+875 ok, MaJ\n",
      "23-D990-34+578 ok, MaJ\n",
      "23-D55-20+284 ok, MaJ\n",
      "23-D941-32+152 ok, MaJ\n",
      "23-D982-4+875 ok, MaJ\n",
      "fini\n"
     ]
    }
   ],
   "source": [
    "#Mise à jour bdd\n",
    "with ct.ConnexionBdd('gti_otv') as c :\n",
    "    c.curs.execute(\"select distinct id_comptag from comptage.na_2010_2018_p where dep='23' order by id_comptag\")\n",
    "    listerecord=[record[0] for record in c.curs]\n",
    "    for id_comptag,tmja, pc_pl  in zip(df_excel_filtre.id_comptag.tolist(), df_excel_filtre.tmja.tolist(),df_excel_filtre.pc_pl.tolist()) : \n",
    "        if id_comptag in listerecord :\n",
    "            c.curs.execute(\"update comptage.na_2010_2018_p set tmja_2018=%s, pc_pl_2018=%s, ann_cpt=%s where id_comptag=%s\",(tmja, pc_pl,annee_cpt,id_comptag))\n",
    "        else : \n",
    "            print (f'{id_comptag} nouveau, à traiter')\n",
    "    print('fini')\n",
    "    c.connexionPsy.commit()\n",
    "    donnees_mens.to_sql('na_2010_2018_mensuel', c.sqlAlchemyConn,schema='comptage',if_exists='append',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CD 40**\n",
    "> Année 2018 : contient des données mensuelless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it.cd40()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CD17**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Année 2015 : traitée dans le fichier Import_trafics.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### année 2016 données issue des borchures de comptage, uniquemnet pour ponctuels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ouverture du fichier\n",
    "cpt17=it.Comptage_cd17(r'Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_produites\\donnnees_travail\\Comptage\\17\\cpt_pctuel_but_2016.txt',\n",
    "                       'brochure',2016)\n",
    "\n",
    "#mettre à jour les id_comptage deja presents (attention, update Bdd à changé, il faut passer par creer_valeur_txt_update avant et certains paramètres ont changé)\n",
    "cpt17.mises_forme_bdd('gti_otv', 'comptage', 'na_2010_2017_p', '17','ponctuel') #creer les attributs selon les donnees presentes dans la base\n",
    "cpt17.update_bdd('gti_otv', 'comptage', 'na_2010_2017_p')#mise à jour\n",
    "\n",
    "#creer referentiel si besoin\n",
    "with ct.ConnexionBdd('gti_otv') as c:\n",
    "    ct.ogr2ogr_shp2pg(c.connstringOgr, r'Y:\\REF_GEO\\BD_Topo\\D17\\ED16\\SHP\\1_DONNEES_LIVRAISON\\N_TRONCON_ROUTE_BDT_017.SHP',\n",
    "                     schema='referentiel',table='troncon_route_bdt17_ed16_l',geotype='MULTILINESTRING', dims=2, encodageClient='LATIN1' )\n",
    "#creer graph\n",
    "rqt=\"\"\"\n",
    "alter table referentiel.troncon_route_bdt17_ed16_l add column source integer , add column target integer ;\n",
    "select pgr_createTopology ('referentiel.troncon_route_bdt17_ed16_l',1,'geom', 'ogc_fid') ;\n",
    "ALTER TABLE referentiel.troncon_route_bdt17_ed16_l  RENAME COLUMN id TO id_ign;\n",
    "ALTER TABLE referentiel.troncon_route_bdt17_ed16_l  RENAME COLUMN ogc_fid TO id;\n",
    "alter table referentiel.troncon_route_bdt17_ed16_l add column long_km numeric ;\n",
    "update referentiel.troncon_route_bdt17_ed16_l set long_km=(st_length(geom)/1000) ;\n",
    "\"\"\" #attention, il manque la ligne au dessus pour créer l'analyseGraph qui va renvoyer le nb de count\n",
    "with ct.ConnexionBdd('gti_otv') as c:\n",
    "    c.sqlAlchemyConn.execute(rqt)\n",
    "\n",
    "#inserer les nouveaux comptages\n",
    "with ct.ConnexionBdd('gti_otv') as c:\n",
    "    cpt17.df_attr_insert.to_sql('na_2010_2017_p',c.sqlAlchemyConn,schema='comptage',if_exists='append', index=False )\n",
    "\n",
    "#mettre à jour la geom \n",
    "rqt=\"\"\" update comptage.na_2010_2017_p\n",
    "  set geom=(select geom_out  from comptage.geoloc_pt_comptag(id_comptag))\n",
    "  where dep='17' and geom is null\n",
    "\"\"\"\n",
    "with ct.ConnexionBdd('gti_otv') as c:\n",
    "    c.sqlAlchemyConn.execute(rqt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### fichier compteurs permanents format csv annee 2017 ou 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "cpt_perm=it.Comptage_cd17(r'Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD17\\2018_csv_permanents_CD17.csv',\n",
    "                         'permanent_csv',2018)\n",
    "\n",
    "cpt_perm.mises_forme_bdd('gti_otv', 'comptage', 'na_2010_2018_p', '17','permanent')\n",
    "\n",
    "#miettre à jour les données deja existantes\n",
    "cpt_perm.update_bdd('gti_otv', 'comptage', 'na_2010_2018_p')#mise à jour\n",
    "\n",
    "#inseérer les données nouvelles\n",
    "cpt_perm.insert_bdd('gti_otv', 'comptage', 'na_2010_2018_p')\n",
    "#mettre à jour la geom \n",
    "cpt_perm.maj_geom('gti_otv', 'comptage', 'na_2010_2018_p', '17')\n",
    "\n",
    "# pour les données mensuelles\n",
    "cpt_perm.insert_bdd_mens('gti_otv', 'comptage','na_2010_2018_mensuel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### annee 2018 ; fichier compteurs tournant format excel issu des donnees pour brochure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#initiliser la classe avec le fichier\n",
    "bdd='gti_otv_pg11'\n",
    "cpt_cd17=it.Comptage_cd17(r'Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD17\\Brochure 2018 CD17 DREAL\\10  5 1 B3 tournants recalculés.xls',\n",
    "                      'tournant_xls_bochure',2018)\n",
    "\n",
    "#mise en forme des données\n",
    "cpt_cd17.comptag_existant_bdd(bdd, 'na_2010_2018_p', dep='17')\n",
    "donnees=cpt_cd17.ouvrir_xls_tournant_brochure()\n",
    "cpt_cd17.conversion_id_comptg_existant_xls_brochure(bdd)\n",
    "cpt_cd17.carac_xls_brochure()\n",
    "\n",
    "#mise à jour des données\n",
    "val_txt=cpt_cd17.creer_valeur_txt_update(cpt_cd17.df_attr_update, ['id_comptag','tmja_2018','tmja_2017'])\n",
    "cpt_cd17.update_bdd(bdd, 'comptage', 'na_2010_2018_p', val_txt,{'tmja_2018':'tmja_2018','tmja_2017':'tmja_2017'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### annee 2017-2018 ; fichier ponctuel excel qui alimente des brochures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#ouvrir le fichier et initialisation\n",
    "cpt_pct2018_cd17=it.Comptage_cd17(r'Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD17\\Brochure 2018 CD17 DREAL\\spécifique Brochure V85_2018 .xls',\n",
    "                      'ponctuel_xls_bochure',2018)\n",
    "bdd='gti_otv_pg11'\n",
    "#mise en forme\n",
    "cpt_pct2018_cd17.comptag_existant_bdd(bdd, 'na_2010_2018_p', dep='17')\n",
    "cpt_pct2018_cd17.conversion_id_comptg_existant_xls_brochure(bdd)\n",
    "cpt_pct2018_cd17.filtrer_periode_ponctuels_xls_brochure()\n",
    "cpt_pct2018_cd17.carac_xls_brochure()\n",
    "\n",
    "#mise à jour des données\n",
    "val_txt=cpt_pct2018_cd17.creer_valeur_txt_update(cpt_pct2018_cd17.df_attr_update, ['id_comptag','tmja','pc_pl','obs'])\n",
    "cpt_pct2018_cd17.update_bdd(bdd, 'comptage', 'na_2010_2018_p', val_txt,{'tmja_2018':'tmja','pc_pl_2018':'pc_pl', 'obs_2018':'obs'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#trouver les points de comptages a inserer situe sur le même troncon elementaires que d'autres points\n",
    "table_corresp=cpt_pct2018_cd17.correspondance_ancien_nouveau_comptage(bdd,'public','cd17_tournant_insert','lineaire.traf2016_bdt17_ed16_l',\n",
    "                                                    'public', 'traf2016_bdt17_ed16_l','traf2016_bdt17_ed16_l_vertices_pgr')\n",
    "\n",
    "#si le point fait partie de la table_corresp, on insère pas, sinon on insère\n",
    "pt_a_inserer=cpt_pct2018_cd17.df_attr_insert.loc[~cpt_pct2018_cd17.df_attr_insert.id_comptag.isin(table_corresp.id_comptag.tolist())].copy()\n",
    "#mise en form avant insertion\n",
    "pt_a_inserer['dep']='17'\n",
    "pt_a_inserer['route']=pt_a_inserer.id_comptag.apply(lambda x : x.split('-')[1])\n",
    "pt_a_inserer.rename(columns={'absc':'abs','tmja':'tmja_2018','pc_pl':'pc_pl_2018','obs':'obs_2018'},inplace=True)\n",
    "pt_a_inserer['reseau']='RD'\n",
    "pt_a_inserer['gestionnai']='CD17'\n",
    "pt_a_inserer['concession']='N'\n",
    "pt_a_inserer['type_poste']='ponctuel'\n",
    "pt_a_inserer=pt_a_inserer[['id_comptag','dep','route','pr','abs','reseau','gestionnai','concession','type_poste','tmja_2018','pc_pl_2018','obs_2018']].copy()\n",
    "#si plusieurs fois le mm point on garde la valeur max\n",
    "pt_a_inserer=pt_a_inserer.loc[pt_a_inserer.tmja_2018==pt_a_inserer.groupby('id_comptag').tmja_2018.transform(max)].copy()\n",
    "\n",
    "cpt_pct2018_cd17.insert_bdd(bdd, 'comptage', 'na_2010_2018_p', pt_a_inserer)\n",
    "cpt_pct2018_cd17.maj_geom(bdd, 'comptage', 'na_2010_2018_p', dep='17')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CD19**\n",
    "> Annee des trafics 2018, fichier : Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD19\\2018_Recensement_trafic.xls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#importer fichier\n",
    "fichier=r'Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD19\\2018_Recensement_trafic.xls'\n",
    "donnees_brutes=pd.read_excel(fichier, skiprows=6)\n",
    "donnees_filtrees=donnees_brutes.rename(columns={'N° R.D.':'route','P.R.':'pr',2018:'ann_2018'})[['route','pr','ann_2018']]\n",
    "donnees_filtrees=donnees_filtrees.loc[~donnees_filtrees.pr.isna()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#mettre à jour les champs et pereparer les donnees\n",
    "def id_comptage(route,pr) : \n",
    "    route=str(route).strip()\n",
    "    pr=str(int(pr.split('+')[0]))+'+0' if int(pr.split('+')[1])==0 else str(int(pr.split('+')[0]))+'+'+str(int(pr.split('+')[1]))\n",
    "    return '19-D'+route+'-'+pr\n",
    "\n",
    "donnees_filtrees['idcomptag']=donnees_filtrees.apply(lambda x : id_comptage(x['route'],x['pr']), axis=1)\n",
    "donnees_filtrees['tmja']=donnees_filtrees.ann_2018.apply(lambda x : 0 if (pd.isna(x) or x=='x') else int(x.split('\\n')[0]))\n",
    "donnees_filtrees['pc_pl']=donnees_filtrees.ann_2018.apply(lambda x : 0 if (pd.isna(x) or x=='x') else float(x.split('\\n')[1].split('%')[0].replace(',','.')))\n",
    "donnees_transfert=donnees_filtrees.loc[donnees_filtrees['tmja']>0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#pour interactions avec Bdd\n",
    "bdd='gti_otv_pg11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#prise en compte variation id_comptag\n",
    "rqt_corresp_comptg='select * from comptage.corresp_id_comptag'\n",
    "with ct.ConnexionBdd(bdd) as c:\n",
    "    corresp_comptg=pd.read_sql(rqt_corresp_comptg, c.sqlAlchemyConn)\n",
    "donnees_transfert['idcomptag']=donnees_transfert.apply(lambda x : corresp_comptg.loc[corresp_comptg['id_gest']==x['idcomptag']].id_gti.values[0] \n",
    "                                            if x['idcomptag'] in corresp_comptg.id_gest.tolist() else x['idcomptag'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Recherche des points existants\n",
    "comptage=it.Comptage(r'Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD19\\2018_Recensement_trafic.xls')\n",
    "cpt_existant=comptage.comptag_existant_bdd('gti_otv_pg11','na_2010_2018_p',dep='19')\n",
    "#identification des nouveaux points\n",
    "points_a_inserer=donnees_transfert.loc[~donnees_transfert['idcomptag'].isin(cpt_existant.id_comptag.tolist())].copy()\n",
    "#identification des points à mettre a jour\n",
    "points_a_mettre_a_jour=donnees_transfert.loc[donnees_transfert['idcomptag'].isin(cpt_existant.id_comptag.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#mettre a jour\n",
    "valeurs_txt=str(tuple([(elem[0],elem[1], elem[2]) for elem in zip(\n",
    "           points_a_mettre_a_jour.idcomptag.tolist(), points_a_mettre_a_jour.tmja.tolist(), \n",
    "            points_a_mettre_a_jour.pc_pl.tolist(), )]))[1:-1]\n",
    "rqt=f\"\"\"update comptage.na_2010_2018_p  as c \n",
    "                set tmja_2018=v.tmja,pc_pl_2018=v.pc_pl from (values {valeurs_txt}) as v(id_comptag,tmja,pc_pl)\n",
    "                where v.id_comptag=c.id_comptag\"\"\"\n",
    "with ct.ConnexionBdd(bdd) as c:\n",
    "    c.sqlAlchemyConn.execute(rqt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#inserer\n",
    "#mise en forme\n",
    "points_a_inserer.rename(columns={'idcomptag':'id_comptag','tmja':'tmja_2018','pc_pl':'pc_pl_2018'}, inplace=True)\n",
    "points_a_inserer.drop(['route','pr','ann_2018'], axis=1, inplace=True)\n",
    "points_a_inserer['type_poste']='tournant'\n",
    "points_a_inserer['dep']='19'\n",
    "points_a_inserer['reseau']='RD'\n",
    "points_a_inserer['gestionnai']='CD19'\n",
    "points_a_inserer['concession']='N'\n",
    "with ct.ConnexionBdd(bdd) as c:\n",
    "    points_a_inserer.to_sql('na_2010_2018_p',c.sqlAlchemyConn,schema='comptage',if_exists='append', index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "comptage.maj_geom(bdd,'comptage','na_2010_2018_p','19')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CD47**\n",
    "> Annee des trafics 2018, fichiers : Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD47\\comptages_CD47_2018\\COMPTAGES 2018\n",
    "les fichiers sont decomposes en permanents tournants temporaires, il faut recomposer les donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#initialiser un objet\n",
    "cpt47=it.Comptage_cd47(r'Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD47\\comptages_CD47_2018\\COMPTAGES 2018','TRAFICS PERMANENTS')\n",
    "#calculer les attributs de comptages : df_attr, df_attr_insert et df_attr_update, en prenant en compte les comptages existants\n",
    "cpt47.classer_comptage_update_insert('gti_otv_pg11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#mise à jour des données déjà présentes dansla base\n",
    "val_txt=cpt47.creer_valeur_txt_update(cpt47.df_attr_update, ['id_comptag','tmja','pc_pl'])\n",
    "cpt47.update_bdd(bdd, 'comptage', 'na_2010_2018_p', val_txt,{'tmja_2018':'tmja','pc_pl_2018':'pc_pl'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#traitement des données non présentes (df_attr_insert)\n",
    "#recherche de correspondance pour les permanents et tournants\n",
    "dico_corresp=cpt47.corresp_old_new_comptag('gti_otv_pg11', 'public','cpt47_temp','lineaire.traf2017_bdt47_ed17_l',\n",
    "                            'referentiel', 'troncon_route_bdt47_ed17_l','troncon_route_bdt47_ed17_l_vertices_pgr','id',ppv_final.id_ign_lin.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#filtre des données df_attr_insert selon l'id_comptag present dans le dico_corresp\n",
    "cpt47.df_attr_insert=cpt47.df_attr_insert.loc[~cpt47.df_attr_insert.id_comptag.isin(df_correspondance.id_comptag.to_list())].copy()\n",
    "# POUR INFO, l'id_comptag présent dan sle dico_corresp a été transférer à la main dans l table comptage.corresp_id_comptag\n",
    "#mettre en forme les attributs avant insert\n",
    "cpt47.mise_en_forme_insert('2018')\n",
    "#inserer les donnes dans la table\n",
    "cpt47.insert_bdd('gti_otv_pg11', 'comptage', 'na_2010_2018_p', cpt47.df_attr_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#mettre à jour la géométrie\n",
    "cpt47.maj_geom('gti_otv_pg11', 'comptage', 'na_2010_2018_p', '47')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CD87**\n",
    "> Dans ce Departement les donnees sont fournies en fichiers .fim. il vaut recalculer les valeusr de comptages <br> Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD87\\Fichiers FIM 87 -2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***lister les voies, classer les types de commptages, lister les fichiers a regrouper***\n",
    "> le dossier contient un tres grand nombre de fihciers, parfois ils sont a regrouper, parfois la structure de nommage varie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK : tous fichiers dans dico\n"
     ]
    }
   ],
   "source": [
    "d87=it.Comptage_cd87(r'Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD87\\Fichiers FIM 87 -2018') \n",
    "d87.dico_pt_cptg() #creer le dico de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d87.dico_voie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pr': 22,\n",
       "  'abs': 250,\n",
       "  'fichiers': ['RD2000PR22(250_1806051122_M4H_WA.FIM',\n",
       "   'RD2000PR22(250_1804061353_M4H_WA (2).FIM',\n",
       "   'RD2000PR22(250_1803051458_M4H_WA.FIM',\n",
       "   'RD2000PR22(250_1810021545_M4H_WA (2).FIM',\n",
       "   'RD2000PR22(250_1809041123_M4H_WA (2).FIM',\n",
       "   'RD2000PR22(250_1807061136_M4H_WA (2).FIM',\n",
       "   'RD2000PR22(250_1812041459_M4H_WA.FIM',\n",
       "   'RD2000PR22(250_1811061054_M4H_WA (2).FIM',\n",
       "   'RD2000PR22(250_1808011055_M4H_WA (2).FIM',\n",
       "   'RD2000PR22(250_1805071515_M4H_WA.FIM']},\n",
       " {'pr': 15,\n",
       "  'abs': 105,\n",
       "  'fichiers': ['RD2000PR15105_1802011049_M4H_WA (2).FIM',\n",
       "   'RD2000PR15105_1803051430_M4H_WA.FIM',\n",
       "   'RD2000PR15105_1806051058_M4H_WA.FIM']}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d87.dico_voie['D2000']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Traiter les donnees***\n",
    "> Pour chaque route référencée dans le dico, on va calculer les TMJA %PL de chaque fichiers muis faire les moyennes si besoin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erreur : (\"'DataFrame' object has no attribute 'VL_sens2'\", 'occurred at index 0') \n",
      " dans fichier : RD2003PR22250_2003_01 (2).fim\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'FIM' object has no attribute 'tmja'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-223-13c0f91e09bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mex\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"erreur : {ex} \\n dans fichier : {f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                 \u001b[0mlist_tmja\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_fim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtmja\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m                 \u001b[0mlist_pc_pl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_fim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpc_pl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tmja'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pc_pl'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_tmja\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_pc_pl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'FIM' object has no attribute 'tmja'"
     ]
    }
   ],
   "source": [
    "for k, v in d87.dico_voie.items() : \n",
    "    for i,e in enumerate(v) : \n",
    "        if len(e['fichiers'])==1 : \n",
    "            obj_fim=it.FIM(os.path.join(d87.dossier,e['fichiers'][0]))\n",
    "            try : \n",
    "                obj_fim.resume_indicateurs()\n",
    "            except obj_fim.fim_PasAssezMesureError : \n",
    "                continue\n",
    "            except Exception as ex : \n",
    "                print(f\"erreur : {ex} \\n dans fichier : {e['fichiers'][0]}\")\n",
    "            e['tmja'], e['pc_pl']=obj_fim.tmja, obj_fim.pc_pl\n",
    "        elif len(e['fichiers'])>1 :\n",
    "            list_tmja=[]\n",
    "            list_pc_pl=[]\n",
    "            for f in e['fichiers'] : \n",
    "                obj_fim=it.FIM(os.path.join(d87.dossier,f))\n",
    "                try : \n",
    "                    obj_fim.resume_indicateurs()\n",
    "                except obj_fim.fim_PasAssezMesureError : \n",
    "                    continue\n",
    "                except Exception as ex : \n",
    "                    print(f\"erreur : {ex} \\n dans fichier : {f}\")\n",
    "                list_tmja.append(obj_fim.tmja)\n",
    "                list_pc_pl.append(obj_fim.pc_pl)\n",
    "            e['tmja'], e['pc_pl']=mean(list_tmja), mean(list_pc_pl)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_fim=it.FIM(os.path.join(r'Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD87\\Fichiers FIM 87 -2018',\n",
    "                           'RD5PR33_1810151625_M1H_WA.FIM'))\n",
    "#RD128PR12(200_1810171523_M3H_WA.FIM\n",
    "#RD5PR33_1810151625_M1H_WA.FIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "lignes=obj_fim.ouvrir_fim()\n",
    "obj_fim.params_fim(lignes)\n",
    "liste_lign_titre=obj_fim.liste_carac_fichiers(lignes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_fim.taille_bloc_donnees(lignes,liste_lign_titre)\n",
    "obj_fim.isoler_bloc(lignes, liste_lign_titre)\n",
    "obj_fim.df_trafic_brut_horaire(liste_lign_titre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_fim.calcul_indicateurs_horaire()\n",
    "obj_fim.calcul_indicateurs_agreges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_fim.sens_uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_fim.pc_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
