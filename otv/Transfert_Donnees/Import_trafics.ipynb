{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style=\"text-align:center;font-size:36px\">***GRAPH DES DONNEES DE COMPTAGES***</h1>\n",
    "> il y a un exemple de verification si doublons de point dans le 17, 47, 87<br>\n",
    "\n",
    "|Gest|Gest|Gest|\n",
    "|-|-|-|\n",
    "|[CD23](#1)|[CD64](#5)|[DIRSO](#9)|\n",
    "|[CD40](#2)|[ASF](#6)|[Anglet](#10)|\n",
    "|[CD17](#3)|[DIRA](#7)||\n",
    "|[Alienor / Atlandes](#4)|[DIRCO](#8)||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\martin.schoreisz\\git\\otv\\otv\\Transfert_Donnees')\n",
    "sys.path.append(r'C:\\Users\\martin.schoreisz\\git\\Outils\\Outils\\Martin_Perso')\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import csv, re, os, statistics, filecmp, unidecode\n",
    "import datetime as dt\n",
    "from math import sqrt, pi, exp, log, log10\n",
    "import Connexion_Transfert as ct\n",
    "import Import_trafics as it\n",
    "from Donnees_horaires import comparer2Sens,verifValiditeFichier,concatIndicateurFichierHoraire,SensAssymetriqueError,verifNbJoursValidDispo, tmjaDepuisHoraire, periodeDepuisHoraire, attributsHoraire\n",
    "from Donnees_sources import MHCorbin, NettoyageTemps, GroupeCompletude, NombreDeJours\n",
    "from Params.DonneesSourcesParams import MHcorbinMaxLength, MHcorbinMaxSpeed, MHCorbinValue0, MHCorbinFailAdviceCode\n",
    "import Outils as O\n",
    "from collections import Counter\n",
    "from shapely.geometry import Point,LineString, MultiLineString\n",
    "from shapely import speedups\n",
    "speedups.disable()\n",
    "from shapely.ops import transform\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "#from Base_BdTopo import Import_outils as io\n",
    "#from Base_BdTopo import Rond_points as rp#from Base_BdTopo import Regroupement_correspondance as rc\n",
    "from sqlalchemy.schema import MetaData\n",
    "from sqlalchemy import inspect\n",
    "from statistics import mean\n",
    "from itertools import combinations\n",
    "from unidecode import unidecode\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import pyproj\n",
    "from shapely.ops import transform\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_colwidth', 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\" ></a>\n",
    "# ***CD 23***\n",
    "- Année 2019 : \n",
    "> ***attention : pour le point de comptage D941 6+152 à Aubusson, le pR est 32 et non 6. il faut donc corriger à la main le fihcier excel***\n",
    "<br> Pour le moment tous les points sont déjà dans  la base, dc pas de traitement de type insert prévus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiliser les données\n",
    "cd23=it.Comptage_cd23(r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\CD23\\2019-CD23_trafics.xls',2019)\n",
    "df_propre=cd23.ouvrirMiseEnForme()\n",
    "cd23.classer_comptage_update_insert('gti_otv_pg11', 'na_2010_2019_p')\n",
    "cd23.update_bdd_23('gti_otv_pg11','comptage', 'na_2010_2019_p')\n",
    "cd23.donneesMens()\n",
    "cd23.insert_bdd('gti_otv_pg11','comptage', 'na_2010_2019_mensuel',cd23.df_attr_mensuel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\" ></a>\n",
    "# ***CD 40***\n",
    "> 2019 : envoi des données B152 de route +   \n",
    "2020 : envoi des données B153 de route +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019 : initialiser\n",
    "cd40=it.Comptage_cd40(r'D:\\temp\\otv\\2019\\Donnees_source\\CD40\\Observatoire des trafics')\n",
    "#mettre enf orme\n",
    "cd40.comptage_forme()\n",
    "cd40.classer_comptage_insert_update('local_otv_station_gti', 'na_2010_2019_p', 'comptage')\n",
    "#transfert donnees_agregees\n",
    "cd40.update_bdd_40('local_otv_station_gti', 'comptage', 'na_2010_2019_p')\n",
    "#donnees_mensuelles\n",
    "#cd40.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_mensuel',cd40.df_attr_mens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2020 : preparer\n",
    "cd40=it.Comptage_cd40(r'C:\\Users\\martin.schoreisz\\Box\\Dossier_Perso\\OTV\\donnees_gestionnaires\\CD40\\en_cours\\donnees', donneesType='B153', annee='2020')\n",
    "cd40.comptage_forme()\n",
    "cd40.classer_comptage_insert_update('local_otv_boulot', 'compteur', 'comptage')\n",
    "#cd40.df_attr_update,cd40.df_attr_insert, cd40.df_attr_mens\n",
    "\n",
    "#mettre a jour \n",
    "#comptages\n",
    "dfComptage=cd40.creer_comptage(cd40.df_attr_update.id_comptag.tolist(), cd40.annee, 'tableur CD40', 'tv/pl', obs='fichier B153 route +')\n",
    "cd40.insert_bdd('local_otv_boulot', 'comptage', 'comptage', dfComptage)\n",
    "#indics_agreges\n",
    "dfIndicAgrege=cd40.structureBddOld2NewForm(cd40.df_attr_update, cd40.annee,['id_comptag', 'annee', 'fichier'],['tmja', 'pc_pl', 'tmje', 'tmjhe'], 'agrege')\n",
    "cd40.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege', dfIndicAgrege)\n",
    "#trafic mensuel\n",
    "dfIndicMensuel=cd40.structureBddOld2NewForm(cd40.df_attr_mens, cd40.annee,['id_comptag', 'annee', 'fichier', 'donnees_type'],['janv', 'fevr', 'mars', 'avri', 'mai', 'juin', 'juil', 'aout', 'sept',\n",
    "       'octo', 'nove', 'dece'], 'mensuel')\n",
    "cd40.insert_bdd('local_otv_boulot', 'comptage', 'indic_mensuel', dfIndicMensuel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\" ></a>\n",
    "# ***CD17***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Année 2015 : traitée dans le fichier Import_trafics.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### année 2016 données issue des borchures de comptage, uniquemnet pour ponctuels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ouverture du fichier\n",
    "cpt17=it.Comptage_cd17(r'Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_produites\\donnnees_travail\\Comptage\\17\\cpt_pctuel_but_2016.txt',\n",
    "                       'brochure',2016)\n",
    "\n",
    "#mettre à jour les id_comptage deja presents (attention, update Bdd à changé, il faut passer par creer_valeur_txt_update avant et certains paramètres ont changé)\n",
    "cpt17.mises_forme_bdd('gti_otv', 'comptage', 'na_2010_2017_p', '17','ponctuel') #creer les attributs selon les donnees presentes dans la base\n",
    "cpt17.update_bdd('gti_otv', 'comptage', 'na_2010_2017_p')#mise à jour\n",
    "\n",
    "#creer referentiel si besoin\n",
    "with ct.ConnexionBdd('gti_otv') as c:\n",
    "    ct.ogr2ogr_shp2pg(c.connstringOgr, r'Y:\\REF_GEO\\BD_Topo\\D17\\ED16\\SHP\\1_DONNEES_LIVRAISON\\N_TRONCON_ROUTE_BDT_017.SHP',\n",
    "                     schema='referentiel',table='troncon_route_bdt17_ed16_l',geotype='MULTILINESTRING', dims=2, encodageClient='LATIN1' )\n",
    "#creer graph\n",
    "rqt=\"\"\"\n",
    "alter table referentiel.troncon_route_bdt17_ed16_l add column source integer , add column target integer ;\n",
    "select pgr_createTopology ('referentiel.troncon_route_bdt17_ed16_l',1,'geom', 'ogc_fid') ;\n",
    "ALTER TABLE referentiel.troncon_route_bdt17_ed16_l  RENAME COLUMN id TO id_ign;\n",
    "ALTER TABLE referentiel.troncon_route_bdt17_ed16_l  RENAME COLUMN ogc_fid TO id;\n",
    "alter table referentiel.troncon_route_bdt17_ed16_l add column long_km numeric ;\n",
    "update referentiel.troncon_route_bdt17_ed16_l set long_km=(st_length(geom)/1000) ;\n",
    "\"\"\" #attention, il manque la ligne au dessus pour créer l'analyseGraph qui va renvoyer le nb de count\n",
    "with ct.ConnexionBdd('gti_otv') as c:\n",
    "    c.sqlAlchemyConn.execute(rqt)\n",
    "\n",
    "#inserer les nouveaux comptages\n",
    "with ct.ConnexionBdd('gti_otv') as c:\n",
    "    cpt17.df_attr_insert.to_sql('na_2010_2017_p',c.sqlAlchemyConn,schema='comptage',if_exists='append', index=False )\n",
    "\n",
    "#mettre à jour la geom \n",
    "rqt=\"\"\" update comptage.na_2010_2017_p\n",
    "  set geom=(select geom_out  from comptage.geoloc_pt_comptag(id_comptag))\n",
    "  where dep='17' and geom is null\n",
    "\"\"\"\n",
    "with ct.ConnexionBdd('gti_otv') as c:\n",
    "    c.sqlAlchemyConn.execute(rqt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### fichier compteurs permanents format csv annee 2017, 2018, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_perm=it.Comptage_cd17(r'D:\\Boulot\\AffairesEnCours\\OTV\\17\\csv perso pactol_2019_1.csv',\n",
    "                         'permanent_csv',2019)\n",
    "cpt_perm.mises_forme_bdd_brochure_pdf('local_otv_gti', 'comptage', 'na_2010_2019_p', '17','permanent', 'maison')\n",
    "#miettre à jour les données deja existantes\n",
    "cpt_perm.update_bdd_17('local_otv_gti', 'comptage', 'na_2010_2019_p')#mise à jour\n",
    "#inseérer les données nouvelles\n",
    "cpt_perm.insert_bdd('gti_otv', 'comptage', 'na_2010_2019_p')\n",
    "#mettre à jour la geom \n",
    "cpt_perm.maj_geom('gti_otv', 'comptage', 'na_2010_2019_p', '17')\n",
    "# pour les données mensuelles\n",
    "cpt_perm.insert_bdd_mens('local_otv_gti', 'comptage','na_2010_2019_mensuel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### annee 2018 ; fichier compteurs tournant format excel issu des donnees pour brochure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiliser la classe avec le fichier\n",
    "bdd='gti_otv_pg11'\n",
    "cpt_cd17=it.Comptage_cd17(r'Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD17\\Brochure 2018 CD17 DREAL\\10  5 1 B3 tournants recalculés.xls',\n",
    "                      'tournant_xls_bochure',2018)\n",
    "\n",
    "#mise en forme des données\n",
    "cpt_cd17.comptag_existant_bdd(bdd, 'na_2010_2018_p', dep='17')\n",
    "donnees=cpt_cd17.ouvrir_xls_tournant_brochure()\n",
    "cpt_cd17.conversion_id_comptg_existant_xls_brochure(bdd)\n",
    "cpt_cd17.carac_xls_brochure()\n",
    "\n",
    "#mise à jour des données\n",
    "val_txt=cpt_cd17.creer_valeur_txt_update(cpt_cd17.df_attr_update, ['id_comptag','tmja_2018','tmja_2017'])\n",
    "cpt_cd17.update_bdd(bdd, 'comptage', 'na_2010_2018_p', val_txt,{'tmja_2018':'tmja_2018','tmja_2017':'tmja_2017'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### annee 2017-2018 ; fichier ponctuel excel qui alimente des brochures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ouvrir le fichier et initialisation\n",
    "cpt_pct2018_cd17=it.Comptage_cd17(r'Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD17\\Brochure 2018 CD17 DREAL\\spécifique Brochure V85_2018 .xls',\n",
    "                      'ponctuel_xls_bochure',2018)\n",
    "bdd='gti_otv_pg11'\n",
    "#mise en forme\n",
    "cpt_pct2018_cd17.comptag_existant_bdd(bdd, 'na_2010_2018_p', dep='17')\n",
    "cpt_pct2018_cd17.conversion_id_comptg_existant_xls_brochure(bdd)\n",
    "cpt_pct2018_cd17.filtrer_periode_ponctuels_xls_brochure()\n",
    "cpt_pct2018_cd17.carac_xls_brochure()\n",
    "\n",
    "#mise à jour des données\n",
    "val_txt=cpt_pct2018_cd17.creer_valeur_txt_update(cpt_pct2018_cd17.df_attr_update, ['id_comptag','tmja','pc_pl','obs'])\n",
    "cpt_pct2018_cd17.update_bdd(bdd, 'comptage', 'na_2010_2018_p', val_txt,{'tmja_2018':'tmja','pc_pl_2018':'pc_pl', 'obs_2018':'obs'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trouver les points de comptages a inserer situe sur le même troncon elementaires que d'autres points\n",
    "table_corresp=cpt_pct2018_cd17.correspondance_ancien_nouveau_comptage(bdd,'public','cd17_tournant_insert','lineaire.traf2016_bdt17_ed16_l',\n",
    "                                                    'public', 'traf2016_bdt17_ed16_l','traf2016_bdt17_ed16_l_vertices_pgr')\n",
    "\n",
    "#si le point fait partie de la table_corresp, on insère pas, sinon on insère\n",
    "pt_a_inserer=cpt_pct2018_cd17.df_attr_insert.loc[~cpt_pct2018_cd17.df_attr_insert.id_comptag.isin(table_corresp.id_comptag.tolist())].copy()\n",
    "#mise en form avant insertion\n",
    "pt_a_inserer['dep']='17'\n",
    "pt_a_inserer['route']=pt_a_inserer.id_comptag.apply(lambda x : x.split('-')[1])\n",
    "pt_a_inserer.rename(columns={'absc':'abs','tmja':'tmja_2018','pc_pl':'pc_pl_2018','obs':'obs_2018'},inplace=True)\n",
    "pt_a_inserer['reseau']='RD'\n",
    "pt_a_inserer['gestionnai']='CD17'\n",
    "pt_a_inserer['concession']='N'\n",
    "pt_a_inserer['type_poste']='ponctuel'\n",
    "pt_a_inserer=pt_a_inserer[['id_comptag','dep','route','pr','abs','reseau','gestionnai','concession','type_poste','tmja_2018','pc_pl_2018','obs_2018']].copy()\n",
    "#si plusieurs fois le mm point on garde la valeur max\n",
    "pt_a_inserer=pt_a_inserer.loc[pt_a_inserer.tmja_2018==pt_a_inserer.groupby('id_comptag').tmja_2018.transform(max)].copy()\n",
    "\n",
    "cpt_pct2018_cd17.insert_bdd(bdd, 'comptage', 'na_2010_2018_p', pt_a_inserer)\n",
    "cpt_pct2018_cd17.maj_geom(bdd, 'comptage', 'na_2010_2018_p', dep='17')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***CD19***\n",
    "> 2019 : creation de la classe Comptage_cd19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\" ></a>\n",
    "# ***CD64***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init\n",
    "fichier=r'C:\\Users\\martin.schoreisz\\Box\\Dossier_Perso\\OTV\\donnees_gestionnaires\\CD64\\en_cours\\Copie de SIG TV PL %PL TOURNANTS + PERMANENTS 2020.xlsx'\n",
    "cd64=it.Comptage_cd64(fichier, '2020')\n",
    "cd64.miseEnForme()\n",
    "cd64.classer_comptage_insert_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verfier les correspondances\n",
    "#verifieles geometries a insrere\n",
    "#calcul auto des geometries et verif Qgis\n",
    "gdfInsert=cd64.localiser_comptage_a_inserer(cd64.df_attr_insert, 'local_otv_boulot', 'public', 'localiser_pt_cd64', \n",
    "                                            'ref.troncon_route_bdt_na_ed20_l', 'ref.pr_ed18_p')\n",
    "#gdfInsert.to_file(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\verif_pt_cd64.shp')\n",
    "#reprendre le fichier corrige via Qgis\n",
    "gdfInsertCorrigee=gp.read_file(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\verif_pt_cd64.shp')\n",
    "dicoCoresp={'64-D10-3+0':'64-D10-3+400','64-D4-25+0':'64-D4-25+500', '64-D+6-8+130':'64-D55-2+535', '64-D6-2+335':'64-D6-0+250'}\n",
    "cd64.verifComptageInsert(dicoCoresp,gdfInsertCorrigee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#mise à jour des données déjà présentes : \n",
    "#mise a jour de obs_supl\n",
    "cd64.update_bdd('comptage', 'compteur', cd64.creer_valeur_txt_update(cd64.df_attr_update, ['id_comptag', 'obs_supl']), {'obs_supl':'obs_supl'})\n",
    "#insere les nouveaux comptages, mettre à jour les anciens\n",
    "#séparer les comptages deja existants et les nouveaux\n",
    "bdd='local_otv_boulot'\n",
    "with ct.ConnexionBdd(bdd) as c  :\n",
    "    comptagesExistant=pd.read_sql('select ca.* from comptage.comptage ca join comptage.compteur ce on ca.id_comptag=ce.id_comptag where ce.dep=\\'64\\'', c.sqlAlchemyConn)\n",
    "dfJointureBddCd64=cd64.df_attr_update.assign(annee=cd64.df_attr_update.annee.astype(str)).merge(comptagesExistant[['id','id_comptag', 'annee']], how='left', on=['id_comptag', 'annee'])\n",
    "dfComptagesExistants=dfJointureBddCd64.loc[~dfJointureBddCd64.id.isna()]\n",
    "dfComptagesNew=dfJointureBddCd64.loc[dfJointureBddCd64.id.isna()]\n",
    "#mise à jour des existants\n",
    "#comptage\n",
    "cd64.update_bdd('comptage', 'comptage', cd64.creer_valeur_txt_update(dfComptagesExistants[['id']].assign(src='tableur CD64'), ['id', 'src']),\n",
    "                {'src':'src'}, identifiant='id')\n",
    "#tmja\n",
    "cd64.update_bdd('comptage', 'indic_agrege', cd64.creer_valeur_txt_update(dfComptagesExistants.assign(id_comptag_uniq=dfComptagesExistants.id)\n",
    "                                                                         , ['id_comptag_uniq', 'tmja']), {'valeur':'tmja'}, identifiant='id_comptag_uniq',\n",
    "                filtre = \"indicateur='tmja'\")\n",
    "#pc_pl\n",
    "cd64.update_bdd('comptage', 'indic_agrege', cd64.creer_valeur_txt_update(dfComptagesExistants.assign(id_comptag_uniq=dfComptagesExistants.id)\n",
    "                                                                         , ['id_comptag_uniq', 'pc_pl']), {'valeur':'pc_pl'}, identifiant='id_comptag_uniq',\n",
    "                filtre = \"indicateur='pc_pl'\")\n",
    "\n",
    "#insertion des nouveaux\n",
    "for a in dfComptagesNew.annee.unique() : \n",
    "    dfComptage=cd64.creer_comptage(dfComptagesNew.loc[dfComptagesNew.annee==a].id_comptag.tolist(), a, 'tableur CD64','tv/pl')\n",
    "    cd64.insert_bdd('local_otv_boulot', 'comptage', 'comptage', dfComptage)\n",
    "    dfIndicAgrege=cd64.structureBddOld2NewForm(dfComptagesNew.loc[dfComptagesNew.annee==a], a,\n",
    "                                               ['id_comptag', 'annee', 'fichier'],['tmja', 'pc_pl'], 'agrege')\n",
    "    cd64.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege', dfIndicAgrege)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***CD47***\n",
    "> Annee des trafics 2018, fichiers : Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD47\\comptages_CD47_2018\\COMPTAGES 2018\n",
    "les fichiers sont decomposes en permanents tournants temporaires, il faut recomposer les donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialiser un objet\n",
    "cpt47=it.Comptage_cd47(r'Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD47\\comptages_CD47_2018\\COMPTAGES 2018','TRAFICS PERMANENTS')\n",
    "#calculer les attributs de comptages : df_attr, df_attr_insert et df_attr_update, en prenant en compte les comptages existants\n",
    "cpt47.classer_comptage_update_insert('gti_otv_pg11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mise à jour des données déjà présentes dansla base\n",
    "val_txt=cpt47.creer_valeur_txt_update(cpt47.df_attr_update, ['id_comptag','tmja','pc_pl'])\n",
    "cpt47.update_bdd(bdd, 'comptage', 'na_2010_2018_p', val_txt,{'tmja_2018':'tmja','pc_pl_2018':'pc_pl'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traitement des données non présentes (df_attr_insert)\n",
    "#recherche de correspondance pour les permanents et tournants\n",
    "dico_corresp=cpt47.corresp_old_new_comptag('gti_otv_pg11', 'public','cpt47_temp','lineaire.traf2017_bdt47_ed17_l',\n",
    "                            'referentiel', 'troncon_route_bdt47_ed17_l','troncon_route_bdt47_ed17_l_vertices_pgr','id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtre des données df_attr_insert selon l'id_comptag present dans le dico_corresp\n",
    "cpt47.df_attr_insert=cpt47.df_attr_insert.loc[~cpt47.df_attr_insert.id_comptag.isin(df_correspondance.id_comptag.to_list())].copy()\n",
    "# POUR INFO, l'id_comptag présent dan sle dico_corresp a été transférer à la main dans l table comptage.corresp_id_comptag\n",
    "#mettre en forme les attributs avant insert\n",
    "cpt47.mise_en_forme_insert('2018')\n",
    "#inserer les donnes dans la table\n",
    "cpt47.insert_bdd('gti_otv_pg11', 'comptage', 'na_2010_2018_p', cpt47.df_attr_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mettre à jour la géométrie\n",
    "cpt47.maj_geom('gti_otv_pg11', 'comptage', 'na_2010_2018_p', '47')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **2019**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt47=it.Comptage_cd47(r'D:\\temp\\otv\\2019\\Donnees_source\\CD47','TRAFICS PERIODIQUES',2019)\n",
    "#calculer les attributs de comptages : df_attr, df_attr_insert et df_attr_update, en prenant en compte les comptages existants, mais ans recherche des équivalences avec les anciens comptage snon recensées\n",
    "cpt47.classer_comptage_update_insert('local_otv_station_gti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qq points tournants non connus\n",
    "cpt47.df_attr_insert.loc[cpt47.df_attr_insert['type_poste'].isin(['permanent','tournant'])]\n",
    "#filtrer les 2 points bizarres\n",
    "cpt47.df_attr=cpt47.df_attr.loc[cpt47.df_attr.id_comptag.apply(lambda x : x[:4]=='47-D')].copy()\n",
    "cpt47.df_attr_insert=cpt47.df_attr_insert.loc[cpt47.df_attr_insert.id_comptag.apply(lambda x : x[:4]=='47-D')].copy()\n",
    "cpt47.df_attr_update=cpt47.df_attr_update.loc[cpt47.df_attr_update.id_comptag.apply(lambda x : x[:4]=='47-D')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtention dico de correspondance\n",
    "dico_corresp=cpt47.corresp_old_new_comptag('local_otv_station_gti', 'public','cpt47_temp','referentiel.troncon_route_bdt47_ed17_l',\n",
    "                            'referentiel', 'troncon_route_bdt47_ed17_l','troncon_route_bdt47_ed17_l_vertices_pgr','id')\n",
    "#insertion dans bdd\n",
    "cpt47.insert_bdd('local_otv_station_gti','comptage','corresp_id_comptag',dico_corresp[['id_comptag','id_comptag_lin']].rename(columns={'id_comptag':'id_gest','id_comptag_lin':'id_gti'}))\n",
    "#calcul nouveau id_comptag\n",
    "cpt47.comptag_existant_bdd('local_otv_station_gti',schema='comptage', table='na_2010_2019_p',dep='47', type_poste=False)\n",
    "cpt47.corresp_nom_id_comptag('local_otv_station_gti',cpt47.df_attr)\n",
    "cpt47.df_attr_update=cpt47.df_attr.loc[cpt47.df_attr.id_comptag.isin(cpt47.existant.id_comptag.tolist())].copy()\n",
    "cpt47.df_attr_insert=cpt47.df_attr.loc[~cpt47.df_attr.id_comptag.isin(cpt47.existant.id_comptag.tolist())].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mise a jour\n",
    "cpt47.update_bdd_47('local_otv_station_gti','comptage', 'na_2010_2019_p',cpt47.df_attr_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#donnees a inserer\n",
    "cpt47.mise_en_forme_insert()\n",
    "cpt47.insert_bdd('local_otv_station_gti','comptage', 'na_2010_2019_p', cpt47.df_attr_insert)\n",
    "cpt47.maj_geom('local_otv_station_gti','comptage', 'na_2010_2019_p', '47')\n",
    "cpt47.insert_bdd('local_otv_station_gti','comptage', 'na_2010_2019_mensuel', cpt47.df_attr_mens)\n",
    "cpt47.insert_bdd('local_otv_station_gti','comptage', 'na_2010_2019_horaire', cpt47.df_attr_horaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***CD87***\n",
    "> Dans ce Departement les donnees sont fournies en fichiers .fim. il vaut recalculer les valeusr de comptages <br> Q:\\DAIT\\TI\\DREAL33\\2019\\C19SA0035_OTR-NA\\Doc_travail\\Donnees_source\\CD87\\Fichiers FIM 87 -2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***lister les voies, classer les types de commptages, lister les fichiers a regrouper***\n",
    "> le dossier contient un tres grand nombre de fihciers, parfois ils sont a regrouper, parfois la structure de nommage varie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d87=it.Comptage_cd87(r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\CD87\\CD87- Comptages 2019 Fichiers .fim','2019') \n",
    "d87.dico_pt_cptg() #creer le dico de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d87.dico_voie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Traiter les donnees***\n",
    "> Pour chaque route référencée dans le dico, on va calculer les TMJA %PL, date_debut, date_fin, type_poste de chaque fichiers puis\n",
    "faire les calculs si necessaires (moyenne si plsr fichiers).<br> ensuite on classe puis update et insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mettre à jour le dico et le transformer en dataframe sans les ponctuels pendant les grandes vacances\n",
    "d87.dataframe_dico_glob()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparer les données\n",
    "#attention cela comprend un script d'identification des points pas forcément nécéssaire\n",
    "d87.classer_comptage_update_insert('gti_otv_pg11','na_2010_2019_p','comptage',\n",
    "                                   'public','d87_cpt_temp','lineaire.traf2018_bdt87_ed18_l',\n",
    "                                  'ref', 'troncon_route_bdt87_ed18_l','troncon_route_bdt87_ed18_l_vertices_pgr','id','ref.pr_ed18_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mettre à jour les données\n",
    "d87.update_bdd_d87('gti_otv_pg11','na_2010_2019_p','comptage')\n",
    "#insérer les données et mettre à jour les geom\n",
    "d87.insert_bdd_d87('gti_otv_pg11','na_2010_2019_p','comptage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "Outils.CopierFichierDepuisArborescence(r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\CD87\\Permanents 2019\\2019',\n",
    "                                      r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\CD87\\Permanents 2019\\tousFichiersVrac',\n",
    "                                      '.fim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK : tous fichiers dans dico\n"
     ]
    }
   ],
   "source": [
    "d87=it.Comptage_cd87(r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\CD87\\Permanents 2019\\tousFichiersVrac','2019') \n",
    "d87.dico_pt_cptg() #creer le dico de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route</th>\n",
       "      <th>pr</th>\n",
       "      <th>absc</th>\n",
       "      <th>tmja</th>\n",
       "      <th>pc_pl</th>\n",
       "      <th>type_poste</th>\n",
       "      <th>date_debut</th>\n",
       "      <th>date_fin</th>\n",
       "      <th>id_comptag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D2000</td>\n",
       "      <td>15</td>\n",
       "      <td>105</td>\n",
       "      <td>9178</td>\n",
       "      <td>8.25</td>\n",
       "      <td>permanent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87-D2000-15+105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D2000</td>\n",
       "      <td>22</td>\n",
       "      <td>250</td>\n",
       "      <td>5182</td>\n",
       "      <td>10.53</td>\n",
       "      <td>permanent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87-D2000-22+250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D29</td>\n",
       "      <td>4</td>\n",
       "      <td>830</td>\n",
       "      <td>8372</td>\n",
       "      <td>2.89</td>\n",
       "      <td>permanent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87-D29-4+830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D675</td>\n",
       "      <td>26</td>\n",
       "      <td>970</td>\n",
       "      <td>2942</td>\n",
       "      <td>7.37</td>\n",
       "      <td>permanent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87-D675-26+970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D675</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2025</td>\n",
       "      <td>6.76</td>\n",
       "      <td>permanent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87-D675-31+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D675</td>\n",
       "      <td>53</td>\n",
       "      <td>890</td>\n",
       "      <td>2786</td>\n",
       "      <td>4.02</td>\n",
       "      <td>permanent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87-D675-53+890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D675</td>\n",
       "      <td>58</td>\n",
       "      <td>680</td>\n",
       "      <td>10367</td>\n",
       "      <td>4.08</td>\n",
       "      <td>permanent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87-D675-58+680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D699</td>\n",
       "      <td>2</td>\n",
       "      <td>255</td>\n",
       "      <td>1941</td>\n",
       "      <td>4.93</td>\n",
       "      <td>permanent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87-D699-2+255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>D704</td>\n",
       "      <td>1</td>\n",
       "      <td>495</td>\n",
       "      <td>6386</td>\n",
       "      <td>5.61</td>\n",
       "      <td>permanent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87-D704-1+495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>D704</td>\n",
       "      <td>19</td>\n",
       "      <td>720</td>\n",
       "      <td>4648</td>\n",
       "      <td>4.82</td>\n",
       "      <td>permanent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87-D704-19+720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>D901</td>\n",
       "      <td>18</td>\n",
       "      <td>500</td>\n",
       "      <td>1643</td>\n",
       "      <td>8.96</td>\n",
       "      <td>permanent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87-D901-18+500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>D942</td>\n",
       "      <td>23</td>\n",
       "      <td>200</td>\n",
       "      <td>3591</td>\n",
       "      <td>4.87</td>\n",
       "      <td>permanent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87-D942-23+200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>D942</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>3000</td>\n",
       "      <td>7.02</td>\n",
       "      <td>permanent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87-D942-39+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D947</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>11744</td>\n",
       "      <td>2.27</td>\n",
       "      <td>permanent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87-D947-3+150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>D951</td>\n",
       "      <td>55</td>\n",
       "      <td>680</td>\n",
       "      <td>5323</td>\n",
       "      <td>38.88</td>\n",
       "      <td>permanent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87-D951-55+680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D979</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>15082</td>\n",
       "      <td>3.45</td>\n",
       "      <td>permanent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87-D979-3+130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    route  pr  absc   tmja  pc_pl type_poste  date_debut  date_fin  \\\n",
       "4   D2000  15   105   9178   8.25  permanent         NaN       NaN   \n",
       "3   D2000  22   250   5182  10.53  permanent         NaN       NaN   \n",
       "5     D29   4   830   8372   2.89  permanent         NaN       NaN   \n",
       "6    D675  26   970   2942   7.37  permanent         NaN       NaN   \n",
       "8    D675  31     0   2025   6.76  permanent         NaN       NaN   \n",
       "7    D675  53   890   2786   4.02  permanent         NaN       NaN   \n",
       "9    D675  58   680  10367   4.08  permanent         NaN       NaN   \n",
       "1    D699   2   255   1941   4.93  permanent         NaN       NaN   \n",
       "13   D704   1   495   6386   5.61  permanent         NaN       NaN   \n",
       "14   D704  19   720   4648   4.82  permanent         NaN       NaN   \n",
       "12   D901  18   500   1643   8.96  permanent         NaN       NaN   \n",
       "10   D942  23   200   3591   4.87  permanent         NaN       NaN   \n",
       "11   D942  39     0   3000   7.02  permanent         NaN       NaN   \n",
       "0    D947   3   150  11744   2.27  permanent         NaN       NaN   \n",
       "15   D951  55   680   5323  38.88  permanent         NaN       NaN   \n",
       "2    D979   3   130  15082   3.45  permanent         NaN       NaN   \n",
       "\n",
       "         id_comptag  \n",
       "4   87-D2000-15+105  \n",
       "3   87-D2000-22+250  \n",
       "5      87-D29-4+830  \n",
       "6    87-D675-26+970  \n",
       "8      87-D675-31+0  \n",
       "7    87-D675-53+890  \n",
       "9    87-D675-58+680  \n",
       "1     87-D699-2+255  \n",
       "13    87-D704-1+495  \n",
       "14   87-D704-19+720  \n",
       "12   87-D901-18+500  \n",
       "10   87-D942-23+200  \n",
       "11     87-D942-39+0  \n",
       "0     87-D947-3+150  \n",
       "15   87-D951-55+680  \n",
       "2     87-D979-3+130  "
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d87.df_attr.sort_values('id_comptag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***CD 16***\n",
    "- Année 2018 : \n",
    "> à partir du fichier D:\\temp\\otv\\Donnees_source\\CD16\\B15_2018.xlsx on traite les permanents.<br> à partir des donnees sur PIGMA on traite les compteurs temporaires <br>***attention : il y a aussi des données de comptages temporaires en FIM qui permettront d'obtenir de la données horaires***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2018\n",
    "cd16=it.Comptage_cd16(r'D:\\temp\\otv\\Donnees_source\\CD16\\B15_2018.xlsx',r'D:\\temp\\otv\\Donnees_source\\CD16\\pigma\\comptages_routiers_2019\\comptages_routiers.shp',\n",
    "                      r'D:\\temp\\otv\\Donnees_source\\CD16\\pigma\\position_compteurs_2019\\position_compteurs.shp',2018)\n",
    "cd16.comptage_forme()\n",
    "cd16.classer_comptage_update_insert('local_otv', 'na_2010_2018_p')\n",
    "\n",
    "cd16.classer_comptage_update_insert('local_otv', 'na_2010_2018_p')\n",
    "\n",
    "cd16.update_bdd_16('local_otv','comptage','na_2010_2018_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2019\n",
    "cd16=it.Comptage_cd16(r'D:\\temp\\otv\\2019\\Donnees_source\\CD16\\B15_2019.xlsx',r'D:\\temp\\otv\\2019\\Donnees_source\\CD16\\SIG_Comptages_CD16\\Comptages_routiers.shp',\n",
    "                      r'D:\\temp\\otv\\2019\\Donnees_source\\CD16\\SIG_Comptages_CD16\\Position_compteurs.shp',2019)\n",
    "cpt_a_ignorer=('16-D731-27+45','16-D910-23+821', '16-D1000-16+35')\n",
    "cd16.comptage_forme(7,('16-D731-27+45','16-D910-23+821', '16-D1000-16+35'),r'D:\\temp\\otv\\2019\\Donnees_source\\CD16\\Comptages_secondaires_CD16_2019')\n",
    "cd16.classer_comptage_update_insert('local_otv_station_gti', 'na_2010_2019_p')\n",
    "#cd16.update_bdd_16('local_otv_station_gti','comptage', 'na_2010_2019_p')\n",
    "#cd16.insert_bdd('local_otv_station_gti','comptage','na_2010_2019_mensuel',cd16.df_attr_mens)\n",
    "#cd16.insert_bdd('local_otv_station_gti','comptage','na_2010_2019_horaire',cd16.df_attr_horaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***CD 86***\n",
    "Attention , dans ce département parfois ce sont les données en PLOD et ASCD qui sont ok, parfois c'est le cumulD <br>\n",
    "Dans ce Dept, les Compmtages dites 'Secondaires' sont équivalent à 'tournants', et 'Tournants' equivalent à 'ponctuel'\n",
    "- Année 2018 : \n",
    "> à partir des fichier D:\\temp\\otv\\Donnees_source\\CD86\\comptages permanents 2018.xlsx et  D:\\temp\\otv\\Donnees_source\\CD86\\Postes secondaires 2018.xls on traite les permanents et secondaires <br> il y a un petit pb sur les compteurs permanents entre la donnees pr+abs chez nous et la leur dans le tableau, donc il faut la premiere fois tout passer dans la table de correspondance.<br> dans ce dept pas de nouveau points\n",
    "- Année 2019 : \n",
    "> un seul fichier avec les comptages sur 2feuilles : permanents et tournants.<br> la feuille permanent contient aussi des données 'Tournant' qui sont masquées, pour lesquelles les reference en abscisse sont tuojours à 0<br> 3 nouveaux points tournants ajoutés à  la main, le reste des ponctuels en auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2018\n",
    "cd86=it.Comptage_cd86(r'D:\\temp\\otv\\Donnees_source\\CD86\\comptages permanents 2018.xlsx',r'D:\\temp\\otv\\Donnees_source\\CD86\\Postes secondaires 2018.xls')\n",
    "\n",
    "#si besoin de dico corresp : \n",
    "corr=cd86.corresp_perm('local_otv', 'na_2010_2018_p')\n",
    "cd86.insert_bdd('local_otv', 'comptage','corresp_id_comptag',corr)\n",
    "\n",
    "#sinon\n",
    "cd86.comptage_forme()\n",
    "cd86.classer_comptage_update_insert('local_otv', 'na_2010_2018_p')\n",
    "cd86.update_bdd_86('local_otv','comptage','na_2010_2018_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2019\n",
    "cd86=it.Comptage_cd86(r'D:\\temp\\otv\\2019\\Donnees_source\\CD86\\Comptages globaux 2019 tournants et permanents.xlsx',r'D:\\temp\\otv\\2019\\Donnees_source\\CD86\\Comptages globaux 2019 tournants et permanents.xlsx',2019,\n",
    "                     'permanents','secondaires')\n",
    "cd86.comptage_forme('local_otv_station_gti', 'na_2010_2019_p')\n",
    "cd86.classer_comptage_update_insert('local_otv_station_gti', 'na_2010_2019_p')\n",
    "cd86.update_bdd_86('local_otv_station_gti','comptage','na_2010_2019_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd86.classer_comptage_update_insert('local_otv_station_gti', 'na_2010_2019_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd86.df_attr_insert['dep']='86'\n",
    "cd86.df_attr_insert['reseau']='RD'\n",
    "cd86.df_attr_insert['gestionnai']='CD86'\n",
    "cd86.df_attr_insert['concession']='N'\n",
    "cd86.df_attr_insert['obs']=\"nouveau_point 2019, denomination CD86='tournant'\"\n",
    "cd86.df_attr_insert.rename(columns={'absc' : 'abs', 'tmja':'tmja_'+str(cd86.annee),'pc_pl':'pc_pl_'+str(cd86.annee),'obs':'obs_'+str(cd86.annee), 'src':'src_'+str(cd86.annee)},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd86.insert_bdd_86('local_otv_station_gti', 'comptage','na_2010_2019_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debut import fichier F:\\Boulot\\otv\\corresp_id_comptag.csv avec shape2pg à 09:18:21 \n",
      " avec commande ogr2ogr -f \"postgreSQL\" --config PG_USE_COPY YES -lco \"SCHEMA=public\" PG:\"host=localhost dbname=otv_gti user=postgres password=postgres port=5432\" F:\\Boulot\\otv\\corresp_id_comptag.csv -nln public.corr_id -oo HEADERS=YES\n",
      "Fait\n"
     ]
    }
   ],
   "source": [
    "with ct.ConnexionBdd('local_otv_gti', localisation='maison') as c : \n",
    "    ct.ogr2ogr_csv2pg(c.connstringOgr, r'F:\\Boulot\\otv\\corresp_id_comptag.csv',schema='public', table='corr_id',encodageClient='UTF-8', headers='YES')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***CD 24***\n",
    "- Année 2018 : \n",
    "> à partir des fichier D:\\temp\\otv\\Donnees_source\\CD24\\2018_CD24_trafic.csv <br> il n'y a que les compteurs permanents.<br> **Données Mensuelles dispos**.<br> Pensez que des céhanges ont ue lieu pour récupérer tous les points de comptages (perm, tourn, ponct). <br> ***Gros pb de geooloc des PR ign***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd24=it.Comptage_cd24(r'D:\\temp\\otv\\Donnees_source\\CD24\\2018_CD24_trafic.csv')\n",
    "cd24.comptage_forme()\n",
    "cd24.classer_comptage_update_insert('local_otv_station_gti', 'na_2010_2018_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd24.update_bdd_24('local_otv_station_gti', 'comptage', 'na_2010_2018_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd24.insert_bdd_24('local_otv_station_gti', 'comptage', 'na_2010_2018_p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Année 2019 : \n",
    ">à partir du fichier Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\CD24\n",
    "que les compteurs permanents et tournants.\n",
    "a voir pour les ponctuels, possibilité aussi de récupérer des données à partirde leur Web SIG : https://dordogne.maps.arcgis.com/apps/MapTools/index.html?appid=34558f68af514a63b6b7426ed77d055f en scrolant et enregistrant les différents fichiers html. ensuite pandas a une fonction read_html qu el'on applique sur des slices du fichiers html (car la fonction renvoi tout les elements dans des slices diffrentes : ligne du tableau, carte, etc...)<br> IL POURRAIT ETRE INTERESSANT DE METTRE A JOUR LES DONNEES DE GEOM SI BESOIN AVCE LES LONG/LAT issues du fichier source du CD24 quand c'est possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\geopandas\\geodataframe.py:830: UserWarning: Geometry column does not contain geometry.\n",
      "  warnings.warn(\"Geometry column does not contain geometry.\")\n"
     ]
    }
   ],
   "source": [
    "cd24=it.Comptage_cd24(r'D:\\Boulot\\AffairesEnCours\\OTV\\24_donnees_sources\\EXPORT SIG COMPTAGES CD24.csv',2019)\n",
    "cd24.comptage_forme()\n",
    "cd24.classer_comptage_update_insert('local_otv_gti', 'na_2010_2019_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marti\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\geopandas\\geodataframe.py:830: UserWarning: Geometry column does not contain geometry.\n",
      "  warnings.warn(\"Geometry column does not contain geometry.\")\n"
     ]
    }
   ],
   "source": [
    "cd24.update_bdd_24('local_otv_gti', 'comptage', 'na_2010_2019_p')\n",
    "cd24.insert_bdd('local_otv_gti', 'comptage', 'na_2010_2019_p', cd24.df_attr_insert)\n",
    "cd24.insert_bdd('local_otv_gti', 'comptage', 'na_2010_2019_mensuel', cd24.df_attr_mens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***CD 33***\n",
    "- Année 2019 : \n",
    "> à partir du fichier de comptage C:\\Users\\martin.schoreisz\\Box\\Dossier_Personnel_de_Martin_SCHOREISZ\\OTV\\33\\CD33\\export  2019 pour DREAL.xlsx (aussi présent sur les anciens serveurs) et du fichier de sectionnement C:\\Users\\martin.schoreisz\\Box\\Dossier_Personnel_de_Martin_SCHOREISZ\\OTV\\33\\CD33\\SECT_2021_CAT en cours.shp <br> On va chercher à recouper les comptages avec les notres en associant l'identifiant de troncon.<br> les troncons du CD ont l'air cohérents, on va qd mm checker les regrouepemnt <br> **Données Mensuelles dispos**<br> environ 70 cpt permanents et 60 tournants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "cptPerm33=it.Comptage_cd33( r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\CD33\\export_2019_pour_DREAL.xlsx',2019,\n",
    "                         r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\CD33\\SECT_2021_CAT en cours.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trouver les connus et inconnus\n",
    "GdfPerm,gdfPermConnus, gdfPermInconnus=cptPerm33.trierPermConnus('local_otv_boulot', 'na_2010_2019_p', 'boulot')\n",
    "#assigner les inconnu manuellement\n",
    "dico_corresp={'0106_03':'33-D106-35+835'}\n",
    "cptPerm33.assignerCptInconnus(dico_corresp,gdfPermInconnus)\n",
    "#fusion\n",
    "gdfPermConnus=pd.concat([gdfPermConnus, gdfPermInconnus.loc[~gdfPermInconnus.id_comptag.isna()]])\n",
    "gdfPermInconnus=gdfPermInconnus.loc[gdfPermInconnus.id_comptag.isna()]\n",
    "GdfPerm=pd.concat([gdfPermConnus,gdfPermInconnus])\n",
    "#mensuel\n",
    "donnees_mens_perm=GdfPerm[['troncon']+[m for m in it.dico_mois.keys()]].assign(donnees_type='tmja')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comptages tournants\n",
    "tournant=cptPerm33.analyseTourn()\n",
    "donneesMensTour=cptPerm33.donneesMensTournant(tournant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chercher les correspondance\n",
    "rqtPpvCptTournant=\"\"\"SELECT DISTINCT ON (c.troncon) t.id_ign, c.troncon\n",
    " FROM test_affectation_cd33_tournant t JOIN tournant_geoloc_l93 c ON st_dwithin(c.geom, t.geom,30)\n",
    " ORDER BY c.troncon, st_distance(t.geom, c.geom)\"\"\"\n",
    "rqtCptExistant=\"select id_ign, id_comptag from lineaire.traf2019_bdt33_ed19_l\"\n",
    "rqtGeomReferentielEpure='select id_ign, geom from test_affectation_cd33_tournant'\n",
    "rqtPpvCptBdd=\"\"\"SELECT DISTINCT ON (t.id_ign) t.id_ign, c.id_comptag\n",
    " FROM test_affectation_cd33_tournant t JOIN comptage.na_2010_2019_p c ON st_dwithin(c.geom, t.geom,30)\n",
    " WHERE c.gestionnai='CD33'\n",
    " ORDER BY t.id_ign, st_distance(t.geom, c.geom)\"\"\"\n",
    "correspTournant,inconnuTournant=cptPerm33.correspondanceTournant('gti_otv_pg11', 'boulot', rqtPpvCptTournant, rqtCptExistant, rqtGeomReferentielEpure, rqtPpvCptBdd,\n",
    "                               'public', 'test_affectation_cd33_tournant','test_affectation_cd33_tournant_vertices_pgr', tournant )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apres analyse mano : \n",
    "dicoCorrespTourn={'0005_06':'33-D5-76+0',\n",
    "                  '0012_11':'33-D12-17+200',\n",
    "                  '0115_06' : '33-D115-103+0',\n",
    "                 '0116_01':'33-D116-23+0',\n",
    "                 '0216_02':'33-D216-15+0',\n",
    "                 '0222_02':'33-D222-16+0',\n",
    "                 '0655_01':'33-D655-10+0'}\n",
    "cptTournantAffecte=cptPerm33.correctionCorrespondanceTournant(dicoCorrespTourn,tournant,correspTournant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creer les df_attr sur le mm schema que les habituels\n",
    "cptPerm33.df_attr_update=pd.concat([cptTournantAffecte.loc[cptTournantAffecte.correspondance==True][['id_comptag', 'tmja_2019', 'pc_pl_2019', 'obs_2019', 'src_2019', 'fichier']],\n",
    "gdfPermConnus[['id_comptag', 'tmja_2019', 'pc_pl_2019', 'src_2019', 'fichier']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creer nouveaux points tournants\n",
    "dicoNewCpt={'troncon':['0652_00','0003_17','0005_00','0009_02','0011_05','0012_10','0012_13','0110_01','0214_00','0222_01','0651_02','0932_03'],\n",
    "             'pr':[4,163,61,32,55,11,39,15,3,5,34,0],\n",
    "             'absc':[280,60,600,90,760,0,330,885,980,280,20,812]}\n",
    "cptPerm33.df_attr_insert=cptPerm33.creerNouveauPointTournants(cptTournantAffecte,dicoNewCpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "cptPerm33.df_attr_insert\n",
    "cptPerm33.df_attr_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#donnees mensuelles\n",
    "donnees_mens_perm.merge(GdfPerm[['troncon', 'id_comptag']], on='troncon')\n",
    "df_corresp_mens=cptTournantAffecte[['troncon','id_comptag']].merge(cptPerm33.df_attr_insert[['troncon','id_comptag']], on='troncon', how='left')\n",
    "df_corresp_mens['id_comptag']=df_corresp_mens.apply(lambda x : x['id_comptag_x'] if not pd.isnull(x['id_comptag_x']) else x['id_comptag_y'], axis=1)\n",
    "df_attr_mens=pd.concat([donneesMensTour.merge(df_corresp_mens[['troncon', 'id_comptag']], on='troncon'),\n",
    "                        donnees_mens_perm.merge(GdfPerm[['troncon', 'id_comptag']], on='troncon')]).drop('troncon', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "cptPerm33.insert_bdd('gti_otv_pg11', 'comptage', 'na_2010_2019_mensuel',df_attr_mens.assign(annee=str(cptPerm33.annee)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***SCA***\n",
    "- Année 2018 : \n",
    "> Concerne COFIROUTE, VINCI, ALIENOR, ATLANDES.<br> Des données de correspondances id_comptages sont dans la table source de la base de données otv.<br> **Donnees TMJM dispos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### COFIROUTE \n",
    "> Que 5 points, faits à la main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\" ></a>\n",
    "- ### VINCI \n",
    "> L'idée c'est d'importer le tableur et les données et de faire la jointure pour mise à jour.<br>**ATTENTION : rien de prévu si nouveau points** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2018\n",
    "cpt=it.Comptage_vinci(r'D:\\temp\\otv\\Donnees_source\\VINCI\\2018_comptage_vitesse_moyenne_VINCI.xlsx')\n",
    "cpt.update_bdd_Vinci('local_otv_station_gti', 'comptage', 'na_2010_2018_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2019\n",
    "cpt=it.Comptage_vinci(r'D:\\temp\\otv\\2019\\Donnees_source\\ASF\\bdd_point_comptage et vitesse moyenne 2019.xlsx', 2019)\n",
    "cpt.update_bdd_Vinci('local_otv_station_gti', 'comptage', 'na_2010_2019_p')\n",
    "#cpt.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_mensuel',cpt.df_attr_mens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2020 : pb de jointure entre les donnees et les id_comptag en base, donc je fais simple et je copie d'id comptage manuellement\n",
    "cpt=it.Comptage_vinci(r'C:\\Users\\martin.schoreisz\\Box\\Dossier_Perso\\OTV\\donnees_gestionnaires\\ASF\\en_cours\\bdd_point_comptage et vitesse moyenne 2020.xlsx', 2020)\n",
    "cpt.classer_comptage_update_insert('local_otv_boulot', 'compteur')\n",
    "#cpt.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_mensuel',cpt.df_attr_mens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insertion comptage\n",
    "cpt.insert_bdd('local_otv_boulot', 'comptage', 'comptage',cpt.creer_comptage(cpt.df_attr.id_comptag.tolist(), cpt.annee, 'tableur Vinci', 'tv/pl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insertion agrege\n",
    "cpt.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege',\n",
    "               cpt.structureBddOld2NewForm(cpt.df_attr_update, cpt.annee,['id_comptag', 'annee', 'fichier'],['tmja', 'pc_pl'], 'agrege'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insertion mensuel\n",
    "cpt.insert_bdd('local_otv_boulot', 'comptage', 'indic_mensuel',cpt.structureBddOld2NewForm(cpt.df_attr_mens, \n",
    "            cpt.annee,['id_comptag', 'annee', 'fichier', 'donnees_type'],['janv', 'fevr', 'mars', 'avri', 'mai', 'juin', 'juil', 'aout', 'sept',\n",
    "       'octo', 'nove', 'dece'], 'mensuel'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\" ></a>\n",
    "- ### ALIENOR / ATLANDES\n",
    "> Que 7 points chaucun, j'utilise surtout là pour les donees mensuelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alienor=it.Comptage_alienor(r'D:\\temp\\otv\\2019\\Donnees_source\\ALIENOR\\ALIENOR_trafic_2019.xlsx',2019)\n",
    "alienor.ouvrir_et_separe_donnees()\n",
    "alienor.update_bdd_Alienor('local_otv_station_gti', 'comptage', 'na_2010_2019_p')\n",
    "alienor.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_mensuel',alienor.df_attr_mens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlandes=it.Comptage_atlandes(r'D:\\temp\\otv\\2019\\Donnees_source\\ATLANDES\\2019_trafic_atlandes_7_boucles.xls',2019)\n",
    "atlandes.donnees_mens()\n",
    "atlandes.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_mensuel',atlandes.df_attr_mens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2020\n",
    "atlandes=it.Comptage_atlandes(r'C:\\Users\\martin.schoreisz\\Box\\Dossier_Perso\\OTV\\donnees_gestionnaires\\ATLANDES\\en_cours\\Trafic atlandes 2020 - 7 boucles DREAL.xls', '2020')\n",
    "donnees=atlandes.miseEnForme()\n",
    "atlandes.insert_bdd('local_otv_boulot', 'comptage', 'comptage',atlandes.donneesAgregees()[['id_comptag', 'src', 'type_veh', 'annee']] )\n",
    "atlandes.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege',\n",
    "                    atlandes.structureBddOld2NewForm(atlandes.donneesAgregees(),atlandes.annee, ['id_comptag', 'annee', 'fichier'], ['tmja', 'pc_pl'], 'agrege'))\n",
    "atlandes.insert_bdd('local_otv_boulot', 'comptage', 'indic_mensuel',\n",
    "                    atlandes.structureBddOld2NewForm(atlandes.df_attr_mens, atlandes.annee,['id_comptag', 'donnees_type', 'annee', 'fichier'], ['janv', 'fevr', 'mars', 'avri', 'mai', 'juin', 'juil',\n",
    "       'aout', 'sept', 'octo', 'nove', 'dece'], 'mensuel' ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Grand Poitiers***\n",
    "> on a deja un fichier dans la base de donnees : on va chercher a greffer les donnees et a cree un nouvel id_comptag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ouvrir un fichier\n",
    "dossier=r'D:\\temp\\otv\\2019\\Donnees_source\\GP\\Automatiques 2019'\n",
    "cpt=it.Comptage_GrandPoitiers(r'D:\\temp\\otv\\2019\\Donnees_source\\GP\\Automatiques 2019',2019)\n",
    "cpt.comptage_forme('local_otv_station_gti')\n",
    "cpt.update_bdd_grdPoi('local_otv_station_gti', 'comptage', 'na_2010_2019_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_horaire', cpt.df_attr_horaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=10 ></a>\n",
    "# ***Ville Anglet***\n",
    "> Ci-dessous simplement un exemple d'ouverture de fcihier .mdb, de liste des tables et de lecture d'une table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Anglet=it.Comptage_Anglet('2017',r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\Anglet\\COMPTAGES ANGLET\\Comptages 2017\\données brutes',\n",
    "                         r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\Anglet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epxortdu fichier csv seravnt a la geoloc\n",
    "Anglet.exporterCsvAGeocoder()\n",
    "#enuiste on geoloc a la main, dans le repertoir dossierResume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#puis on recupere la geoloc et on creer la df permettantde creer des compteurs\n",
    "Anglet.creerDfGeoloc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation des df hoarires et agrege sans filtre\n",
    "Anglet.indicsTousFichiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPPV=Anglet.plusProcheVoisinBddRegroupe('traf2020_bdt_na_ed20_simpli_l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trouver les doublons\n",
    "listCptDoublons=Anglet.isolerComptagesDoublons(dfPPV)\n",
    "#apres verif on conserve\n",
    "cptAConserver=['Anglet-10_rue_de_Chassin--1.5343;43.4819', 'Anglet-53_rue_de_Chassin--1.5323;43.4848', 'Anglet-103_Av_de_l_Adour--1.5002;43.5127', \n",
    "'Anglet-20_rue_de_Lavigne--1.5267;43.4724','Anglet-277_Av_de_l_Adour--1.5118;43.5262','Anglet-31_Av_de_la_Ch_d_Amour--1.5349;43.4952','Anglet-Av_Chambre_d_Amour(petit_casino)--1.5317;43.4949']\n",
    "#filtre\n",
    "dfPPVSsDbl=Anglet.cptSsDblEtSsGeom(dfPPV, cptAConserver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserer donnees \n",
    "Anglet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creer les compteurs a inserer dans la bdd\n",
    "dfCptAcreer=dfPPVSsDbl.loc[dfPPVSsDbl.id_comptag_bdd.isna()]\n",
    "compteur=dfCptAcreer[['geometrie', 'id_comptag', 'route', 'reseau', 'dep', 'gestionnai','concession', 'type_poste', 'src_geo', 'obs_geo', 'x_l93', 'y_l93',\n",
    "       'fictif', 'src_cpt', 'convention','obs_supl','sens_cpt']].drop_duplicates().copy()\n",
    "#inserer\n",
    "Anglet.insert_bdd('local_otv_boulot', 'comptage', 'compteur', compteur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creer les comptages a inserer dans la bdd\n",
    "dfPPVSsDbl['id_comptag_final']=dfPPVSsDbl.apply(lambda x : x.id_comptag_bdd if not pd.isnull(x.id_comptag_bdd) else x.id_comptag, axis=1)\n",
    "comptage=dfPPVSsDbl[['id_comptag_final', 'annee', 'periode']].assign(src='gestionnaire', type_veh='tv/pl').rename(columns={'id_comptag_final':'id_comptag'}).drop_duplicates()\n",
    "#inserer\n",
    "Anglet.insert_bdd('local_otv_boulot', 'comptage', 'comptage',comptage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creer les indicateurs a inserer dans la Bdd\n",
    "indicAgrege=dfPPVSsDbl.merge(Anglet.recupererIdUniqComptage(dfPPVSsDbl.id_comptag_final.tolist(), Anglet.annee).rename(columns={'id_comptag_final':'id_comptag'})\n",
    "                             , on=['id_comptag', 'annee'])[['id_comptag_uniq', 'indicateur', 'valeur', 'fichier']]\n",
    "dfHoraireSsDbl=Anglet.dfHoraire.merge(dfPPVSsDbl[['id_comptag', 'id_comptag_final']], on='id_comptag')\n",
    "indicHoraire=dfHoraireSsDbl.assign(annee=Anglet.annee, \n",
    "    indicateur=dfHoraireSsDbl.indicateur.str.upper()).merge(Anglet.recupererIdUniqComptage(\n",
    "    dfHoraireSsDbl.id_comptag_final.tolist(), Anglet.annee).rename(columns={'id_comptag':'id_comptag_final'}), on=['id_comptag_final', 'annee']).drop([\n",
    "    'sens_cpt', 'note_manuelle_qualite', 'obs_qualite', 'annee', 'id_comptag','id_comptag_final', 'obs_supl'], axis=1)\n",
    "Anglet.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege',indicAgrege)\n",
    "Anglet.insert_bdd('local_otv_boulot', 'comptage', 'indic_horaire',indicHoraire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indicHoraire.id_comptag_uniq.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jour</th>\n",
       "      <th>indicateur</th>\n",
       "      <th>h0_1</th>\n",
       "      <th>h1_2</th>\n",
       "      <th>h2_3</th>\n",
       "      <th>h3_4</th>\n",
       "      <th>h4_5</th>\n",
       "      <th>h5_6</th>\n",
       "      <th>h6_7</th>\n",
       "      <th>h7_8</th>\n",
       "      <th>h8_9</th>\n",
       "      <th>h9_10</th>\n",
       "      <th>h10_11</th>\n",
       "      <th>h11_12</th>\n",
       "      <th>h12_13</th>\n",
       "      <th>h13_14</th>\n",
       "      <th>h14_15</th>\n",
       "      <th>h15_16</th>\n",
       "      <th>h16_17</th>\n",
       "      <th>h17_18</th>\n",
       "      <th>h18_19</th>\n",
       "      <th>h19_20</th>\n",
       "      <th>h20_21</th>\n",
       "      <th>h21_22</th>\n",
       "      <th>h22_23</th>\n",
       "      <th>h23_24</th>\n",
       "      <th>fichier</th>\n",
       "      <th>id_comptag_uniq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [jour, indicateur, h0_1, h1_2, h2_3, h3_4, h4_5, h5_6, h6_7, h7_8, h8_9, h9_10, h10_11, h11_12, h12_13, h13_14, h14_15, h15_16, h16_17, h17_18, h18_19, h19_20, h20_21, h21_22, h22_23, h23_24, fichier, id_comptag_uniq]\n",
       "Index: []"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicHoraire.loc[indicHoraire.id_comptag_uniq.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paramétrer les infos relatives a une annee\n",
    "annee='2018'#2019\n",
    "dossier=r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\Anglet\\COMPTAGES ANGLET\\Comptages 2018\\données brutes'#C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\Anglet\\COMPTAGES ANGLET\\Comptages 2019\\données brutes\n",
    "dossierResume=r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\Anglet'\n",
    "codepostal='64600'\n",
    "Commune='Anglet'\n",
    "resumeComptage=os.path.join(dossierResume,f'Comptage{annee}.csv')\n",
    "resumeComptageGeoloc=os.path.join(dossierResume,f'Comptage{annee}_geoloc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lister les fichiers et exporter le fichier csv pour géocodage IGN\n",
    "dicoAdresse={'fichier':[], 'adresse':[], 'codePostal':codepostal, 'Commune':Commune}\n",
    "#exporter les adresses (géocodées ensuite via mongeocodeur)\n",
    "def replaceAdresse(matchobj):\n",
    "    return matchobj.group(0).replace('.',',')\n",
    "for files in os.listdir(dossier):\n",
    "    if os.path.isfile(os.path.join(dossier, files)) and files.endswith('.mdb'):\n",
    "        dicoAdresse['fichier'].append(os.path.join(dossier, files))\n",
    "        dicoAdresse['adresse'].append(re.sub('^[1-9]+\\.', replaceAdresse,files[:-4] ))\n",
    "dfFichierAdresse=pd.DataFrame(dicoAdresse)\n",
    "dfFichierAdresse.to_csv(resumeComptage, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importer le fichier des points de comptage geolocalise et le mettre en forme\n",
    "gdfGeoloc=gp.read_file(resumeComptageGeoloc, encoding='utf-8')#C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\Anglet\\Comptage2019_geoloc.csv\n",
    "gdfGeoloc.geometry=gp.points_from_xy(x=gdfGeoloc['longitude'], y=gdfGeoloc['latitude'], crs=4326)\n",
    "gdfGeoloc=gdfGeoloc.to_crs('epsg:2154')\n",
    "gdfGeoloc['id_comptag']=gdfGeoloc.apply(lambda x : 'Anglet-'+re.sub('_{2,50}', '_',re.sub('(,|\\.|\\'| +)', '_', x['adresse']))+f\"-{round(float(x['longitude']), 4)};{round(float(x['latitude']),4)}\", axis=1)\n",
    "gdfGeoloc['route']=gdfGeoloc.adresse.apply(lambda x : re.sub('^([1-9]{1,3},)+','', x))\n",
    "gdfGeoloc['reseau']='VC'\n",
    "gdfGeoloc['dep']='64'\n",
    "gdfGeoloc['gestionnai']='Anglet'\n",
    "gdfGeoloc['concession']=False\n",
    "gdfGeoloc['type_poste']='ponctuel'\n",
    "gdfGeoloc['src_geo']='adresse'\n",
    "gdfGeoloc['obs_geo']=gdfGeoloc.apply(\n",
    "    lambda x : f\"geocodé avec 'mon géocodeur' de l'IGN ; qualite : {x.qualite} ; precision geocodage : {x['precision geocodage']} ; ID adresse : {x['ID adresse']}; adresse geocodee : {x['adresse geocodee']}\", axis=1)\n",
    "gdfGeoloc['x_l93']=round(gdfGeoloc.geometry.x,3)\n",
    "gdfGeoloc['y_l93']=round(gdfGeoloc.geometry.y,3)\n",
    "gdfGeoloc['fictif']=False\n",
    "gdfGeoloc['src_cpt']='gestionnaire'\n",
    "gdfGeoloc['convention']=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#récupérer un fichier depuis le mdb et en extraire les donnees horaires\n",
    "listDfHoraires=[]\n",
    "dicoNbSens={}\n",
    "for row in gdfGeoloc.itertuples(index=False) : \n",
    "    print(row.fichier)\n",
    "    mhc=MHCorbin(row.fichier)\n",
    "    listDfHoraires.append(mhc.formaterDonneesHoraires(mhc.formaterDonneesIndiv(mhc.dfAgreg2Sens)).reset_index().assign(\n",
    "        id_comptag=row.id_comptag,\n",
    "        fichier=mhc.fichierCourt,\n",
    "        obs_supl=f\"{mhc.dfAgreg2Sens.obs_supl.values[0]} ; {mhc.dfAgreg2Sens.sensTxt.values[0]}\",\n",
    "        sens_cpt=mhc.dfAgreg2Sens.nb_sens.values[0],\n",
    "        note_manuelle_qualite=mhc.indicQualite,\n",
    "        obs_qualite=mhc.comQualite))\n",
    "#dfHoraireBddAnglet=Anglet.formaterDonneesHoraires(Anglet.formaterDonneesIndiv(Anglet.dfAgreg2Sens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcul des dF d'indicateurs\n",
    "dfHoraire=pd.concat(listDfHoraires)\n",
    "dfIndicAgrege=tmjaDepuisHoraire(dfHoraire.assign(annee=annee)).merge(dfHoraire[['id_comptag','obs_supl','sens_cpt', 'note_manuelle_qualite', 'obs_qualite', 'fichier']].drop_duplicates(), on='id_comptag', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\martin.schoreisz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\geopandas\\geodataframe.py:1321: UserWarning: Geometry column does not contain geometry.\n",
      "  warnings.warn(\"Geometry column does not contain geometry.\")\n"
     ]
    }
   ],
   "source": [
    "#passer la df dans bdd pour plus propche (cas du premier jeu de donnees passe) \n",
    "transfert=it.Comptage('fake')\n",
    "transfert.insert_bdd('local_otv_boulot', 'public', f'cpt_anglet_{annee}',gdfGeoloc.drop('fichier', axis=1), if_exists='replace' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trouver le plus proche voisin sur les tronçons elementaires de Vince (DF initiale)\n",
    "rqt=\"\"\"SELECT DISTINCT ON (c.field_1) c.*, t.gid, st_distance(c.geom, t.geom)\n",
    " FROM public.cpt_anglet_2019_temp c left JOIN linauto.traf2020_bdt_na_ed20_simpli_l t ON st_dwithin(c.geom, t.geom, 20)\n",
    " ORDER BY c.field_1, st_distance(c.geom, t.geom)\"\"\"\n",
    "with ct.ConnexionBdd('local_otv_boulot') as c : \n",
    "    dfPPV=gp.read_postgis(rqt, c.sqlAlchemyConn, crs='epsg:2154').merge(dfIndicAgrege, on='id_comptag', how='left').merge(periodeDepuisHoraire(dfHoraire.assign(annee='2019')), how='left', on='id_comptag')\n",
    "    dfPPV=O.gp_changer_nom_geom(dfPPV, 'geometrie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trouver le plus proche voisin sur les tronçons elementaires de Vince avec en plus une colonne qui traduit si le point existe deja\n",
    "rqt=f\"\"\"WITH \n",
    "cpteur_base AS (\n",
    "SELECT DISTINCT ON (c.id_comptag) c.id_comptag id_comptag_bdd, t.gid, st_distance(c.geom, t.geom)\n",
    " FROM comptage.compteur c left JOIN linauto.traf2020_bdt_na_ed20_simpli_l t ON st_dwithin(c.geom, t.geom, 20)\n",
    " ORDER BY c.id_comptag, st_distance(c.geom, t.geom))\n",
    "SELECT DISTINCT ON (c.field_1) \n",
    "                    c.*, t.gid, st_distance(c.geom, t.geom),\n",
    "                    c2.id_comptag_bdd\n",
    " FROM public.cpt_anglet_{annee} c left JOIN linauto.traf2020_bdt_na_ed20_simpli_l t ON st_dwithin(c.geom, t.geom, 20)\n",
    "                               LEFT JOIN cpteur_base c2 ON t.gid=c2.gid\n",
    " ORDER BY c.field_1, st_distance(c.geom, t.geom)\"\"\"\n",
    "with ct.ConnexionBdd('local_otv_boulot') as c : \n",
    "    dfPPV=gp.read_postgis(rqt, c.sqlAlchemyConn, crs='epsg:2154').merge(dfIndicAgrege, on='id_comptag', how='left').merge(periodeDepuisHoraire(dfHoraire.assign(annee=annee)), how='left', on='id_comptag')\n",
    "    dfPPV=O.gp_changer_nom_geom(dfPPV, 'geometrie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pour les comptages qui sont multiples et proches d'une voies, je ne garde que le plus fort (DF initiale)\n",
    "dfPPVTmja=dfPPV.loc[(dfPPV.indicateur=='tmja') & (~dfPPV.gid.isna())]\n",
    "dfCptUniq=dfPPV.loc[dfPPV.id_comptag.isin(dfPPVTmja.loc[dfPPVTmja.valeur==dfPPVTmja.groupby('gid').valeur.transform(max)].id_comptag.unique())]\n",
    "Comptag_2019=pd.concat([dfCptUniq, dfPPV.loc[dfPPV.gid.isna()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conserver certains comptages, mais en priorisant les plus fort quand même\n",
    "#compteurs a creer \n",
    "idComptagForce=('Anglet-12_bis_Av_de_la_Chambre_d_Amour--1.5306;43.495', 'Anglet-16_Av_de_la_Chambre_d_Amour--1.5307;43.4949')\n",
    "dfPPVForce=dfPPV.loc[(dfPPV.id_comptag.isin(idComptagForce)) & (dfPPV.indicateur=='tmja')]\n",
    "idComptagForceMax=dfPPVForce.loc[dfPPVForce.valeur==dfPPVForce.groupby('gid').valeur.transform(max)].id_comptag.unique()\n",
    "dfCptAcreer=dfPPV.loc[((dfPPV.id_comptag_bdd.isna()) |( dfPPV.id_comptag.isin(idComptagForceMax)))&(dfPPV.indicateur=='tmja')]\n",
    "#simple comptages supp sur compteur presents\n",
    "dfCptAModifier=dfPPV.loc[((~dfPPV.id_comptag_bdd.isna()) & (~dfPPV.id_comptag.isin(idComptagForceMax))) & (dfPPV.indicateur=='tmja')]\n",
    "dfCptAModifierMax=dfPPV.loc[(dfPPV.id_comptag.isin(dfCptAModifier.id_comptag.tolist())) & (dfPPV.valeur==dfPPV.groupby('gid').valeur.transform(max))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compteur=dfCptAcreer[['geometrie', 'id_comptag', 'route', 'reseau', 'dep', 'gestionnai','concession', 'type_poste', 'src_geo', 'obs_geo', 'x_l93', 'y_l93',\n",
    "       'fictif', 'src_cpt', 'convention','obs_supl','sens_cpt']].drop_duplicates().copy()\n",
    "comptage=dfCptAcreer[['id_comptag', 'annee', 'periode']].assign(src='gestionnaire', type_veh='tv/pl').drop_duplicates()\n",
    "indicAgrege=dfCptAcreer.merge(transfert.recupererIdUniqComptage(dfCptAcreer.id_comptag.tolist(), '2018'), on=['id_comptag', 'annee'])[['id_comptag_uniq', 'indicateur', 'valeur', 'fichier']]\n",
    "indicHoraire=dfHoraire.loc[dfHoraire.id_comptag.isin(dfCptAcreer.id_comptag.tolist())].assign(annee='2018', \n",
    "    indicateur=dfHoraire.loc[dfHoraire.id_comptag.isin(dfCptAcreer.id_comptag.tolist())].indicateur.str.upper()).merge(transfert.recupererIdUniqComptage(\n",
    "    dfHoraire.loc[dfHoraire.id_comptag.isin(dfCptAcreer.id_comptag.tolist())].id_comptag.tolist(), '2018'), on=['id_comptag', 'annee']).drop([\n",
    "    'sens_cpt', 'note_manuelle_qualite', 'obs_qualite', 'annee', 'id_comptag', 'obs_supl'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.concat([dfCptAcreer,dfCptAModifierMax]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#transférer les données\n",
    "transfert.insert_bdd('local_otv_boulot', 'comptage', 'compteur', compteur)\n",
    "transfert.insert_bdd('local_otv_boulot', 'comptage', 'comptage',comptage)\n",
    "transfert.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege',indicAgrege)\n",
    "transfert.insert_bdd('local_otv_boulot', 'comptage', 'indic_horaire',indicHoraire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ajout=MHCorbin(r\"C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\Anglet\\COMPTAGES ANGLET\\Comptages 2017\\données brutes\\211, Promenade de la Barre.mdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dicoTables={}\n",
    "with ct.ConnexionBdd('mdb', fichierMdb=r\"C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\Anglet\\COMPTAGES ANGLET\\Comptages 2017\\données brutes\\211, Promenade de la Barre.mdb\") as c:\n",
    "    tables = list(c.mdbCurs.tables())\n",
    "    for k in [t[2] for t in tables if t[2].lower() not in ('msysaces','msysobjects','msysqueries','msysrelationships')] :\n",
    "        dicoTables[k.lower()]=pd.read_sql(f\"SELECT * FROM {k}\", c.connexionMdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dicoTables['hshdr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('C:\\\\Users\\\\martin.schoreisz\\\\Documents\\\\temp\\\\OTV\\\\Anglet\\\\COMPTAGES ANGLET\\\\Comptages 2017\\\\données brutes\\\\211, Promenade de la Barre.mdb', None, 'MSysACEs', 'SYSTEM TABLE', None),\n",
       " ('C:\\\\Users\\\\martin.schoreisz\\\\Documents\\\\temp\\\\OTV\\\\Anglet\\\\COMPTAGES ANGLET\\\\Comptages 2017\\\\données brutes\\\\211, Promenade de la Barre.mdb', None, 'MSysObjects', 'SYSTEM TABLE', None),\n",
       " ('C:\\\\Users\\\\martin.schoreisz\\\\Documents\\\\temp\\\\OTV\\\\Anglet\\\\COMPTAGES ANGLET\\\\Comptages 2017\\\\données brutes\\\\211, Promenade de la Barre.mdb', None, 'MSysQueries', 'SYSTEM TABLE', None),\n",
       " ('C:\\\\Users\\\\martin.schoreisz\\\\Documents\\\\temp\\\\OTV\\\\Anglet\\\\COMPTAGES ANGLET\\\\Comptages 2017\\\\données brutes\\\\211, Promenade de la Barre.mdb', None, 'MSysRelationships', 'SYSTEM TABLE', None),\n",
       " ('C:\\\\Users\\\\martin.schoreisz\\\\Documents\\\\temp\\\\OTV\\\\Anglet\\\\COMPTAGES ANGLET\\\\Comptages 2017\\\\données brutes\\\\211, Promenade de la Barre.mdb', None, 'A5', 'TABLE', None),\n",
       " ('C:\\\\Users\\\\martin.schoreisz\\\\Documents\\\\temp\\\\OTV\\\\Anglet\\\\COMPTAGES ANGLET\\\\Comptages 2017\\\\données brutes\\\\211, Promenade de la Barre.mdb', None, 'A6', 'TABLE', None),\n",
       " ('C:\\\\Users\\\\martin.schoreisz\\\\Documents\\\\temp\\\\OTV\\\\Anglet\\\\COMPTAGES ANGLET\\\\Comptages 2017\\\\données brutes\\\\211, Promenade de la Barre.mdb', None, 'C5', 'TABLE', None),\n",
       " ('C:\\\\Users\\\\martin.schoreisz\\\\Documents\\\\temp\\\\OTV\\\\Anglet\\\\COMPTAGES ANGLET\\\\Comptages 2017\\\\données brutes\\\\211, Promenade de la Barre.mdb', None, 'C6', 'TABLE', None),\n",
       " ('C:\\\\Users\\\\martin.schoreisz\\\\Documents\\\\temp\\\\OTV\\\\Anglet\\\\COMPTAGES ANGLET\\\\Comptages 2017\\\\données brutes\\\\211, Promenade de la Barre.mdb', None, 'HSHDR', 'TABLE', None),\n",
       " ('C:\\\\Users\\\\martin.schoreisz\\\\Documents\\\\temp\\\\OTV\\\\Anglet\\\\COMPTAGES ANGLET\\\\Comptages 2017\\\\données brutes\\\\211, Promenade de la Barre.mdb', None, 'V5', 'TABLE', None),\n",
       " ('C:\\\\Users\\\\martin.schoreisz\\\\Documents\\\\temp\\\\OTV\\\\Anglet\\\\COMPTAGES ANGLET\\\\Comptages 2017\\\\données brutes\\\\211, Promenade de la Barre.mdb', None, 'V6', 'TABLE', None)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Ville Niort***\n",
    "> 2020 : une dizaine de ponts de comptage. l'enjeu est sur al localisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation des donnees a transferer\n",
    "cpt_niort=it.Comptage_Niort(r'D:\\temp\\otv\\2019\\Donnees_source\\Niort\\NIORT_COMPTAGE_ROUTIER_2020\\2020',2020)\n",
    "dico_id_comptag={\n",
    "'Niort-rue_alsace_lorraine--0,4580;46,3287' : '01 2020 Alsace Lorraine',\n",
    "'Niort-boulevard_cassin--0,4523;46,3223' :'01 2020 Rue Terraudiere Bld Cassin_2',\n",
    "'Niort-rue_terraudiere--0,4524;46,3228' :'01 2020 Rue Terraudiere Bld Cassin_1',\n",
    "'Niort-rue_chateau_menu--0,4524;46,3592': '02 2020 Chateau Menu',\n",
    "'Niort-rue_de_souche--0,4345;46,3260':'02 2020 rue de Souché',\n",
    "'Niort-rue_du_24_fevrier--0,4628;46,3212':'03 2020 24 Février',\n",
    "'Niort-avenue_de_paris--0,4458;46,3285':'03 2020 Paris',\n",
    "'Niort-avenue_saint_jean_angely--0,4656;46,3203':'03 2020 St Jean',\n",
    "'Niort-rue_14_juillet--0,4560;46,3233':'01 2020 Limoges 14 Juillet_2',\n",
    "'Niort-rue_marechal_leclerc--0,4400;46,3527':'01 2020 Mal Leclerc',\n",
    "'Niort-avenue_de_limoges--0,4565;46,3221':'01 2020 Limoges 14 Juillet_1',\n",
    "'Niort-rue_de_la_la_gare--0,4578;46,3203':'01 2020 rue de la gare'}\n",
    "dico_fichiers_final=cpt_niort.creer_dico(dico_id_comptag)\n",
    "cpt_niort.horaire_tout_cpt(dico_fichiers_final)\n",
    "cpt_niort.agrege_tout_cpt(dico_fichiers_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_niort.df_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_txt=cpt_niort.creer_valeur_txt_update(cpt_niort.df_attr, ['id_comptag','tmja','pc_pl', 'src'])\n",
    "cpt_niort.update_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_p', val_txt,{f'tmja_{str(cpt_niort.annee)}':'tmja',f'pc_pl_{str(cpt_niort.annee)}':'pc_pl', f'src_{str(cpt_niort.annee)}':'src'})\n",
    "cpt_niort.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_horaire', cpt_niort.df_attr_horaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 2016 a 2019 : \n",
    "on peut creer le dico_id_comptag a partir des donnees stockes dans la table (geom, id des fchiers, reference du dossier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dossier_src=r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\Niort\\comptages_2016_2019\\CEREMA'\n",
    "annees=['2016','2017','2018','2019']\n",
    "dico_dossier_src={annee:os.path.join(dossier_src, annee) for annee in annees}\n",
    "#obtenir le lien entre les fichiers et de compatg et l'id_comptag, precedemmnet entre dans la bdd via qgis\n",
    "with ct.ConnexionBdd('gti_otv_pg11') as c : \n",
    "    rqt=\"select id_comptag, id_cpt, fichier from comptage.na_2010_2019_p where id_comptag like 'Niort%%' and fichier IS NOT null\"\n",
    "    ids=pd.read_sql(rqt, c.sqlAlchemyConn)\n",
    "#formater pour pouvoir utiliser le code creer pour 2020\n",
    "dico_id_comptag={id_comptag:[os.path.join(d,f) for f in id_cpt.split(';')] for id_comptag,id_cpt,d in \n",
    "                 zip(ids.id_comptag.tolist(),ids.id_cpt.tolist(),ids.fichier.tolist()) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculer les données et les insérer\n",
    "for a,val in dico_dossier_src.items():\n",
    "    dico_limite={k:v for k,v in dico_id_comptag.items() if all([val in e for e in v])}\n",
    "    cpt_niort=it.Comptage_Niort(val,a)\n",
    "    cpt_niort.agrege_tout_cpt(dico_limite)\n",
    "    cpt_niort.horaire_tout_cpt(dico_limite)\n",
    "    cpt_niort.df_attr=cpt_niort.df_attr.loc[~cpt_niort.df_attr.tmja.isna()].copy()\n",
    "    cpt_niort.df_attr_horaire=cpt_niort.df_attr_horaire.loc[cpt_niort.df_attr_horaire.id_comptag.isin(cpt_niort.df_attr.id_comptag.tolist())].copy()\n",
    "    cpt_niort.insert_bdd('gti_otv_pg11', 'comptage', 'na_2010_2019_horaire',cpt_niort.df_attr_horaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Grand Dax***\n",
    "> une 20aine de points de comptage. l'enjeu est sur la localisation : faite à la main pour aller plus vite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cptDax=it.Comptage_GrandDax(r'D:\\temp\\otv\\2019\\donnees_produite\\points_Dax_temp.shp')\n",
    "cptDax.creer_df_agrege()\n",
    "cptDax.df_horaire_final()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cptDax.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_p', cptDax.df_attr)\n",
    "cptDax.insert_bdd('local_otv_station_gti', 'comptage', 'na_2010_2019_horaire',cptDax.df_attr_horaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Limoges Metropole***\n",
    "> un Webservice est dispo ici : https://siglm.agglo-limoges.fr/servernf/rest/services/_TRANSPORTS/transports_consult/featureServer\n",
    "on peut y acceder via Qgis, ce qui permet de creer un shape : Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\LIMOGES\\Limoge_Web_service.shp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## isoler les points représentatifs du trafic total\n",
    "1. ajouter des attributs d'identification : de la représentativité, de groupement\n",
    "1. Checker la validité des attributs et déterminer sur lesquels s'appuyer\n",
    "1. Regrouper les points avec un identfiant\n",
    "1. Conserver les points avec 'type' == 'Double' ie 'representatif'=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POUR INFO\n",
    "#rechreche incohérence entre direction et type : direction 2 sens et type Simple\n",
    "limMet.loc[(limMet.apply(lambda x : any([a.lower() in x['direction'].lower() \n",
    "            for a in ('2 sens','2  sens', 'deux sens', 'double sens', 'cumul') if x['direction']]), axis=1)) & (limMet['type']=='Simple')].objectid.tolist()\n",
    "\"\"\"objectId in (40390.0, 40844.0, 41639.0, 42174.0, 42175.0, 42176.0, 42177.0, 42432.0, 42599.0, 43066.0, 43720.0, \n",
    "52077.0, 39017.0, 39274.0, 39586.0, 39959.0, 40014.0, 40015.0) prioriser 'type'=='Double', ne pas trop s'appuyer sur le type\"\"\"\n",
    "#rechreche incohérence entre direction et type : direction != 2 sens et type Double : là aussi, ça confirme de s'appuyer sur le type Double\n",
    "limMet.loc[(limMet.apply(lambda x : all([a.lower() not in x['direction'].lower() \n",
    "            for a in ('2 sens','2  sens', 'deux sens', 'double sens', 'cumul') if x['direction']]), axis=1)) & (limMet['type']=='Double')].objectid.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limMet=it.Comptage_Limoges_Metropole(r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\LIMOGES\\Limoge_Web_service.shp',\n",
    "                                    r'D:\\temp\\otv\\2019\\donnees_produite\\test_limoges\\zone_equi_cpt.shp')\n",
    "limMet.groupe_point()\n",
    "limMet.df_regroupee_complete(limMet.df_regroupee())\n",
    "limMet.insert_bdd('gti_otv_pg11', 'comptage', 'na_2010_2019_p', limMet.df_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Agglo LaRochelle***\n",
    "> bcp de donnée éparpillées u peu n'importe comment ici : <br> Chaque commune à sa façon de bosser..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Exemple sainte-SOulle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dossier=r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\La_Rochelle\\donnees-la-rochelle\\Données La Rochelle\\7-Communes\\SteSoulle'\n",
    "toto=it.Comptage(os.path.join(dossier,'rue des Fortiness.txt'))\n",
    "SteSoulle=pd.read_csv(os.path.join(dossier,'rue des Fortines.txt'), sep=' ')\n",
    "SteSoulle.rename(columns={'Nombrevéhicules':'nbveh', 'Date':'heure'}, inplace=True)\n",
    "SteSoulle.reset_index(inplace=True)\n",
    "SteSoulle.rename(columns={'Nombrevéhicules':'nbveh', 'Date':'heure', 'index':'jour'}, inplace=True)\n",
    "SteSoulle.set_index(SteSoulle.apply(lambda x : pd.to_datetime(x['jour']+ ' ' + x.heure, dayfirst=True), axis=1), inplace=True)\n",
    "#les données sur le 4,10 et 11 février sont bizarres, on les exclus,du coup pour ne pas fausser le tmja avec trop de WE je ne garde que les jours ouvrés et je fais un tmjo\n",
    "#SteSoulle=SteSoulle.loc[(~SteSoulle.index.dayofyear.isin([pd.to_datetime(x).dayofyear for x in (('2016-03-28','2016-03-23','2016-04-02'))]))\n",
    "                       #& (~SteSoulle.index.dayofweek.isin((5,6)))][['nbveh', 'jour', 'heure']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcul tmja (basé sur calcul_indicateurs_agreges() de la classe FIM)\n",
    "df_jour=SteSoulle[['nbveh']].resample('1D').sum()\n",
    "df_jour=df_jour.loc[df_jour['nbveh']!=0].copy()\n",
    "if len(df_jour)<7 : \n",
    "    raise it.PasAssezMesureError(len(df_jour))\n",
    "elif len(df_jour) in (7,8) : \n",
    "    traf_list=df_jour.nbveh.tolist()\n",
    "    tmjo=int(statistics.mean([traf_list[0]+traf_list[-1]]+traf_list[1:-1]))\n",
    "else : \n",
    "    tmjo=int(df_jour.iloc[1:-1].nbveh.mean())*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_horaire=SteSoulle[['jour', 'heure', 'nbveh']].pivot(index='jour', columns='heure', values='nbveh').fillna(0)*2\n",
    "df_horaire.columns=[f'h{str(int(c.split(\":\")[0]))}_{str(int(c.split(\":\")[0])+1)}' for c in df_horaire.columns]\n",
    "df_horaire=df_horaire.reset_index().assign(type_veh='TV', id_comptag='LaRoche-r des fortines--1.0391;46.188')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toto.insert_bdd('gti_otv_pg11', 'comptage', 'na_2010_2019_horaire', df_horaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## La Rochelle\n",
    "plusieurs dossier contenant desfichiers de comptages, : Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\La_Rochelle\\campagne-comptages-2015\\trafic_aggloLR_SMOB2015 ; Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\La_Rochelle\\comptages_delattre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Larochelle.update_bdd_LaRochelle('gti_otv_pg11', 'comptage', 'na_2010_2019_p')\n",
    "Larochelle.insert_bdd('gti_otv_pg11', 'comptage', 'na_2010_2019_horaire', Larochelle.df_attr_horaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepar donnees\n",
    "Larochelle=it.Comptage_LaRochelle(r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\La_Rochelle\\donnees-la-rochelle\\Données La Rochelle\\7-Communes\\LaRochelle_LaPalice')\n",
    "ids=Larochelle.listCptCreer()\n",
    "Larochelle.creer_dfs(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ct.ConnexionBdd('gti_otv_pg11') as c : \n",
    "            rqt=\"select id_comptag, id_cpt from comptage.na_2010_2019_p where id_comptag in ('LaRoch-r marcel deflandre--1.2128;46.1698','LaRoch-r de bethencourt--1.2028;46.1712','LaRoch-r de bethencourt--1.2014;46.172')\"\n",
    "            ids=pd.read_sql(rqt, c.sqlAlchemyConn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fichier=r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\La_Rochelle\\donnees-la-rochelle\\Données La Rochelle\\7-Communes\\LaRochelle_LaPalice\\SEMAINE 2\\P1-RUE MARCEL DEFLANDRE SENS 2 SEMAINE 2.xls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(fichier)\n",
    "tmja=round(df.loc[38,'Unnamed: 6'])\n",
    "pl=round(df.loc[42,'Unnamed: 6'])\n",
    "periode=df.iloc[1,16]\n",
    "index_date=pd.date_range(start=pd.to_datetime(periode.split(' au ')[0][3:], dayfirst=True), end=pd.to_datetime(periode.split(' au ')[1], dayfirst=True))\n",
    "df_pl=df.iloc[17:24,2:26].copy()\n",
    "df_tv=df.iloc[27:34,2:26].copy()\n",
    "df_pl.columns=[f'h{str(i)}_{str(i+1)}' for i in range(24)]\n",
    "df_tv.columns=[f'h{str(i)}_{str(i+1)}' for i in range(24)]\n",
    "df_pl=df_pl.assign(jour=index_date, type_veh='PL')\n",
    "df_tv=df_tv.assign(jour=index_date, type_veh='TV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\" ></a>\n",
    "# ***DIRA***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Année 2019\n",
    "> il existe trois sorte de données, TMJA, TMJM et horaires. les données TMJA DOIVENT etre issu de (ordre de priorité) :<br>\n",
    "1. de la carto DIRA si le point est représenté\n",
    "1. du fichier global (Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\DIRA\\0_tmja_dira_par_section_20200106.ods)\n",
    "1. des fichiers horaires \n",
    "<br> les données horaires ne peuvent etre issue que des fichiers horaires Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\DIRA\\0_Annee_Complete_2019\n",
    "- des graphs dispo dans le notebook Graph_tafics\n",
    "- attention, certaines données de TMJA sont mises à jour apres prises en comptes des données horares,,quand une données horaire est dispo et le TMJA non. fait sous sql  \n",
    "***ATTENTION : EN 2020 IL Y  A EU CONFUSION NETRE LES POINTS rn150 MEDIS ET ST-ROMAIN-DE-BENET / BIEN CHECKER QUE TOUS LES IDENTFIANTS LIES AU BOUCLE ET AUTRES SONT OK***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## *TMJA / TMJM*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation de l'objet\n",
    "dira=it.Comptage_Dira(r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\DIRA\\0_tmja_dira_par_section_20200106.ods',\n",
    "                      r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\DIRA\\0_Annee_Complete_2019',\n",
    "                     '2019','gti_otv_pg11', 'na_2010_2019_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mise en form edes données\n",
    "dfMensGrp=dira.MiseEnFormeMensuelleAnnuelle(dira.verifValiditeMensuelle(dira.jointureExistantFichierTmja('gti_otv_pg11', 'na_2010_2019_p')))\n",
    "dira.MiseEnFormeAnnuelle(dfMensGrp,'16-N10-2+700')\n",
    "dira.MiseEnFormeMensuelle(dfMensGrp,'16-N10-2+700')\n",
    "#mise à jour de la Bdd\n",
    "dira.update_bdd_Dira('gti_otv_pg11', 'comptage', 'na_2010_2019_p', nullOnly=True)\n",
    "dira.insert_bdd('gti_otv_pg11','comptage', 'na_2010_2019_mensuel', dira.df_attr_mens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2020\n",
    "dira=it.Comptage_Dira(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\DIRA\\0_tmja_dira_par_section_20210101.ods',\n",
    "                      r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\DIRA\\GrosFichiers - JP CASSOU\\0_Annee_Complete_2020',\n",
    "                      r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\DIRA\\dira_tmja_2020.ods',\n",
    "                     '2020','local_otv_boulot', 'compteur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mise en forme des données \n",
    "dfMensGrp=dira.MiseEnFormeMensuelleAnnuelle(dira.verifValiditeMensuelle(dira.jointureExistantFichierTmja()))\n",
    "dira.MiseEnFormeAnnuelle(dfMensGrp)\n",
    "dira.MiseEnFormeMensuelle(dfMensGrp)\n",
    "#insertion des comptages\n",
    "dira.insert_bdd('local_otv_boulot', 'comptage', 'comptage', dira.creer_comptage(dira.df_attr.id_comptag.unique(), dira.annee, 'tableau annuel DIRA', 'tv/pl'))\n",
    "#insertion des indicateurs agreges\n",
    "dira.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege',dira.structureBddOld2NewForm(dira.df_attr, dira.annee,['id_comptag', 'annee', 'fichier'],['tmja', 'pc_pl'], 'agrege'))\n",
    "#insertion des indicateurs mensuel\n",
    "dira.insert_bdd('local_otv_boulot', 'comptage', 'indic_mensuel',dira.structureBddOld2NewForm(dira.df_attr_mens.replace(-99, np.nan), \n",
    "            dira.annee,['id_comptag', 'annee', 'fichier', 'donnees_type'],['janv', 'fevr', 'mars', 'avri', 'mai', 'juin', 'juil', 'aout', 'sept',\n",
    "       'octo', 'nove', 'dece'], 'mensuel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gestion des données carto\n",
    "donneesAgregeesUpdate, donneesAgregeesInsert=dira.cptCartoInsertUpdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update comptages\n",
    "dira.update_bdd('comptage', 'comptage', dira.creer_valeur_txt_update(donneesAgregeesUpdate.loc[donneesAgregeesUpdate.obs.isna()], ['id', 'src']),\n",
    "                {'src':'src'}, identifiant='id')\n",
    "dira.update_bdd('comptage', 'comptage', dira.creer_valeur_txt_update(donneesAgregeesUpdate.loc[~donneesAgregeesUpdate.obs.isna()], ['id', 'src', 'obs']),\n",
    "                {'src':'src', 'obs':'obs'}, identifiant='id')\n",
    "#update tmja\n",
    "dira.update_bdd('comptage', 'indic_agrege', dira.creer_valeur_txt_update(donneesAgregeesUpdate.assign(id_comptag_uniq=donneesAgregeesUpdate.id)\n",
    "                                                                         , ['id_comptag_uniq', 'tmja']), {'valeur':'tmja'}, identifiant='id_comptag_uniq',\n",
    "                filtre = \"indicateur='tmja'\")\n",
    "#update pc_pl\n",
    "dira.update_bdd('comptage', 'indic_agrege', dira.creer_valeur_txt_update(donneesAgregeesUpdate.assign(id_comptag_uniq=donneesAgregeesUpdate.id)\n",
    "                                                                         , ['id_comptag_uniq', 'pc_pl']), {'valeur':'pc_pl'}, identifiant='id_comptag_uniq',\n",
    "                filtre = \"indicateur='pc_pl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserer comptages\n",
    "dira.insert_bdd('local_otv_boulot', 'comptage', 'comptage',dira.creer_comptage(donneesAgregeesInsert.id_comptag.unique(), dira.annee, 'carto dira 2020', 'tv/pl', obs=donneesAgregeesInsert.obs.tolist()))\n",
    "dira.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege',dira.structureBddOld2NewForm(donneesAgregeesInsert, dira.annee,['id_comptag', 'annee', 'fichier'],['tmja', 'pc_pl'], 'agrege'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## *Donnees horaires*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time dfTousFichier,idCptNonAffectes,dblATraiter=dira.concatTousFichierHoraire()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vérifier\n",
    "dblATraiter\n",
    "idCptNonAffectes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Séparer les données horaires entres comptages existants et comptages a creer\n",
    "dfHoraireIdConnus, dfHoraireIdsInconnus=dira.scinderComptagExistant(dfTousFichier, dira.annee, table='comptage')\n",
    "dfHoraireIdsInconnus.rename(columns={'type_veh':'indicateur'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comptages a creer\n",
    "#mise en forme des donnees horaire vers du tmja\n",
    "dfTmjaPcpl=tmjaDepuisHoraire(dfHoraireIdsInconnus)\n",
    "dfMeltInconnusPeriode=periodeDepuisHoraire(dfHoraireIdsInconnus)\n",
    "\n",
    "#scinder les tablesvers comptages et indics_agrege\n",
    "#creer les comptages manquants puis recuperer les ids correspondants\n",
    "dfToutTable=dfTmjaPcpl.merge(dfMeltInconnusPeriode[['id_comptag', 'periode']], on=['id_comptag']).assign(\n",
    "    src='tmja reconstitue depuis donnees horaires 2020', type_veh='tv/pl')\n",
    "dfComptages=dfToutTable[['id_comptag','annee', 'periode', 'src', 'type_veh']].drop_duplicates(['id_comptag','annee', 'periode', 'src', 'type_veh'])\n",
    "dira.insert_bdd('local_otv_boulot', 'comptage', 'comptage', dfComptages)\n",
    "dfIdCptUniqsNew=dira.recupererIdUniqComptage(dfComptages.id_comptag.tolist(), '2020', 'local_otv_boulot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserer les indicateurs agreges\n",
    "dfIndicAgreges=dfToutTable[['id_comptag', 'annee', 'indicateur', 'valeur']].merge(dfHoraireIdsInconnus.assign(fichier=dfHoraireIdsInconnus.fichier.apply(\n",
    "    lambda x : ';'.join(set(x.split('.xls'))).strip(';'))).groupby('id_comptag').fichier.agg(lambda x : ';'.join(set(tuple(x)))).reset_index(), on='id_comptag').merge(\n",
    "    dfIdCptUniqsNew, on=['id_comptag','annee']).rename(columns={'id':'id_comptag_uniq'}).drop(['id_comptag', 'annee'], axis=1)\n",
    "dira.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege', dfIndicAgreges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#refaire tourner  l'identification des comptages existant ou non (nromalement tout le monde defvrait etre existant) puis inserer\n",
    "dfHoraireIdConnus, dfHoraireIdsInconnus=dira.scinderComptagExistant(dfTousFichier, dira.annee, table='comptage')\n",
    "dira.insert_bdd('local_otv_boulot', 'comptage', 'indic_horaire',dfHoraireIdConnus.drop(['id_comptag', 'index', 'annee'], axis=1).assign(fichier=dfHoraireIdConnus.fichier.apply(\n",
    "    lambda x : ';'.join(set(x.split('.xls'))).strip(';'))).rename(columns={'type_veh':'indicateur'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Année 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOUVELLE SOURCE DE DONNEES VIA Christophe Damas et DtecTV**\n",
    "on va aussi chercher à obtenir les données DIRA, mais d'abord on puet checker celles contenues dans les fichiersde TV ici : \n",
    "Q:\\DAIT\\TI\\DREAL33\\2021\\OTV\\Doc_travail\\Donnees_sources\\DIRA\\Donnees_Tipi_TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "donneesMinutes=pd.read_csv(r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\DIRA\\tipi_alienor_raw.v2.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#liste des stations TIPI\n",
    "listIdCompteurTipi=donneesMinutes.PME_ID.unique()\n",
    "#liste des stations OTV\n",
    "with ct.ConnexionBdd('local_otv_boulot') as c : \n",
    "    listObsSupl=pd.read_sql(\"select distinct id_comptag, id_cpt, obs_supl from comptage.compteur where gestionnai='DIRA'\", c.sqlAlchemyConn)\n",
    "listStationOtvBrut=listObsSupl.obs_supl.apply(lambda x : x.split(';')[1].split('station : ')[1] if not pd.isnull(x) and 'EMC' not in x and ';' in x else x).unique()\n",
    "listStationOtvBrut2=[e.split(',') for e in listStationOtvBrut if e and re.search('^M.*\\.._.*$', e)]\n",
    "listStationOtv=[a.strip().replace('_','') for b in listStationOtvBrut2 for a in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#station TIPI non présentes dans OTV : \n",
    "StationTipiHorsOTV=[s for s in listIdCompteurTipi if s not in listStationOtv]\n",
    "StationOtvHorsTipi=[s for s in listStationOtv if s not in listIdCompteurTipi]\n",
    "StationOtvTipi=[s for s in listIdCompteurTipi if s in listStationOtv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"8\" ></a>\n",
    "# ***DIRCO***\n",
    "- Année 2019 : \n",
    "> il existe trois sorte de données, TMJA, TMJM et horaires. les données TMJA et TMJM chaque source de données à sonpropre fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2019\n",
    "fichierMja=r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\DIRCO\\TMJA DIRCO-NA 2019_unfused.csv'\n",
    "fichierMjM=r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\DIRCO\\TMJM DIRCO-NA 2019.ods'\n",
    "dossierHoraire=r'Q:\\DAIT\\TI\\DREAL33\\2020\\OTV\\Doc_travail\\Donnees_source\\DIRCO\\données dirco'\n",
    "dirco=it.Comptage_Dirco(fichierMja,fichierMjM,dossierHoraire,'2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2020\n",
    "fichierMja=r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\DIRCO\\TMJA DIRCO 2020 NA.ods'\n",
    "fichierMjM=r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\DIRCO\\TMJM DIRCO 2020 NA.ods'\n",
    "dossierHoraire=r'C:\\Users\\martin.schoreisz\\Documents\\temp\\OTV\\DIRCO\\Re_ Observatoire des trafics routiers DREAL NA 2020'\n",
    "dirco=it.Comptage_Dirco(fichierMja,fichierMjM,dossierHoraire,'2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## TMJA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import des données et mise en forme des données\n",
    "dfTrafic=dirco.miseEnFormeMJA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#verifier et creer des compteurs si besoin\n",
    "dfIdsConnus, dfIdsInconnus=dirco.scinderComptagExistant(dfTrafic, '2020', gest='DIRCO')\n",
    "#modfi de la mise en forme\n",
    "dfIdsConnus['obs_supl']=dfIdsConnus.merge(dirco.existant[['obs_supl', 'id_comptag']], on='id_comptag').apply(lambda x : x['obs_supl_y']+';'+x['obs_supl_x'] if x['obs_supl_y'] else x['obs_supl_x'], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#MaJ de l'obs_supl\n",
    "dirco.update_bdd('comptage', 'compteur', dirco.creer_valeur_txt_update(dfIdsConnus.loc[~dfIdsConnus.obs_supl.isna()], ['id_comptag', 'obs_supl']), {'obs_supl':'obs_supl'})\n",
    "#creation des comptages\n",
    "dirco.insert_bdd('local_otv_boulot', 'comptage', 'comptage', dirco.creer_comptage(dfIdsConnus.id_comptag.tolist(), dirco.annee, 'tableau TMJA DIRCO', 'tv/pl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#insertion des données agrégées\n",
    "dirco.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege', \n",
    "                 dirco.structureBddOld2NewForm(dfIdsConnus, '2020', ['id_comptag', 'fichier', 'annee'], ['tmja', 'pc_pl'], 'agrege'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## TMJM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2019\n",
    "dfMensuel=dirco.indicateurGlobalFichierMJM('gti_otv_pg11','3-N145-9+573')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirco.insert_bdd('gti_otv_pg11','comptage', 'na_2010_2019_mensuel', dfMensuel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2020\n",
    "dfMensuel=dirco.indicateurGlobalFichierMJM('local_otv_boulot', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_comptag</th>\n",
       "      <th>janv</th>\n",
       "      <th>fevr</th>\n",
       "      <th>mars</th>\n",
       "      <th>avri</th>\n",
       "      <th>mai</th>\n",
       "      <th>juin</th>\n",
       "      <th>juil</th>\n",
       "      <th>aout</th>\n",
       "      <th>sept</th>\n",
       "      <th>octo</th>\n",
       "      <th>nove</th>\n",
       "      <th>dece</th>\n",
       "      <th>donnees_type</th>\n",
       "      <th>obs</th>\n",
       "      <th>annee</th>\n",
       "      <th>id_comptag_uniq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id_comptag, janv, fevr, mars, avri, mai, juin, juil, aout, sept, octo, nove, dece, donnees_type, obs, annee, id_comptag_uniq]\n",
       "Index: []"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trouver les comptages inconnus en 2020, verifier qu'il ne manque pas de compteur (termine a la main)\n",
    "dfIdsConnus, dfIdsInconnus=dirco.scinderComptagExistant(dfMensuel, '2020', 'comptage', gest='DIRCO')\n",
    "dfIdsInconnus.loc[~dfIdsInconnus.id_comptag.isin(dirco.existant.id_comptag.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creer les commptages inconnus (que si les compteurs existent)\n",
    "dirco.insert_bdd('local_otv_boulot', 'comptage', 'comptage', dirco.creer_comptage(dfIdsInconnus.id_comptag.unique(), dirco.annee, 'tableau TMJM DIRCO', 'tv/pl', obs='1 seul sens disponible'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trouver les comptages ayant des donnees mensuelles mais pas de donnees TMJA\n",
    "dfCptSansTmja=dirco.recupererComptageSansTrafic(dfIdsConnus.id_comptag.tolist(), '2020')\n",
    "dfCptSansTmja2=dfIdsConnus.loc[dfIdsConnus.id_comptag.isin(dfCptSansTmja.id_comptag.tolist())].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculer les indicateurs agreges des comptages sans tmja\n",
    "dfCptSansTmja2['tmja']=dfCptSansTmja2.loc[dfCptSansTmja2.donnees_type=='tmja'].apply(lambda x : int(mean([x[e] for e in dfCptSansTmja2.columns if e not in ('id_comptag', 'donnees_type', 'annee', 'id_comptag_uniq', 'obs')])), axis=1)\n",
    "dfCptSansTmja2['pc_pl']=dfCptSansTmja2.loc[dfCptSansTmja2.donnees_type=='pc_pl'].apply(lambda x : round(mean([x[e] for e in dfCptSansTmja2.columns if e not in ('id_comptag', 'donnees_type', 'annee', 'id_comptag_uniq', 'obs') and not pd.isnull(x[e])]),2), axis=1)\n",
    "#dfCptSansTmja2['valeur']=dfCptSansTmja2.apply(lambda x : x['tmja'] if not pd.isnull(x['tmja']) else x['pc_pl'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserer\n",
    "#agerege\n",
    "dirco.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege', dfCptSansTmja2.rename(columns={'donnees_type':'indicateur'}).assign(fichier=os.path.basename(dirco.fichierTmjm))[['id_comptag_uniq','indicateur','valeur','obs', 'fichier']])\n",
    "#mensuel\n",
    "dirco.insert_bdd('local_otv_boulot', 'comptage', 'indic_mensuel', dirco.structureBddOld2NewForm(dfIdsConnus.assign(fichier=os.path.basename(dirco.fichierTmjm)), \n",
    "                        dirco.annee, ['id_comptag', 'annee','obs', 'fichier', 'donnees_type'], ['janv', 'fevr', 'mars', 'avri', 'mai', 'juin', 'juil', 'aout', 'sept',\n",
    "       'octo', 'nove', 'dece'], 'mensuel' ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Horaire\n",
    "on ne dispose que de donnees TV, et il faut au prealable joindre les id_comptagavec les code_sation des donnes horaire. POur ça on utilise le fichier de tmja comme pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFichierTmja=dirco.miseEnFormeFichierTmjaPourHoraire()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicoCptOkTot,dicoCptErrorTot=dirco.tousFichierHoraires(dfFichierTmja)\n",
    "dicoCptErrorTot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jour</th>\n",
       "      <th>id_comptag</th>\n",
       "      <th>fichier</th>\n",
       "      <th>h0_1</th>\n",
       "      <th>h1_2</th>\n",
       "      <th>h2_3</th>\n",
       "      <th>h3_4</th>\n",
       "      <th>h4_5</th>\n",
       "      <th>h5_6</th>\n",
       "      <th>h6_7</th>\n",
       "      <th>h7_8</th>\n",
       "      <th>h8_9</th>\n",
       "      <th>h9_10</th>\n",
       "      <th>h10_11</th>\n",
       "      <th>h11_12</th>\n",
       "      <th>h12_13</th>\n",
       "      <th>h13_14</th>\n",
       "      <th>h14_15</th>\n",
       "      <th>h15_16</th>\n",
       "      <th>h16_17</th>\n",
       "      <th>h17_18</th>\n",
       "      <th>h18_19</th>\n",
       "      <th>h19_20</th>\n",
       "      <th>h20_21</th>\n",
       "      <th>h21_22</th>\n",
       "      <th>h22_23</th>\n",
       "      <th>h23_24</th>\n",
       "      <th>type_veh</th>\n",
       "      <th>annee</th>\n",
       "      <th>id_comptag_uniq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [jour, id_comptag, fichier, h0_1, h1_2, h2_3, h3_4, h4_5, h5_6, h6_7, h7_8, h8_9, h9_10, h10_11, h11_12, h12_13, h13_14, h14_15, h15_16, h16_17, h17_18, h18_19, h19_20, h20_21, h21_22, h22_23, h23_24, type_veh, annee, id_comptag_uniq]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trouver les comptages inconnus en 2020, verifier qu'il ne manque pas de compteur (termine a la main)\n",
    "dirco.corresp_nom_id_comptag(dirco.df_attr_horaire)\n",
    "dfIdsConnus, dfIdsInconnus=dirco.scinderComptagExistant(dirco.df_attr_horaire, '2020', 'comptage', gest='DIRCO')\n",
    "dfIdsInconnus.loc[~dfIdsInconnus.id_comptag.isin(dirco.existant.id_comptag.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jour</th>\n",
       "      <th>id_comptag</th>\n",
       "      <th>fichier</th>\n",
       "      <th>h0_1</th>\n",
       "      <th>h1_2</th>\n",
       "      <th>h2_3</th>\n",
       "      <th>h3_4</th>\n",
       "      <th>h4_5</th>\n",
       "      <th>h5_6</th>\n",
       "      <th>h6_7</th>\n",
       "      <th>h7_8</th>\n",
       "      <th>h8_9</th>\n",
       "      <th>h9_10</th>\n",
       "      <th>h10_11</th>\n",
       "      <th>h11_12</th>\n",
       "      <th>h12_13</th>\n",
       "      <th>h13_14</th>\n",
       "      <th>h14_15</th>\n",
       "      <th>h15_16</th>\n",
       "      <th>h16_17</th>\n",
       "      <th>h17_18</th>\n",
       "      <th>h18_19</th>\n",
       "      <th>h19_20</th>\n",
       "      <th>h20_21</th>\n",
       "      <th>h21_22</th>\n",
       "      <th>h22_23</th>\n",
       "      <th>h23_24</th>\n",
       "      <th>type_veh</th>\n",
       "      <th>annee</th>\n",
       "      <th>id_comptag_uniq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>19-A20-276+0</td>\n",
       "      <td>a20 19.xlsx</td>\n",
       "      <td>275.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>661.0</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>2046.0</td>\n",
       "      <td>1733.0</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>1530.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>1366.0</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>1081.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>TV</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2021-09-02</td>\n",
       "      <td>19-A20-276+0</td>\n",
       "      <td>a20 19.xlsx</td>\n",
       "      <td>220.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>1216.0</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>1702.0</td>\n",
       "      <td>1934.0</td>\n",
       "      <td>2102.0</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>1588.0</td>\n",
       "      <td>1903.0</td>\n",
       "      <td>1744.0</td>\n",
       "      <td>1866.0</td>\n",
       "      <td>1891.0</td>\n",
       "      <td>1571.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>TV</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2021-09-03</td>\n",
       "      <td>19-A20-276+0</td>\n",
       "      <td>a20 19.xlsx</td>\n",
       "      <td>226.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>2102.0</td>\n",
       "      <td>2215.0</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>1877.0</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>1672.0</td>\n",
       "      <td>1813.0</td>\n",
       "      <td>1825.0</td>\n",
       "      <td>1749.0</td>\n",
       "      <td>1225.0</td>\n",
       "      <td>848.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>TV</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2021-09-04</td>\n",
       "      <td>19-A20-276+0</td>\n",
       "      <td>a20 19.xlsx</td>\n",
       "      <td>283.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>823.0</td>\n",
       "      <td>1347.0</td>\n",
       "      <td>2029.0</td>\n",
       "      <td>2465.0</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>2198.0</td>\n",
       "      <td>1923.0</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>1772.0</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>1325.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>957.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>TV</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2021-09-05</td>\n",
       "      <td>19-A20-276+0</td>\n",
       "      <td>a20 19.xlsx</td>\n",
       "      <td>198.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>1357.0</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>2135.0</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>1873.0</td>\n",
       "      <td>1903.0</td>\n",
       "      <td>1870.0</td>\n",
       "      <td>1812.0</td>\n",
       "      <td>1544.0</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>933.0</td>\n",
       "      <td>638.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>TV</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>2021-09-26</td>\n",
       "      <td>87-N21-6+947</td>\n",
       "      <td>rn21 221 1021 1113.xlsx</td>\n",
       "      <td>129.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>561.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>579.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>TV</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>2021-09-27</td>\n",
       "      <td>87-N21-6+947</td>\n",
       "      <td>rn21 221 1021 1113.xlsx</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>637.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>835.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>TV</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>2021-09-28</td>\n",
       "      <td>87-N21-6+947</td>\n",
       "      <td>rn21 221 1021 1113.xlsx</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>987.0</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>604.0</td>\n",
       "      <td>732.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>878.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>TV</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>2021-09-29</td>\n",
       "      <td>87-N21-6+947</td>\n",
       "      <td>rn21 221 1021 1113.xlsx</td>\n",
       "      <td>28.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>988.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>652.0</td>\n",
       "      <td>825.0</td>\n",
       "      <td>976.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>TV</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>87-N21-6+947</td>\n",
       "      <td>rn21 221 1021 1113.xlsx</td>\n",
       "      <td>35.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>526.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>627.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>623.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>822.0</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>867.0</td>\n",
       "      <td>588.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>TV</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          jour    id_comptag                  fichier   h0_1   h1_2   h2_3  \\\n",
       "30  2021-09-01  19-A20-276+0              a20 19.xlsx  275.0  254.0  222.0   \n",
       "31  2021-09-02  19-A20-276+0              a20 19.xlsx  220.0  225.0  224.0   \n",
       "32  2021-09-03  19-A20-276+0              a20 19.xlsx  226.0  236.0  218.0   \n",
       "33  2021-09-04  19-A20-276+0              a20 19.xlsx  283.0  219.0  224.0   \n",
       "34  2021-09-05  19-A20-276+0              a20 19.xlsx  198.0  162.0  109.0   \n",
       "..         ...           ...                      ...    ...    ...    ...   \n",
       "849 2021-09-26  87-N21-6+947  rn21 221 1021 1113.xlsx  129.0   76.0   66.0   \n",
       "850 2021-09-27  87-N21-6+947  rn21 221 1021 1113.xlsx   11.0    8.0   13.0   \n",
       "851 2021-09-28  87-N21-6+947  rn21 221 1021 1113.xlsx   20.0   11.0   17.0   \n",
       "852 2021-09-29  87-N21-6+947  rn21 221 1021 1113.xlsx   28.0   15.0   17.0   \n",
       "853 2021-09-30  87-N21-6+947  rn21 221 1021 1113.xlsx   35.0   14.0   23.0   \n",
       "\n",
       "      h3_4   h4_5   h5_6   h6_7    h7_8    h8_9   h9_10  h10_11  h11_12  \\\n",
       "30   218.0  242.0  353.0  661.0  1294.0  1559.0  1518.0  1953.0  2046.0   \n",
       "31   213.0  233.0  359.0  611.0  1216.0  1462.0  1702.0  1934.0  2102.0   \n",
       "32   213.0  253.0  339.0  596.0  1149.0  1550.0  1658.0  2102.0  2215.0   \n",
       "33   238.0  243.0  290.0  453.0   823.0  1347.0  2029.0  2465.0  2358.0   \n",
       "34    93.0   97.0  139.0  231.0   426.0   728.0  1357.0  1880.0  2135.0   \n",
       "..     ...    ...    ...    ...     ...     ...     ...     ...     ...   \n",
       "849   25.0   22.0   21.0   74.0   115.0   156.0   281.0   347.0   444.0   \n",
       "850   27.0   66.0  145.0  325.0   989.0  1038.0   583.0   540.0   530.0   \n",
       "851   36.0   88.0  146.0  294.0   987.0  1050.0   595.0   514.0   528.0   \n",
       "852   34.0   84.0  141.0  319.0   945.0   988.0   611.0   585.0   548.0   \n",
       "853   27.0   96.0  133.0  320.0   999.0  1012.0   676.0   526.0   557.0   \n",
       "\n",
       "     h12_13  h13_14  h14_15  h15_16  h16_17  h17_18  h18_19  h19_20  h20_21  \\\n",
       "30   1733.0  1498.0  1530.0  1692.0  1366.0  1731.0  1462.0  1081.0   731.0   \n",
       "31   1731.0  1588.0  1903.0  1744.0  1866.0  1891.0  1571.0  1156.0   770.0   \n",
       "32   1965.0  1877.0  1964.0  1805.0  1672.0  1813.0  1825.0  1749.0  1225.0   \n",
       "33   2198.0  1923.0  1977.0  1772.0  1536.0  1325.0  1011.0   957.0   578.0   \n",
       "34   1731.0  1536.0  1873.0  1903.0  1870.0  1812.0  1544.0  1294.0   933.0   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "849   437.0   351.0   449.0   457.0   561.0   605.0   579.0   370.0   255.0   \n",
       "850   594.0   644.0   637.0   578.0   850.0  1001.0   835.0   497.0   335.0   \n",
       "851   604.0   732.0   622.0   660.0   813.0  1060.0   878.0   605.0   361.0   \n",
       "852   740.0   707.0   699.0   652.0   825.0   976.0   855.0   593.0   324.0   \n",
       "853   627.0   680.0   623.0   594.0   822.0  1066.0   867.0   588.0   377.0   \n",
       "\n",
       "     h21_22  h22_23  h23_24 type_veh annee  id_comptag_uniq  \n",
       "30    632.0   442.0   262.0       TV  2020              NaN  \n",
       "31    597.0   430.0   280.0       TV  2020              NaN  \n",
       "32    848.0   541.0   385.0       TV  2020              NaN  \n",
       "33    409.0   309.0   265.0       TV  2020              NaN  \n",
       "34    638.0   392.0   275.0       TV  2020              NaN  \n",
       "..      ...     ...     ...      ...   ...              ...  \n",
       "849   144.0    74.0    41.0       TV  2020              NaN  \n",
       "850   194.0    99.0    41.0       TV  2020              NaN  \n",
       "851   188.0   118.0    72.0       TV  2020              NaN  \n",
       "852   190.0   100.0    53.0       TV  2020              NaN  \n",
       "853   216.0   147.0    78.0       TV  2020              NaN  \n",
       "\n",
       "[240 rows x 30 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfIdsInconnus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creer les commptages inconnus (que si les compteurs existent)\n",
    "dirco.insert_bdd('local_otv_boulot', 'comptage', 'comptage', dirco.creer_comptage(dfIdsInconnus.id_comptag.unique(), dirco.annee, 'donnees horaires DIRCO', 'tv', obs='tmja recalcule a partirdes donnees horaires'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trouver les comptages ayant des donnees horaires mais pas de donnees TMJA\n",
    "dfCptSansTmja=dirco.recupererComptageSansTrafic(dfIdsConnus.id_comptag.tolist(), '2020')\n",
    "dfCptSansTmja2=dfIdsConnus.loc[dfIdsConnus.id_comptag.isin(dfCptSansTmja.id_comptag.tolist())].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mettre en forme les données\n",
    "dfTmja=dfCptSansTmja2[['id_comptag_uniq', 'jour','fichier']+attributsHoraire].assign(tmj=lambda x : sum([x[e] for e in dfCptSansTmja2.columns if e in attributsHoraire])).groupby(['id_comptag_uniq', 'fichier']\n",
    "    ).agg(trafSum=pd.NamedAgg(column='tmj',aggfunc='sum'), \n",
    "        nbJour=pd.NamedAgg(column='jour',aggfunc='count'))\n",
    "dfTmja['valeur']=round(dfTmja['trafSum']/dfTmja['nbJour'])\n",
    "dfTmja['indicateur']='tmja'\n",
    "dfTmja['obs']='tmja recalcule depuis donnees horaires'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserer les donnes agregees non connue\n",
    "dirco.insert_bdd('local_otv_boulot', 'comptage', 'indic_agrege',dfTmja.drop(['trafSum', 'nbJour'], axis=1).reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserer les donnes horaires\n",
    "dirco.insert_bdd('local_otv_boulot', 'comptage', 'indic_horaire',dirco.structureBddOld2NewForm(dirco.df_attr_horaire, dirco.annee, ['id_comptag', 'annee'], ['toto'], 'horaire'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"9\" ></a>\n",
    "# ***DIRSO***\n",
    "- Année 2020 : \n",
    "> il n'y a que 2 points, dont les données sont téléchargées directement sur le site de la DIRCO (cf src.txt sur Box)\n",
    "les 2 seuls poijnts qui nous interessent sont MAZERES N524 8+890 et  LAPEYRADE N524 64+800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ficherMensuel=r'C:\\Users\\martin.schoreisz\\Box\\Dossier_Perso\\OTV\\donnees_gestionnaires\\DIRSO\\en_cours\\hors_convention\\tmja_2020_cumule.xls'\n",
    "dirso=it.Comptage(ficherMensuel)\n",
    "dfMens=pd.read_excel(dirso.fichier, skiprows=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intitulé du PM</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>C. A.</th>\n",
       "      <th>Route</th>\n",
       "      <th>Janvier</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Février</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Mars</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Avril</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Mai</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Juin</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "      <th>Juillet</th>\n",
       "      <th>Unnamed: 20</th>\n",
       "      <th>Août</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Septembre</th>\n",
       "      <th>Unnamed: 24</th>\n",
       "      <th>Octobre</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>Novembre</th>\n",
       "      <th>Unnamed: 28</th>\n",
       "      <th>Décembre</th>\n",
       "      <th>Unnamed: 30</th>\n",
       "      <th>MJA</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <th>Evts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>33</td>\n",
       "      <td>932.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N524</td>\n",
       "      <td>8682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>MAZERES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>8+ 890</td>\n",
       "      <td>0.055</td>\n",
       "      <td>lg</td>\n",
       "      <td>0.057</td>\n",
       "      <td>lg</td>\n",
       "      <td>0.065</td>\n",
       "      <td>lg</td>\n",
       "      <td>0.089</td>\n",
       "      <td>lg</td>\n",
       "      <td>0.069</td>\n",
       "      <td>lg</td>\n",
       "      <td>0.07</td>\n",
       "      <td>lg</td>\n",
       "      <td>0.072</td>\n",
       "      <td>lg</td>\n",
       "      <td>0.068</td>\n",
       "      <td>lg</td>\n",
       "      <td>0.072</td>\n",
       "      <td>lg</td>\n",
       "      <td>0.063</td>\n",
       "      <td>lg</td>\n",
       "      <td>0.076</td>\n",
       "      <td>lg</td>\n",
       "      <td>0.057</td>\n",
       "      <td>lg</td>\n",
       "      <td>0.066</td>\n",
       "      <td>lg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>40</td>\n",
       "      <td>524.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N524</td>\n",
       "      <td>902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>LAPEYRADE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>64+ 800</td>\n",
       "      <td>0.159</td>\n",
       "      <td>lg</td>\n",
       "      <td>0.146</td>\n",
       "      <td>lg</td>\n",
       "      <td>0.174</td>\n",
       "      <td>lg</td>\n",
       "      <td>0.31</td>\n",
       "      <td>lg</td>\n",
       "      <td>0.168</td>\n",
       "      <td>lg</td>\n",
       "      <td>0.17</td>\n",
       "      <td>lg</td>\n",
       "      <td>0.134</td>\n",
       "      <td>lg</td>\n",
       "      <td>0.163</td>\n",
       "      <td>lg</td>\n",
       "      <td>0.379</td>\n",
       "      <td>lg</td>\n",
       "      <td>0.361</td>\n",
       "      <td>lg</td>\n",
       "      <td>0.419</td>\n",
       "      <td>lg</td>\n",
       "      <td>0.365</td>\n",
       "      <td>lg</td>\n",
       "      <td>0.235</td>\n",
       "      <td>lg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Intitulé du PM  Unnamed: 1  Unnamed: 2 Unnamed: 3  Unnamed: 4 C. A.  \\\n",
       "93             33       932.0         0.0          C         NaN   NaN   \n",
       "94        MAZERES         NaN         NaN        NaN         NaN         \n",
       "95             40       524.0         2.0          C         NaN   NaN   \n",
       "96      LAPEYRADE         NaN         NaN        NaN         NaN         \n",
       "\n",
       "       Route Janvier Unnamed: 8 Février Unnamed: 10   Mars Unnamed: 12  Avril  \\\n",
       "93      N524    8682        NaN    9067         NaN   5418         NaN   2830   \n",
       "94    8+ 890   0.055         lg   0.057          lg  0.065          lg  0.089   \n",
       "95      N524     902        NaN     922         NaN    614         NaN    329   \n",
       "96   64+ 800   0.159         lg   0.146          lg  0.174          lg   0.31   \n",
       "\n",
       "   Unnamed: 14    Mai Unnamed: 16  Juin Unnamed: 18 Juillet Unnamed: 20  \\\n",
       "93         NaN   5839         NaN  8684         NaN    8997         NaN   \n",
       "94          lg  0.069          lg  0.07          lg   0.072          lg   \n",
       "95         NaN    773         NaN  1035         NaN    1174         NaN   \n",
       "96          lg  0.168          lg  0.17          lg   0.134          lg   \n",
       "\n",
       "     Août Unnamed: 22 Septembre Unnamed: 24 Octobre Unnamed: 26 Novembre  \\\n",
       "93   8813         NaN      9202         NaN    8842         NaN     6196   \n",
       "94  0.068          lg     0.072          lg   0.063          lg    0.076   \n",
       "95   1148         NaN      1057         NaN    1008         NaN      578   \n",
       "96  0.163          lg     0.379          lg   0.361          lg    0.419   \n",
       "\n",
       "   Unnamed: 28 Décembre Unnamed: 30    MJA Unnamed: 32 Evts  \n",
       "93         NaN     8009         NaN   7549         NaN  NON  \n",
       "94          lg    0.057          lg  0.066          lg  NaN  \n",
       "95         NaN      762         NaN    860         NaN  NON  \n",
       "96          lg    0.365          lg  0.235          lg  NaN  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMensSo=dfMens.iloc[sorted([a for a in dfMens.loc[dfMens['Intitulé du PM'].isin(('MAZERES', 'LAPEYRADE'))].index]+[a-1 for a in dfMens.loc[dfMens['Intitulé du PM'].isin(\n",
    "    ('MAZERES', 'LAPEYRADE'))].index])].copy()\n",
    "dfMensSo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMensSoTmja=dfMensSo.loc[~dfMensSo.Evts.isna()][[a for b in it.dico_mois.values() for a in b if a in dfMensSo.columns]].assign(\n",
    "    donnees_type='tmja', id_comptag=['33-N524-8+890','40-N524-64+800'],fichier=os.path.basename(ficherMensuel), annee='2020').T.drop_duplicates().T\n",
    "dfMensSoPcpl=dfMensSo.loc[dfMensSo.Evts.isna()][[a for b in it.dico_mois.values() for a in b if a in dfMensSo.columns]].applymap(lambda x : x*100).assign(\n",
    "    donnees_type='pc_pl', id_comptag=['33-N524-8+890','40-N524-64+800'],fichier=os.path.basename(ficherMensuel), annee='2020').T.drop_duplicates().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dirso.insert_bdd('local_otv_boulot', 'comptage', 'indic_mensuel',\n",
    "                 dirso.structureBddOld2NewForm(pd.concat([dirso.renommerMois(dfMensSoPcpl),dirso.renommerMois(dfMensSoTmja)]), '2020', ['id_comptag', 'annee', 'donnees_type'], \n",
    "                                               [k for k in it.dico_mois.keys()], 'mensuel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Janvier</th>\n",
       "      <th>Février</th>\n",
       "      <th>Mars</th>\n",
       "      <th>Avril</th>\n",
       "      <th>Mai</th>\n",
       "      <th>Juin</th>\n",
       "      <th>Juillet</th>\n",
       "      <th>Août</th>\n",
       "      <th>Septembre</th>\n",
       "      <th>Octobre</th>\n",
       "      <th>Novembre</th>\n",
       "      <th>Décembre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>8682</td>\n",
       "      <td>9067</td>\n",
       "      <td>5418</td>\n",
       "      <td>2830</td>\n",
       "      <td>5839</td>\n",
       "      <td>8684</td>\n",
       "      <td>8997</td>\n",
       "      <td>8813</td>\n",
       "      <td>9202</td>\n",
       "      <td>8842</td>\n",
       "      <td>6196</td>\n",
       "      <td>8009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>902</td>\n",
       "      <td>922</td>\n",
       "      <td>614</td>\n",
       "      <td>329</td>\n",
       "      <td>773</td>\n",
       "      <td>1035</td>\n",
       "      <td>1174</td>\n",
       "      <td>1148</td>\n",
       "      <td>1057</td>\n",
       "      <td>1008</td>\n",
       "      <td>578</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Janvier  Février  Mars  Avril   Mai  Juin  Juillet  Août  Septembre  \\\n",
       "93     8682     9067  5418   2830  5839  8684     8997  8813       9202   \n",
       "95      902      922   614    329   773  1035     1174  1148       1057   \n",
       "\n",
       "    Octobre  Novembre  Décembre  \n",
       "93     8842      6196      8009  \n",
       "95     1008       578       762  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json(dfMensSo.loc[~dfMensSo.Evts.isna()][[a for b in it.dico_mois.values() for a in b if a in dfMensSo.columns]].T.drop_duplicates().T.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***TESTS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DETAILS OPERATIONS CD87\n",
    "\n",
    "#regrouper les différentes données issues de ficiers et les ajouter au dico\n",
    "for k, v in d87.dico_voie.items() : \n",
    "    for i,e in enumerate(v) : \n",
    "        if len(e['fichiers'])==1 : \n",
    "            print(e['fichiers'][0])\n",
    "            obj_fim=it.FIM(os.path.join(d87.dossier,e['fichiers'][0]))\n",
    "            try : \n",
    "                obj_fim.resume_indicateurs()\n",
    "            except obj_fim.fim_PasAssezMesureError : \n",
    "                continue\n",
    "            except Exception as ex : \n",
    "                print(f\"erreur : {ex} \\n dans fichier : {e['fichiers'][0]}\")\n",
    "            e['tmja'], e['pc_pl'], e['date_debut'], e['date_fin']=obj_fim.tmja, obj_fim.pc_pl, obj_fim.date_debut,obj_fim.date_fin\n",
    "        elif len(e['fichiers'])>1 :\n",
    "            list_tmja=[]\n",
    "            list_pc_pl=[]\n",
    "            for f in e['fichiers'] : \n",
    "                obj_fim=it.FIM(os.path.join(d87.dossier,f))\n",
    "                print(f)\n",
    "                try : \n",
    "                    obj_fim.resume_indicateurs()\n",
    "                except (obj_fim.fim_PasAssezMesureError,obj_fim.fimNbBlocDonneesError)  : \n",
    "                    continue\n",
    "                except Exception as ex : \n",
    "                    print(f\"erreur : {ex} \\n dans fichier : {f}\")\n",
    "                list_tmja.append(obj_fim.tmja)\n",
    "                list_pc_pl.append(obj_fim.pc_pl)\n",
    "            e['tmja'], e['pc_pl'], e['date_debut'], e['date_fin']=int(mean(list_tmja)), round(mean(list_pc_pl),2),np.NaN, np.NaN\n",
    "\n",
    "#renseigner le type de poste\n",
    "for k, v in d87.dico_voie.items() : \n",
    "    for e in v : \n",
    "        if len(e['fichiers']) > 4 :\n",
    "            e['type_poste']='permanent'\n",
    "        elif 1<len(e['fichiers'])<=4 : \n",
    "            e['type_poste']='tournant'\n",
    "        elif len(e['fichiers'])== 1 :\n",
    "            e['type_poste']='ponctuel'\n",
    "        else : \n",
    "            e['type_poste']='NC'\n",
    "\n",
    "#faire une df avec les points de comptage\n",
    "d87.df_attr=pd.DataFrame([[k, e['pr'], e['abs'], e['tmja'], e['pc_pl'], e['type_poste'],\n",
    "                      e['date_debut'],e['date_fin']] for k, v in d87.dico_voie.items() for e in v if 'tmja' in e.keys()], \n",
    "             columns=['route','pr','absc','tmja','pc_pl','type_poste','date_debut','date_fin'])\n",
    "d87.df_attr['id_comptag']=d87.df_attr.apply(lambda x :'87-'+x['route']+'-'+str(x['pr'])+'+'+str(x['absc']), axis=1)\n",
    "\n",
    "#filtre cpt ponctuel\n",
    "d87.df_attr=d87.df_attr.loc[d87.df_attr.apply(lambda x : x['date_debut'].month not in [7,8] and x['date_fin'].month not in [7,8], \n",
    "                                                         axis=1)].copy()\n",
    "\n",
    "#fare le tri avec les comptages existants : \n",
    "#recuperer les compmtages existants\n",
    "d87.comptag_existant_bdd('gti_otv_pg11', 'na_2010_2018_p', schema='comptage',dep='87', type_poste=False)\n",
    "d87.df_attr_update=d87.df_attr.loc[d87.df_attr.id_comptag.isin(d87.existant.id_comptag.tolist())].copy()\n",
    "d87.df_attr_insert=d87.df_attr.loc[~d87.df_attr.id_comptag.isin(d87.existant.id_comptag.tolist())].copy()\n",
    "#obtenir une cle de correspondace pour les comptages tournants et permanents\n",
    "df_correspondance=d87.corresp_old_new_comptag('gti_otv_pg11', 'public','d87_cpt_temp','lineaire.traf2017_bdt87_ed17_l',\n",
    "                                'referentiel', 'troncon_route_bdt87_ed17_l','troncon_route_bdt87_ed17_l_vertices_pgr','id')\n",
    "\n",
    "#verifier si cette clé n'existent pas deja dans la table de correspondance et passer les nouvelles dedans\n",
    "rqt_corresp_comptg='select * from comptage.corresp_id_comptag'\n",
    "with ct.ConnexionBdd('gti_otv_pg11') as c:\n",
    "    corresp_comptg=pd.read_sql(rqt_corresp_comptg, c.sqlAlchemyConn)\n",
    "df_correspondance=df_correspondance.loc[~df_correspondance['id_comptag'].isin(corresp_comptg.id_gest.tolist())]\n",
    "if not df_correspondance.empty():\n",
    "    d87.insert_bdd('gti_otv_pg11', 'comptage', 'corresp_id_comptag', \n",
    "               df_correspondance.rename(columns={'id_comptag_lin':'id_gti','id_comptag':'id_gest'})[['id_gest','id_gti']])\n",
    "\n",
    "#faire la correspondance entre les noms de comptage\n",
    "d87.corresp_nom_id_comptag('gti_otv_pg11',d87.df_attr)\n",
    "\n",
    "#recalculer les insert et update\n",
    "d87.df_attr_update=d87.df_attr.loc[d87.df_attr.id_comptag.isin(d87.existant.id_comptag.tolist())].copy()\n",
    "d87.df_attr_insert=d87.df_attr.loc[~d87.df_attr.id_comptag.isin(d87.existant.id_comptag.tolist())].copy()\n",
    "\n",
    "#mettre en forme pour update\n",
    "d87.df_attr_update['obs']=d87.df_attr_update.apply(lambda x : x['date_debut'].strftime('%d/%m/%Y')+'-'+ x['date_fin'].strftime('%d/%m/%Y') if not pd.isnull(x['date_debut']) else '', axis=1)\n",
    "d87.df_attr_update.loc[d87.df_attr_update.pc_pl.isna(),'obs']='pc_pl inconnu'\n",
    "d87.df_attr_update.loc[d87.df_attr_update.pc_pl.isna(),'pc_pl']=-99\n",
    "\n",
    "#preparer update\n",
    "valeurs_txt=d87.creer_valeur_txt_update(d87.df_attr_update, ['id_comptag','tmja','pc_pl','obs'])\n",
    "dico_attr={'tmja_2018':'tmja','pc_pl_2018':'pc_pl','obs_2018':'obs'}\n",
    "#update\n",
    "d87.update_bdd('gti_otv_pg11', 'comptage', 'na_2010_2018_p', valeurs_txt,dico_attr)\n",
    "\n",
    "#mettre en forme le insert\n",
    "dbl=d87.df_attr_insert.loc[d87.df_attr_insert.duplicated('id_comptag', False)].copy()\n",
    "ss_dbl=d87.df_attr_insert.loc[~d87.df_attr_insert.index.isin(dbl.index.tolist())].copy()\n",
    "dbl=dbl.dropna()\n",
    "dbl_traite=dbl.loc[dbl.tmja==dbl.groupby('id_comptag').tmja.transform(max)].drop_duplicates().copy()\n",
    "d87.df_attr_insert=pd.concat([dbl_traite,ss_dbl], axis=0, sort=False)\n",
    "d87.df_attr_insert.pc_pl.fillna(-99, inplace=True)\n",
    "annee='2018'\n",
    "d87.df_attr_insert['dep']='87'\n",
    "d87.df_attr_insert['reseau']='RD'\n",
    "d87.df_attr_insert['gestionnai']='CD87'\n",
    "d87.df_attr_insert['concession']='N'\n",
    "d87.df_attr_insert['obs']=d87.df_attr_insert.apply(lambda x : f\"\"\"nouveau_point,{x['date_debut'].strftime(\"%d/%m/%Y\")}-{x['date_fin'].strftime(\"%d/%m/%Y\")}\"\"\" if not (pd.isnull(x['date_debut']) and  pd.isnull(x['date_fin'])) else None,axis=1)\n",
    "d87.df_attr_insert.rename(columns={'absc' : 'abs', 'tmja':'tmja_'+annee,'pc_pl':'pc_pl_'+annee,'obs':'obs_'+annee},inplace=True)\n",
    "d87.df_attr_insert.drop(['date_debut','date_fin','route'],axis=1,inplace=True)\n",
    "\n",
    "#mettre à jour la geom\n",
    "d87.maj_geom('gti_otv_pg11', 'comptage', 'na_2010_2018_p', dep='87')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [],
   "source": [
    "Niort=MHCorbin(r'C:\\Users\\martin.schoreisz\\git\\otv\\otv\\Transfert_Donnees\\data\\MHCorbin\\rue de souche du 31 01 au 07 02 2020.mdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [
    {
     "ename": "PasAssezMesureError",
     "evalue": "le fichier comporte moins de 7 jours complets de mesures. Nb jours complets : 6 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPasAssezMesureError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MARTIN~1.SCH\\AppData\\Local\\Temp/ipykernel_4772/2861395283.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdfHoraireBddNiort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNiort\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformaterDonneesHoraires\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNiort\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformaterDonneesIndiv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNiort\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdfAgreg2Sens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\git\\otv\\otv\\Transfert_Donnees\\Donnees_sources.py\u001b[0m in \u001b[0;36mformaterDonneesHoraires\u001b[1;34m(self, df)\u001b[0m\n\u001b[0;32m   1043\u001b[0m             \u001b[0mdfHoraireBdd\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m         \"\"\" \n\u001b[1;32m-> 1045\u001b[1;33m         \u001b[0mdfFormatGroupe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGroupeCompletude\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNettoyageTemps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1046\u001b[0m         \u001b[0mdfHoraireBdd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdonneesIndiv2HoraireBdd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfFormatGroupe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdfHoraireBdd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\git\\otv\\otv\\Transfert_Donnees\\Donnees_sources.py\u001b[0m in \u001b[0;36mNettoyageTemps\u001b[1;34m(dfVehiculesValides)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;31m#vérif qu'il y a recouvrement\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtimstampMin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mtimstampMax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mPasAssezMesureError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbJours\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#sinon renvoyer sur l'erreur ci-dessus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;31m#on relimite la df :\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mdfValide\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdfVehiculesValides\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdfVehiculesValides\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate_heure\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimstampMin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtimstampMax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPasAssezMesureError\u001b[0m: le fichier comporte moins de 7 jours complets de mesures. Nb jours complets : 6 "
     ]
    }
   ],
   "source": [
    "dfHoraireBddNiort=Niort.formaterDonneesHoraires(Niort.formaterDonneesIndiv(Niort.dfAgreg2Sens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#récupérer un fichier depuis le mdb et en extraire les donnees horaires\n",
    "Anglet=MHCorbin(r'C:\\Users\\martin.schoreisz\\Box\\Dossier_Perso\\OTV\\donnees_gestionnaires\\Anglet_ville\\historique\\2019\\COMPTAGES ANGLET\\Comptages 2019\\donnees brutes\\1.Av .des Dauphins.mdb')\n",
    "dfHoraireBddAnglet=Anglet.formaterDonneesHoraires(Anglet.formaterDonneesIndiv(Anglet.dfAgreg2Sens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
